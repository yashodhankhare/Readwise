---
tags:
  - readwise
---

# The AI Mirror

![rw-book-cover](https://m.media-amazon.com/images/I/71TM1P-f6BL._SY160.jpg)

## Metadata
- Author: [[Shannon Vallor]]
- Full Title: The AI Mirror
- Category: #books

## Highlights
- On June 11, 2022, a Google engineer named Blake Lemoine made global headlines. He claimed that LaMDA, an artificial intelligence product that he was testing for his employer, was sentient—that it was a conscious, self-aware being, not a piece of company property. The subsequent media uproar was intense but brief, thanks to the loud chorus of AI researchers who quickly refuted Lemoine’s claims. Experts in the type of product that Lemoine was testing—a large language model or LLM—confidently reassured the public that LaMDA is, in fact, no more conscious than your toaster. The debate within the AI community that followed was not about whether Lemoine was wrong, but about how wrong. Did he simply jump the gun with a system that is at best a precursor to genuinely sentient AI? Or was his error one of a deeper kind? Was he hallucinating something not even faintly on our horizon? ([Location 66](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=66))
    - Tags: [[pink]] 
- To make sense of Lemoine’s error, it first helps to understand that today’s most advanced AI systems are constructed as immense mirrors of human intelligence. They do not think for themselves; instead, they generate complex reflections cast by our recorded thoughts, judgments, desires, needs, perceptions, expectations, and imaginings. ([Location 79](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=79))
    - Tags: [[pink]] 
- This book is about another power of AI mirrors, one that is harder to notice but even more dangerous. It is their power to induce in us a type of self-forgetting—a selective amnesia that loosens our grip on our own human agency and clouds our self-knowledge. It is an illusion that can ensnare even the most technologically adept among us, as it did Lemoine, who found himself talking to his own reflection. ([Location 84](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=84))
    - Tags: [[pink]] 
- Today’s AI mirrors tell us what it is to be human, what we ourselves care about, what we find good, or beautiful, or worth our attention. It is these machines that now tell us the story of our own past, and project our collective futures. They do so without living even one day of that history, or knowing a single moment of the human condition. What happens to a person, or an intelligent species, when they stop telling their own story? ([Location 96](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=96))
    - Tags: [[pink]] 
- One of the book’s aims is to explain why, and how, artificial intelligence is inseparable from our humanity; much in the way that our image in the mirror is inseparable from the body it reflects. The other aim is to explain how AI, in its dominant commercial form, endangers our humanity. This might sound less odd to you. It’s a common motif in science fiction and in contemporary media representations of AI. Whether it is claims that the “rise of the robots” and generative AI tools like ChatGPT will endanger the future of work for humans, or even more speculative warnings that a superior machine intelligence might enslave or exterminate us, we are by now used to hearing that AI is a potential threat to humanity. We need to understand this threat in a radically different way. AI does not threaten us as a future successor to humans. It is not an external enemy encroaching upon our territory. It threatens us from within our humanity. ([Location 103](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=103))
    - Tags: [[pink]] 
- This book tells a story of humanity increasingly lost in its own reflected image, and captive to mechanical mirrors of our own making. The story echoes that of Narcissus and Echo in Book III of the Metamorphoses. There, the Roman poet Ovid (43 BCE–17 AD) recounts the tragic fate of young Narcissus, whose beauty and pride became a fatal prison when he caught sight of his own face in a reflecting pool: Here, the boy, tired by the heat and his enthusiasm for the chase, lies down, drawn to it by its look and by the fountain. While he desires to quench his thirst, a different thirst is created. While he drinks he is seized by the vision ([Location 114](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=114))
    - Tags: [[pink]] 
- of his reflected form. He loves a bodiless dream. He thinks that a body, that is only a shadow. ([Location 119](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=119))
    - Tags: [[pink]] 
- Narcissus lies on the ground for days, ignoring his body’s growing hunger and need for sleep, vainly pleading with the beauty in the watery mirror to return his passion: How often he gave his lips in vain to the deceptive pool, how often, trying to embrace the neck he could see, he plunged his arms into the water, but could not catch himself within them! What he has seen he does not… ([Location 121](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=121))
    - Tags: [[pink]] 
- AI, and related computing technologies, increasingly function as a mirror of our humanity. It’s a profoundly useful and illuminating mirror, yet one that also creates for us, like Narcissus, a mortal danger. The chapters of this book will articulate more fully why and how AI can be understood as a mirror. For now, it is enough to say that like Narcissus’s pool, we see in AI a vision of ourselves that enthralls us, captivates us in much the way that… ([Location 126](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=126))
    - Tags: [[pink]] 
- Like Narcissus, we increasingly neglect the most essential and vital aspects of our embodied, fragile humanity and situation in order to chase illusions of perfection in the machine mirror. Like Narcissus, many fervently chase in AI a “bodiless dream,” this time a dream of our cognitive perfection rather than perfection of our physical countenance. Like Narcissus, we readily misperceive in this reflection the seduction of an “other”—a tireless companion, a perfect future lover, an ideal friend, an unbiased judge, a foolproof collaborator—yet in truth, a thing with which we are increasingly left alone, talking to ourselves.2 Even more dangerously, our AI mirrors project a vision of human intelligence constructed entirely from the amalgamated data of humanity’s past. This is why our dependence on these mirrors for self-knowledge risks leaving us captive like Narcissus, unwilling to move forward and leave behind what the mirror shows. At the very moment when accelerating climate change,… ([Location 131](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=131))
    - Tags: [[pink]] 
- Like Narcissus, our own humanity risks being sacrificed to that reflection. Corporate titans and even political leaders have taken to warning of the “existential risk” posed by powerful new AI systems, by which they mean the potential for AI systems to bring about human extinction. These warnings profoundly misunderstand the risk AI poses to humanity, as we will see. There are indeed risks that malevolent or foolish humans will use AI to bring about great harm. These harms will require robust safety engineering and regulatory action to prevent, just as we work to prevent accidents and terrorist actions enabled by nuclear power and biotechnologies. Yet the loudest political and corporate rhetoric around AI’s existential risk misrepresents the danger as coming from the tools themselves; from them spontaneously “waking up”… ([Location 140](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=140))
    - Tags: [[pink]] 
- The danger is a call to human action and responsibility. We are the source of the danger to ourselves from AI, and this is a good thing—it means we hold the power to resist, and the power to heal. After all, Ovid’s story is not about the evils of reflecting pools! What endangered Narcissus was not some shiny water. It was his own weakness of character—his vanity, narcissism, and selfish obsession—that enabled his detachment from others and the fatal loss of his world. The story of Narcissus (and of Echo, who appears in the next chapter) is about virtue, or rather, vice. It’s about what we lose when we habitually turn our eyes away from our shared future, away from its noblest possibilities and unmet responsibilities. ([Location 155](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=155))
    - Tags: [[pink]] 
- We face a stark choice in building AI technologies. We can use them to strengthen our humane virtues, sustaining and extending our collective capabilities to live wisely and well. By this path we can still salvage a shared future for human flourishing. Or we can continue on our current path: building and using AI in ways that disable the humane virtues by treating them as unnecessary for the efficient operation of our societies and the steering of our personal lives. ([Location 161](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=161))
    - Tags: [[pink]] 
- Unlike earthquakes, asteroids, supervolcanoes, and other force majeure threats to human welfare, nothing about the threat that AI now poses to our humanity is inevitable or forced upon us by nature. It is an entirely self-inflicted wound. This also means that rescuing ourselves from the threat posed by AI need not mean eliminating AI. In fact, “artificial intelligence” names a wide and diverse range of technologies, many of which are immensely beneficial and even essential tools for the highest moral task we face today: reconstructing the built world for sustainable human and planetary flourishing. ([Location 170](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=170))
    - Tags: [[pink]] 
- But AI is no panacea or cheap technical fix for our social and environmental ills. AI won’t enable a sustainable future without reformed political institutions and economic incentives. What’s more, the kinds of AI technologies we’re developing today are undermining and delaying these reforms rather than supporting them, precisely because they mirror the misplaced patterns of judgment and value that led us into our current peril. ([Location 180](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=180))
    - Tags: [[pink]] 
- To change that will require something more radical than the solutions sought by a growing number of computer scientists interested in fields like “AI safety,” who are looking for ways to program AI to be more reliably beneficial and aligned with human values.3 The reason this kind of strategy won’t work, at least not in our present environment, is because human values are at the very root of the problem. AI isn’t developing in harmful ways today because it’s misaligned with our current values. It’s already expressing those values all too well. ([Location 183](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=183))
    - Tags: [[pink]] 
- AI mirrors are being used to tell us what we will learn, in which career we can succeed, which roads we will travel, who we can love, who we will exclude or abuse, who we will detain or set free, who we will heal or house, what we will buy, and the investments we’ll make. They tell us what we will read, what words we’ll type next, which music we’ll hear, what images we’ll paint, the experiences we’ll seek, the risks we will accept, the strategies we’ll adopt, the policies we will support, and the visions of our future that we will embrace. ([Location 192](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=192))
    - Tags: [[pink]] 
- What AI mirrors do is to extract, amplify, and push forward the dominant powers and most frequently recorded patterns of our documented, datafied past. In doing so they turn our vision away from the newer, rarer, wiser, more mature and humane possibilities that we must embrace for the future. Instead of asking one another what we might now become, we ask AI mirrors to show us who we already are and have been, and to predict from there what must come next. We are frozen in place like Narcissus, captive to a reflection of our most immature forms of brilliance. As the chapters that follow will reveal, this loss of freedom to envision more humane yet unmade possibilities has roots that long predate digital computers. But those roots are now becoming mature, and they are strangling us. We are caught in the grip of a gradual and accelerating mechanization of the human personality: the systematic replacement of reflective discernment with mindless prediction; the efficient sacrifice of ([Location 200](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=200))
    - Tags: [[pink]] 
- shared flourishing to expected utility; the exchange of humane creativity and open-ended progress for local optimization of content delivery. In short, the surrender of humane wisdom to machine thinking. ([Location 207](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=207))
    - Tags: [[pink]] 
- Yet, because today’s AI mirrors face backward, the more we rely on them to know who we are, the more the fullness of our humane potential recedes from our view. ([Location 215](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=215))
    - Tags: [[pink]] 
- The Spanish existentialist philosopher José Ortega y Gasset wrote in 1939 about the relationship between human existence and technology. He insisted that the most basic impulse of the human personality is to be an engineer, carrying out a lifelong task of autofabrication: literally, the task of making ourselves.4 The task is ours because nature cannot provide the complete blueprint—we must draft it ourselves. Human language and culture, born of our surplus cognitive energy and capacity, liberated us from animal compulsions and desires without separating us from them. We have the same desires to eat, drink, and seek comfort as a cow does. But the cow has no need to ask itself, “What kind of cow do I want to be?”, or “What kind of cow can I be?”, or “What kind of cow should I be?” Eating, drinking, and finding a comfortable place to lie down is still essential for human animals but, as Ortega points out, for us it is not enough. Our restless mental energy compels further activity, and since nature did not provide the script for that further activity, or define for us its proper aims, we must complete that task ourselves. After we have slept, drank, and eaten each day, we must decide what else we will do—and be. ([Location 218](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=218))
    - Tags: [[pink]] 
- The values embedded in today’s AI tools are thus very poor mirrors of what humans as a whole want or care about. This endangers all of us, because mirrors are not merely passive things. Like all technologies, mirrors not only reflect us—they change us. Mirrors bring to our attention things we might otherwise have ignored. They show us things we could not easily see without them, and thereby open new possibilities for action. These new possibilities for action opened by our technologies also create new moral and political responsibilities that we would not have had otherwise.5 Mirrors, then, have important uses, and this is true of our AI mirrors too. We should want these mirrors to reflect the widest scope of human need and potential. But mirrors do not merely reveal things as they are: mirrors also magnify, occlude, and distort what is captured in their frame. Their view is always both narrower and shallower than the realities they reflect. This book is therefore about more than the past and present visions of our humanity being reflected in today’s AI mirrors. It is equally about what today’s AI mirrors do not show us: what they hide, what they diminish, what humane possibilities for self-engineering are lost in their bright surfaces, and how these possibilities might be recovered. ([Location 240](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=240))
    - Tags: [[pink]] 
- A metaphor draws a comparison between two things that are not literally of the same kind yet have parallel features that allow our understanding of one thing to carry over to and illuminate the other. While all metaphors have their limits and points of failure, the mirror metaphor, which has been used to explain many harmful outputs of AI systems, is more apt than we may realize, and for reasons that few have considered. ([Location 264](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=264))
    - Tags: [[pink]] 
- What does the metaphor of the mirror reveal about AI? What does it reveal about us? When we see the nature of human intelligence and thought in the mirror of an AI model or algorithm, what dimensions of ourselves are revealed and magnified in that mirror? Which aspects and possibilities of our existence are diminished, distorted, or occluded? To what illusions does that mirror potentially hold us captive, like Narcissus in the reflecting pool? And what threat do our AI mirrors pose for the future of our humanity—a threat having little to do with AI’s potential to dominate that future, and everything to do with our potential to surrender it? ([Location 267](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=267))
    - Tags: [[pink]] 
- From the beginning, artificial intelligence was intended to replicate the power of human cognition. While cybernetic theory allowed for broader notions of intelligence inspired by biological communication and control systems in other living things, it became a commonplace assumption from Turing’s 1950 paper forward that machine intelligence would, and should, mirror our own. ([Location 288](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=288))
    - Tags: [[pink]] 
- Popular media have long reinforced the misconception that AI researchers use something many readers will know as the “Turing Test” to measure success in developing a genuinely intelligent machine. The Turing Test, as a practical exercise (in contrast to its purely speculative role in Alan Turing’s classic paper) involves computers designed to fool a human conversational partner into believing that they are talking to another human. But in fact, very few serious AI researchers have regarded the test as either uniquely meaningful or definitive. Other than occasional public competitions held primarily to attract more funding and media coverage, the test has had little impact on serious AI research. In truth, no single test or benchmark for AI has been endorsed by scientific consensus. This is also true of intelligence itself, which most experts today regard as a “cluster concept” composed of multiple distinct cognitive faculties, rather than a single measurable quality. This is one reason why intelligence tests and related concepts like IQ have long been critiqued as arbitrary, biased, and limited in scope. As the paleontologist Stephen Jay Gould noted in 1981 in The Mismeasure of Man, the concept of intelligence is tainted by its ties to nineteenth-century pseudo-scientific efforts to design a metric that would definitively establish the innate superiority of white European peoples, and thereby justify policies of colonial repression, exclusion, and eugenics. As we will see later, this legacy has yet to be fully severed from the AI project. Still, for most AI researchers, a sound scientific definition of intelligence is not needed for the practical engineering task: build a machine that can do everything that intelligent human beings do. ([Location 295](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=295))
    - Tags: [[pink]] 
- AI is, therefore, an object of scientific interest (the theory of artificial cognition) and engineering ambition (the application of the theory to the construction of thinking machines). AI is often conflated with its close ([Location 308](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=308))
    - Tags: [[pink]] 
- relatives in computing. (If you’re a computer scientist, you can feel free to skip forward a few pages.) For example, most AI tools today embed some type of machine learning (ML). Machine learning uses various algorithmic techniques for producing a trainable mathematical model of the problem or task you want to solve. First, you need to design an algorithm that contains steps for calculating an “objective function,” namely, a mathematical description of the task in terms of a numerical sum to be maximized or minimized. Then, “train” that algorithm on a data set relevant to the task. The result is an abstract mathematical model that represents patterns in the data and an approximate path to the problem solution. Next, repeat the training process with the right kind of feedback to tune the results. Over many training runs, the algorithm updates the “weights” in its initial… ([Location 309](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=309))
    - Tags: [[pink]] 
- Cloud computing is another term linked to AI, as it is a popular way of making commercial AI systems available to end users. While many kinds of non-AI computing are also done via the “cloud,” large AI models are now routinely cloud-based. Instead of selling a proprietary model to customers, AI companies like Google, Microsoft, and Amazon can keep the model on their servers and sell cloud access to it, letting their customers use the model upon request via the Internet and a software bridge called an API (application programming interface). If you have tried OpenAI’s ChatGPT, you used their web-based API to do it. Many open-source, nonproprietary models are also cloud-hosted. However, some users store AI models on their own servers for security, transparency, or usability reasons. ([Location 325](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=325))
    - Tags: [[pink]] 
- Whether you realize it or not, you already interact with this kind of AI today whenever you search in a browser, consult recommendations from Netflix or YouTube, ask Alexa about the weather forecast, or configure your email spam folder. AI tools of this kind can now interact with you when you apply for a job with a large corporation, stand in front of the scanner at airport security, or get placed on an organ transplant list. Yet there remains deep disagreement in the AI community about what kind of progress has been made. ([Location 345](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=345))
    - Tags: [[pink]] 
- If you ask ChatGPT to tell you about me and my career, it usually gets a lot right, but it just makes up the rest. When my host at a festival I was speaking at used ChatGPT to write my bio for the live audience, the tool listed in a confident tone a series of fictitious articles I haven’t written, named as my coauthors people that I’ve never met, and stated that I graduated from the University of California at Berkeley (I have never studied there). Importantly, these are not errors. Error implies some kind of failure or miscalculation. But these fabrications are exactly what ChatGPT is designed to do—produce outputs that are statistically plausible given the patterns of the input. ([Location 400](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=400))
    - Tags: [[pink]] 
- When I was offered a PhD scholarship at age 25, I became a full-time student again after eight years in the workforce. I first set foot in a college dorm in my 40s, as a university professor. My story isn’t common. And that’s precisely why ChatGPT selected a more “fitting” story for me; quite literally, one that better “fit” the statistical curves of its data model for academic biographies. ([Location 409](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=409))
    - Tags: [[pink]] 
- These systems can perform computations on the world’s data far faster than we can, but they can’t understand it, because that requires the ([Location 413](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=413))
    - Tags: [[pink]] 
- ability to conceive of more than mathematical structures and relationships within data. AI tools lack a “world model,” a commonsense grasp and flowing awareness of how the world works and fits together. ([Location 414](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=414))
    - Tags: [[pink]] 
- AI tools don’t think, because they don’t need to. As this book explains, AI models use mathematical data structures to mimic the outputs of human intelligence—our acts of reasoning, speech, movement, sensing, and so on. They can do this without having the conscious thoughts, feelings, and intentions that drive our actions. Often, this is a benefit to us! It helps when a machine learning model’s computations solve a problem much faster than we could by thinking about it. It’s great when an AI tool finds a new, more efficient solution hidden somewhere in the math that you’d never look for. But your brain does much, much better than AI at coping with the countless problems the world throws at us every day, whose solutions aren’t mathematically predefined or encoded in data. ([Location 418](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=418))
    - Tags: [[pink]] 
- In this way, AI tools can function as a powerful amplifier of human ([Location 443](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=443))
    - Tags: [[pink]] 
- ability, automating computationally burdensome tasks that have been a bottleneck to progress in a larger human project. ([Location 443](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=443))
    - Tags: [[pink]] 
- Not only do the leading AI models continue to fabricate false answers, they often can’t defend the answers they get right. As researchers have showed, it is easy to trick a large language model into recanting its own correct answers, even by using absurdly invalid arguments.12 Does a machine understand a good answer that it can’t defend? ([Location 492](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=492))
    - Tags: [[pink]] 
- This is why the now-famous 2021 academic paper on the risks of large language models that sparked the controversial firing of its coauthors Timnit Gebru and Meg Mitchell from Google was titled “On the Dangers of Stochastic Parrots.” The paper explains that, like a parrot that not only repeats its owner’s vocalizations but produces random (stochastic) variations on the owner’s familiar pattern, these models parrot back to us variations on our own speech. They do so with just enough coherence and familiarity to project the illusion of understanding, and just enough randomness to surprise us and make us think we are hearing something new. The parrot metaphor works, up to a point, although I think the mirror metaphor works better. After all, parrots do experience a world and cope intelligently with it! ([Location 509](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=509))
    - Tags: [[pink]] 
- For there is another central character, and another mirror, in the story of Narcissus. Echo is the nymph who is herself, like most, besotted with the beautiful Narcissus. But thanks to a curse by the goddess Juno, who is jealous of her conversational talents, Echo finds herself rendered speechless save for one capacity—the ability to repeat the last few words spoken by ([Location 532](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=532))
    - Tags: [[pink]] 
- another. Echo cannot articulate any thoughts or desires of her own; when she opens her mouth, what comes out is only the trailing echo of another’s words. As Narcissus lies dying at the edge of the pool, his sighs and laments are helplessly mirrored by Echo’s speech. Yet with his gaze fixed on his own reflection, he does not realize that it is Echo, and not his beloved boy in the water, who quietly returns his farewell. ([Location 534](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=534))
    - Tags: [[pink]] 
- There is still hope for us to be something more with AI—and with one another—than what we have already been. ([Location 564](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=564))
    - Tags: [[pink]] 
- An AI mirror is not a mind. It is a mathematical tool for extracting statistical patterns from past human-generated data and projecting these patterns forward into optimized predictions, selections, classifications, and compositions. Eliza knew nothing of Pierre’s mind, or his pain, or the danger he was in, because Eliza knew nothing, and was no one, at all. Though a chatbot can mimic human speech, it bears no resemblance to AGI: a machine with thoughts of its own to express. A chatbot is a device for mathematically modeling human language patterns and extrapolating from these to generate new mathematical tokens (here, words and sentences) that mirror those patterns. A chatbot like Eliza uses words thoughtlessly, in the most literal sense. ([Location 587](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=587))
    - Tags: [[pink]] 
- Consider the image that appears in your bathroom mirror every morning. The body in the mirror is not a second body taking up space in the world with you. It is not a copy of your body. It is not even a pale imitation of your body. The mirror-body is not a body at all. A mirror produces a reflection of your body. Reflections are not bodies. They are their own kind of thing. By the same token, today’s AI systems trained on human thought and behavior are not minds. They are their own new kind of thing—something like a mirror. They don’t produce thoughts or feelings any more than mirrors produce bodies. What they produce is a new kind of reflection. ([Location 597](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=597))
    - Tags: [[pink]] 
- The intrinsically embodied character of biological minds has important implications for AI research, which is frequently led astray by the idea that the relationship between our minds and bodies is equivalent to the relationship between software and hardware. This computational metaphor for the mind can sometimes be useful, within its limits, but it has all too often been inflated into a computational theory of mind: the belief that the mind is, literally, a computer. It sparks fantasies of downloading and uploading human minds into the cloud, into virtual worlds, or into robot bodies, finally enabling the fleshy manacles of human mortality to be broken. Everything we know about the complex evolved physiology of mental life gives us ample reason to be skeptical of these fantasies.3 A trained AI model like ChatGPT is not a mind. It is a mathematical structure extracted from data. That structure must be stored and implemented on a physical object, but a server rack in a data storage facility has more in common with a file cabinet than with a living, feeling body. We do not get closer to the truth of a trained AI model when we describe it as an alien mind, or a weak mind, or a narrow mind. Even as a metaphor, the concept of a mind is a poor fit for an AI tool because it obscures rather than clarifies the nature of its object.4 The mirror metaphor is a far better heuristic and, conveniently, already a familiar one. ([Location 620](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=620))
    - Tags: [[pink]] 
- This is just one example of the kind of runaway feedback loop documented by sociologist Ruha Benjamin, in which the old human biases mirrored by our AI technologies drive new actions in the world, carving those harmful biases even deeper into our world’s bones.8 We see this in the phenomenon of Instagram digital video “beauty filters” designed with Eurocentric biases that make your skin whiter, your eyes wider, and your nose narrower. These kinds of filters are strongly associated with the negative effects of Instagram on young people’s mental health and self-image, particularly the effects on women whose real-world ([Location 679](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=679))
    - Tags: [[pink]] 
- world appearance does not match the standards of white female beauty that their filters allow them to mirror online. In their paper “The Whiteness of AI,” researchers Stephen Cave and Kanta Dihal detailed numerous ways in which AI today mirrors back to us and strengthens the dominant cultural preference for Whiteness, from its depictions in stock imagery to the nearly universal choice of white plastic for “social” robots. ([Location 684](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=684))
    - Tags: [[pink]] 
- Mirrors do not only reveal us; they distort, occlude, cleave, and flatten us. If I see in myself only what the mirror tells, I know myself not at all. And if AI is one of our most powerful mirrors today, we need to understand how its distortions and shallows dim our self-understanding and visions of our futures. ([Location 716](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=716))
    - Tags: [[pink]] 
- In his book How We Became Our Data: A Genealogy of the Informational Person, philosopher Colin Koopman reveals how this dream is rooted in the twentieth-century creation of a nascent data regime intent on the formatting of the human person as a set of discrete ([Location 765](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=765))
    - Tags: [[pink]] 
- and calculable variables: the invention of what he calls the “algorithmic personality.” Koopman’s historical analysis shows that this dream, born in the first quasi-scientific survey forms filled out by military conscripts to assess their emotional fitness for service, predates commercial AI by nearly a century. For many, today’s AI represents the hope of this dream’s final fulfillment. ([Location 767](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=767))
    - Tags: [[pink]] 
- Today, an AI hiring algorithm can be trained on a vast pool of data exhaust linked to you across multiple domains of activity, purchased from commercial data brokers that gather information about what kind of items you purchase for your home, what you like to eat and drink, where you’ve traveled on holiday, the work histories or legal records of your friends and relatives, the medical conditions you’ve researched online, the movies and TV shows you’ve downloaded, where you’ve frequently driven your car or ridden your bike, and the most common words used in your social media posts and those in your social network. ([Location 773](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=773))
    - Tags: [[pink]] 
- This is the root of the capabilities that AI marketers, investors, and pundits are now routinely describing as “god-like.” But for gods, these are a fairly shoddy bunch. Far from the omniscient revelations we might expect from all-powerful machine beings, today’s AI tools are deeply unreliable narrators. More like neighborhood gossips than deities, they can amuse and inform, but they also trade in stock clichés, stereotyped assumptions, and lazy guesses. This is certainly true for generative AI models like ChatGPT, which have the habit of “making shit up” baked into their algorithmic DNA. It’s not a malfunction. It’s what generative AI tools are designed to do—generate new content that looks or sounds right. Whether it is right is another matter altogether. ([Location 777](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=777))
    - Tags: [[pink]] 
- A study by Purdue University showed that ChatGPT gave incorrect answers to coding questions over half the time. Ironically, users often preferred the wrong answers to more accurate ones generated by knowledgeable humans, in part due to the confident style of the tool’s answers, accompanied by statements like, “Of course I can help you!” or “This will certainly fix it.”11 ([Location 789](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=789))
    - Tags: [[pink]] 
- I am far more than my data, and certainly far more than the totality of the data that Microsoft, Google, or data brokers like Axciom and Experian hold about me. You are more than your data as well. But if AI mirrors become the dominant way that we see who we are, then whatever they miss will sink further into invisibility. What does this loss include? What parts of ourselves get pushed further into the shadows, dwarfed by the intensifying and expanding luminance of our data trail? One aspect of our humanity that today’s AI mirrors reflect very poorly is the moral meaning of our lives and actions. Among the greatest social and commercial risks associated with AI algorithms is their inability to reliably track moral distinctions, or their meaning, which is highly context-dependent. There simply is no algorithm, no objective function, that reliably targets the variables “good” and “evil,” “right” and “wrong,” “morally permissible,” or “virtuous.” That is why social media platforms still cannot depend fully on their automated tools to remove harmful and dangerous content, from child pornography, to animal abuse, to terrorist propaganda. ([Location 804](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=804))
    - Tags: [[pink]] 
- There’s a deeper question here. What happens as AI mirrors become the dominant surface in which we see ourselves and one another, given that these mirrors either dangerously distort or block reflections of the moral qualities of our being? Since the tools themselves have no moral intelligence, their developers ([Location 829](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=829))
    - Tags: [[pink]] 
- must rely heavily on algorithmic filters to stop potentially harmful outputs. But these rigid and coarse-grained filters block far more than that. ([Location 832](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=832))
    - Tags: [[pink]] 
- There is one more limit of these mirrors’ reflective power. They occlude human spontaneity and adaptability: our profound potential for change. Predictive AI mirrors project our futures based on our past, and the past of others like us. If the user of a predictive AI model wants to know whether you are going to flourish at university and graduate in a timely manner, the prediction will say only how well students whose past data trails resembled yours today fared in their studies. Anything that is new in your life or mind, any sudden resolve or commitment, any inspiration or ambition that has recently germinated without leaving a trail in your data exhaust, is invisible to the model. It will predict that you will be in the future essentially who you have been. Or to be more precise, what people very much like you have been. But what ([Location 857](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=857))
    - Tags: [[pink]] 
- you could be, what transformations, or rebirths, or renewals are possible for you alone, or for all of us—these lie in the shadows beyond the penumbra of the AI mirror. One’s god, if you have one, might hold out hope for your redemption, but the AI mirror does not know the meaning of epiphany. What will become of us when we have looked in the AI mirror so long that we no longer know? As researcher Abeba Birhane has repeatedly argued, AI mirrors are profoundly conservative seers.15 That is, they are literally built to conserve the patterns of the past and extend them into our futures. This can be harmful for obvious, well-documented reasons. Historical policing data, used to train AI predictive policing tools, creates runaway feedback loops that ensure that minority neighborhoods continue to be overpoliced and thus overrepresented in crime statistics. These data then train the next version of the predictive model. It’s a vicious cycle. ([Location 863](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=863))
    - Tags: [[pink]] 
- Much of what is hidden from AI’s view lies in the realm of our lived experience of the world—what philosophers have called subjective consciousness or first-person “phenomenology.” ([Location 889](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=889))
    - Tags: [[pink]] 
- In this gaze that holds me at a distance from myself, that gaze of which an AI mirror can see or say nothing, Levinas observes that I am confronted with the original call to justice. When a person is not an abstraction, not a data point or generic “someone,” but a unique, irreplaceable life standing before you and addressing you, there is a feeling, a kind of moral weight in their presence, that is hard to ignore. ([Location 911](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=911))
    - Tags: [[pink]] 
- Levinas tells us that we live in a time “where no being looks at the face of the other.”18 He wrote this in 1961, long before we had a TikTok feed on our phones to deflect and mediate the gaze of our dinner companions, long before biometric eye-trackers measured our children’s engagement with a teacher, and long before AI mirrors converted the meaning of a human face to the calculation of uniquely identifying mathematical vectors in a faceprint. Our detachment from the world’s incessant and overwhelming calls to justice is nothing new. But the AI mirror threatens to engrave it even deeper into our way of being. ([Location 917](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=917))
    - Tags: [[pink]] 
- Might more advanced techniques in AI research and development produce equivalent gains in the function of AI mirrors, such that they can reveal more fully and faithfully who we are? To an extent, this is what is already happening with novel efforts in the field of AI ethics and “responsible AI.” These include developing more rigorous standards and benchmarks for algorithmic fairness testing, more diverse and inclusive training data, more reliable tools for making AI-generated predictions explainable or interpretable, and more robust regimes of algorithmic auditing and accountability to find the harmful distortions and unexpected occlusions that persist in these mirrors—even when we develop them with care, rigor, and integrity. ([Location 941](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=941))
    - Tags: [[pink]] 
- But there are limits—hard limits—to this path of building better, more encompassing AI mirrors. At least this is true for the data-hungry AI models that dominate the market today. An algorithmic pattern ([Location 946](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=946))
    - Tags: [[pink]] 
- discriminator that has no body to burst with energy or ache with age, no despair or ennui to assuage, no dreams to pursue, no calls for justice to make or answer, no secrets to hold or share, no hopes or fears to express in song or dance, no larger purpose to find in service or solidarity with others, can never know very much about who or what I am, or about who we are. More importantly, it knows even less—nothing at all—about what we can become, what we might make of ourselves and our lives together. ([Location 948](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=948))
    - Tags: [[pink]] 
- In Through the Looking Glass, Lewis Carroll’s sequel to Alice’s Adventures in Wonderland, Alice falls yet again into a realm of fantastical creatures and otherworldly possibilities, this time by means of a mirror. Set over the fireplace mantel, the mirror reflects the room in which Alice plays with her kittens. Yet as she chats to her animal companions, constantly projecting to herself their possible inner desires and motivations, the power of Alice’s imagination begins to project another possibility. She begins to believe that the looking glass is not a reflection of her existing reality, but a window. ([Location 975](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=975))
    - Tags: [[pink]] 
- She now imagines that it reveals another room into which she might pass. And pass into it with Kitty she does, to find in this inverted world new adventures with the mercurial Red Queen and the White Queen, Tweedledum and Tweedledee, Humpty Dumpty, and the mirror-written nonsense poetry of “Jabberwocky.” Carroll’s work is beloved by every generation because it embodies with rare intensity a humane virtue that is deeply cherished but, for many of us, hard to hold onto. It both exemplifies and glorifies the creative power of human imagination. Imagination is one of the few virtues that we often find more actively and readily expressed in children than adults. A virtue is an excellence of character, a trait that humans treasure and recognize as not only worthy of praise in an individual, but essential to shared human flourishing. There are moral virtues (such as courage, honesty, and generosity) and intellectual virtues (such as wisdom, curiosity, and open-mindedness), although some hold that these two types are not truly distinct. Virtues have been studied by philosophers for millennia, and in many different philosophical traditions and regions of the world. Both the ancient Greek philosopher Aristotle and the classical Chinese philosopher Kongzi (widely known by his Latinized name, Confucius) believed that virtues are not innate but acquired by practice. We can think of virtues as our moral and intellectual muscles, which like physical ([Location 979](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=979))
    - Tags: [[pink]] 
- muscles must be actively cultivated and strengthened by activity. So, most of our valued traits, like honesty and courage, are only weakly present as dispositions in children, while some virtues, like wisdom, are thought to be virtually absent in the very young. It is only with many years of reinforcement by habitual moral or intellectual practice, and refinement by social learning and feedback, that a good trait becomes deeply ingrained in our character and shaped well enough to be reliably expressed in the right ways. For reasons that readers of my first book, Technology and the Virtues, should find familiar, it’s important to consider the relationship of AI mirrors to our virtues. Our virtues can be powerfully shaped by our habits of using AI tools, because these tools alter how we perform the activities that build those virtues. By enabling more automation of social and intellectual tasks, AI tools will also affect whether those of us with access to these tools perform such activities at all. To put it another way, AI has the potential to change our human character; to make it better or worse. Yet as we have seen, virtues also encapsulate much of what AI mirrors fail… ([Location 989](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=989))
    - Tags: [[pink]] 
- Finally, moral and intellectual virtues—like wisdom, courage, justice, and honesty—hold the key to meeting the tremendous challenges we now face as a species. Without them, we cannot invent the new ways of flourishing together that a sustainable future on this fragile planet will demand. Whatever role we decide artificial intelligence should play in our existential task of autofabrication—José Ortega y Gasset’s term for the humane task of making new ways of life—we will need our virtues to guide it. Let’s return, then, to the virtue of imagination, which is a curious case. It was not named as a virtue by ancient philosophers such as Aristotle or Kongzi. But contemporary philosophers, including me, have often recognized it as one, or at least as an essential component of virtue.1 It is hard to envision someone entirely lacking in imagination who can still develop and express their full moral, intellectual, and creative potential. Imagination is how we envision yet unmade possibilities for ourselves and others; it is what makes autofabrication possible. Lacking any imagination might be technically survivable for an… ([Location 1000](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1000))
    - Tags: [[pink]] 
- While we do associate imagination strongly with children, this power—however vivid and fertile in a child’s mind—is not yet a full virtue. Imagination in a child can go overboard. It can present a danger if a child too easily confuses their dream for their reality. A child in the thrall of a fantasy may forget that they can’t actually fly. We cherish the child that is Carroll’s Alice, and we may well guess that Alice as a woman would be a joy to be around, but we wouldn’t ask Alice the child to make critical decisions with long-term consequences for the human family. This is because another essential component of any virtue is our ability to exercise it with situational intelligence, steered by what Aristotle called phrónēsis. Phrónēsis is variously translated in English as practical wisdom, prudence, or prudential… ([Location 1011](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1011))
    - Tags: [[pink]] 
- Yet the AI dream is driven as much by what AI is not, namely, an intelligence of the flesh, as by what it is—a mind of silicon, made intelligent only by code. ([Location 1039](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1039))
    - Tags: [[pink]] 
- But of course, those who worry about AGI existential risk imagine scenarios where humans have already given a malevolent AI system control of our power grid, and our water supply, and the mineral mines, and the chip factories, and everything else that AI needs to exist. Of course, we could simply not do that. This doesn’t seem hard. But that does not mean that AI poses no grave safety risks. In truth, we actually have more to fear from an AI system that is not truly intelligent, that doesn’t have a clue what it is doing or why, but has nonetheless been handed control of ([Location 1214](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1214))
    - Tags: [[pink]] 
- the critical systems on which we depend, in the name of “efficiency” and “innovation.” This would be immensely foolish, as many AI tools are prone to dangerous acts of “reward hacking.” That is, while it can’t alter its “reward function” or programmed objective, a machine learning system can often calculate a more efficient, surprising, and highly undesirable path to obtaining that goal. This is an old trope of science fiction, where AI tools that we program to protect human life at all costs might just imprison us to guarantee our safety. Real-life examples of AI “reward hacking,” while far less dramatic, are legion. They highlight that predicting how mindless AI tools might go about achieving the goals we set them is a serious problem. In the words of cybernetics pioneer Norbert Wiener, “To turn a machine off effectively, we must be in possession of information as to whether the danger point has come. The mere fact that we have made the machine does not guarantee that we shall have the proper information to do this.”17 ([Location 1218](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1218))
    - Tags: [[pink]] 
- Why are we trying to build AI to mirror ourselves? In part, because we can. That is, we already have what we need to make it work. Data and processing power are the two computing resources upon which today’s approach depends. Large, well-funded AI companies have been able to get their hands on a lot more of both in this century, thanks to the exponential growth in computing power described by Moore’s Law and the equally rapid growth in human-generated data—much of it delivered by social media and Internet platforms. Recall what I said in Chapter 2, that data are the incident “light” of these new AI mirrors. The answer to why so many AI researchers are now committed to this approach is a version of the punchline to the old joke: Why is the drunk man searching for his lost car keys under the lamppost? Because that’s where the light is. Still, a lucky drunk might find his keys there! But even if our present path did somehow lead us to “human-like” AGI (setting aside that our AI-training data miserably fail to represent all humans), consider this plainly obvious fact: we already have people to be people. Some countries do face temporary labor deficits due to aging populations, particularly when paired with rigid and punitive immigration policies, ([Location 1261](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1261))
    - Tags: [[pink]] 
- but globally, people are not in short supply. Even if it were feasible, creating digital versions of humans seems, well, redundant. The obvious exceptions involve tasks that very few people are capable of performing, or those tasks that most people would be happier with machines doing—what AI researchers call the 3Ds: dull, dirty, and dangerous labor. But even if many such tasks should be fully automated (a question which invites complex moral, political, and economic deliberation), narrow AI should do just fine for these applications. It doesn’t explain why we should build AI mirrors to be our doppelgangers. ([Location 1270](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1270))
    - Tags: [[pink]] 
- We also stand to gain more, even in purely economic terms, from building AI systems that augment human capacities rather than mirror them. Brynjolfsson points out that AI tools often yield the highest performance when they are paired with a human agent in a complementary way: when we build them to amplify or strengthen one component of a human performance rather than replace it altogether. ([Location 1298](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1298))
    - Tags: [[pink]] 
- But one company, Crisis Text Line, has used AI to rapidly match human volunteer therapists with people calling an emergency crisis hotline. This is a task that a very narrow AI tool can perform effectively and nearly instantaneously, all without a whit of “human-like” intelligence. It’s also a task that doesn’t replace a human ability—no human could do this kind of matching in real time without delaying lifesaving help. But with an AI tool in their task loop, matching their skills to others’ needs, the human therapists are augmented; they can be more effective than they were on their own. Using AI in this way doesn’t only make us better at what we already do. It can also help us do new things that were formerly beyond our capacity. And this is going to be of vital importance in this century and the next, as climate change, food insecurity, and global pandemics will require us to do many new things to survive and protect life on the planet. As Brynjolfsson notes, “inventing tools that augment the process of invention itself promises to expand not only our collective abilities, but to accelerate the rate of expansion of those abilities.”20 He observes that a turn from automation to augmentation can also counter ([Location 1302](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1302))
    - Tags: [[pink]] 
- the growing “tech backlash,” largely driven by justifiable public reactions to tech that increasingly exploits or replaces rather than empowers people. This backlash, however warranted, threatens public confidence in innovation, and undermines our collective will to develop and embrace the new science and technology that can boost our capacity to meet the existential challenges we face. ([Location 1312](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1312))
    - Tags: [[pink]] 
- In a profoundly ironic turn, this was also the plan for the data collected by nonprofit Crisis Text Line, when it packaged anonymized data from the sensitive conversations between their human volunteers and callers for sale to its for-profit spinoff Loris.ai.23 I say, “was the plan” because a loud public outcry from the volunteers and a global community of data and AI ethicists stopped it. The troves of data that Crisis Text Line had amassed—extracted from deeply personal and charitable acts of humans helping other humans in crisis—was going to be used by Loris.ai to power its customer service optimization AI tool, which monitors, instructs and scores human call center workers. The Loris.ai website says its AI improves the efficiency and ‘empathy’ of individual agents by steering their ([Location 1328](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1328))
    - Tags: [[pink]] 
- responses into “more predictable” patterns that “make every agent, your best agent.” Is this how humans acquire empathy —by parroting a machine-supplied pattern? We can build AI to mirror and systematically replace human intelligence—and empathy—with a machine-molded facsimile. Or we can build AI to genuinely assist and liberate our humane potential. You might ask, “why not both?” As Brynjolfsson points out, our short-sighted economic and political incentives have already heavily stacked the deck toward the first strategy. Unlike the ruthless optimization promised by the path of mechanized agency, the second option allows AI to increase the power and agency of beings like us. Beings who can say no, ask difficult questions, or point out inconvenient truths. Beings who can value things like justice and liberty more than efficiency or profit. Beings for whom intelligence is physically inseparable from the need to sleep, joke, mess around, doodle, daydream, and blow off steam. If we stay on the path with AI we are traveling now, that will not be the kind of intelligence that guides our futures. More likely we will get stuck in a world where our complex human agency, spontaneity and intellect are increasingly cramped and restrained by unthinking AI mirrors, wielded by powerful corporations and government powers who demand that our actions reflect back to these dead mirrors a denatured, reduced, but “optimized” version of what they took from us. This will also be what drives AGI development. Even if AGI cannot arise by this path, this model of “superhuman” intelligence will nevertheless define the kind of technology that we and our children will live with, and it will become the main measure of their humanity. I hope the examples above give you ample reason to question the desirability, or even the moral acceptability, of that future. The growing trend of reverse adaptation to AI explains why our lives will be worse if we don’t alter the current trajectory of AI development. But the examples above don’t capture the full sadness of such a failure of humanity’s most meaningful existential task: what Ortega called our autofabrication. Today’s AI mirrors cannot guide our future without us surrendering every hope of making ourselves more than what we have already been. Recall the earlier ([Location 1334](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1334))
    - Tags: [[pink]] 
- chapters’ description of today’s AI tools as mirrors pointing backwards, narrowly reflecting only the dominant statistical patterns in our data history. Such mirrors, when used not as reflections of the past but as windows into our future, serve as straitjackets on our moral, intellectual, cultural, and political imagination. They project the statistical curve of history into the still-open future, and by… ([Location 1351](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1351))
    - Tags: [[pink]] 
- The painter who draws merely by practice and by eye, without any reason, is like a mirror which copies every thing placed in front of it without being conscious of their existence. —Leonardo da Vinci, Libro di Pittura “Book on Painting” (1513–1516 AD) ([Location 1512](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1512))
    - Tags: [[pink]] 
- It is a profoundly erroneous truism . . . that we should cultivate the habit of thinking of what we are doing. The precise opposite is the case. Civilization advances by extending the number of important operations which we can perform without thinking about them. ([Location 1518](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1518))
    - Tags: [[pink]] 
- So, when we gaze in our AI mirrors, we often cannot ask the mirror why it sees what it sees. Even if we design a way to ask, it can be impossible to get an answer that is both reliable (a correct and precise explanation) and interpretable (that is, understandable in human terms). And this is a big problem if what we are using this tool to do is to recommend a lifesaving medical treatment, deny someone a loan or a job, accuse them of fraud, or predict a child’s educational achievement—all things that AI mirrors are currently being used to do. How can we trust such decisions if we cannot understand or interrogate them? There are now many agendas in AI research driven by attempts to get around this difficult problem by finding new ways to make model outputs “explainable.” But there’s a deeper issue, namely, the way that AI mirrors are now limiting our own space for thinking. Unless we address it, we may soon be unable to answer the question I asked at the start of this chapter: What thoughts do the civilized keep? ([Location 1571](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1571))
    - Tags: [[pink]] 
- Dost thou know why the mirror (of thy soul) reflects nothing? Because the rust is not cleared from its face. —Rumi, “Masnavi” 1:34 (1273 CE) ([Location 1953](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1953))
    - Tags: [[pink]] 
- All technologies are mirrors, because all technologies are extensions of human values into the built world. Every technology—from the wheel, to the book, to the engine, to the computer—reflects what humans of certain times and places thought was worth doing, making, enabling, improving, or trying. Judgments of “worth” always indicate a human act of valuing, whether or not we are valuing the right things. Even acts of violence can express a value judgment. If I willingly strike you in the face, I am expressing a judgment that at that moment, your personal dignity and well-being are not worth enough to me to command ([Location 1955](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1955))
    - Tags: [[pink]] 
- my respect—not valuable enough to warrant me making the necessary moral effort to restrain my rage. When we gaze in our AI mirrors at the words and images they generate, at the predictions and classifications they make, we are not seeing objective truths, under any definition of “objective.” We are seeing reflections of what humans valued enough to describe or record in data. But not all humans. What our AI mirrors show are the values of those humans who have historically had the power to shape the dominant patterns now engraved in our recorded data. ([Location 1960](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1960))
    - Tags: [[pink]] 
- The point is that our AI mirrors are nothing like neutral reflections of a shared human reality. They are very potent indicators of how a small subset of humans have seen and valued the world, and the marks they have left on it. For many reading this book, the reflections in AI mirrors will resemble something not too far from your own assumptions and value judgments about the world; what you see in them will be mostly comforting and familiar, even as they surprise and delight you with their power to speak without faces, or to write sonnets without hands. For most others, these reflections have a dimmer cast. Their voices speak a language that is not originally yours, or their patterns retrace a historical arc of devaluation and denigration by other humans who have chosen to see you and your kind as lesser. This character of AI mirrors can be immensely instructive: a powerful source of learning. Before you can change the arc of history, you have to study its pattern. Like Rumi’s mirror of the soul in his poem “Masnavi,” the surfaces of our AI mirrors are deeply rusted by our own histories of injustice and oppression. If we don’t see in them what we wish to see in ourselves, we must clear that rust away. The reflections in AI mirrors can therefore be a powerful driver of the changes needed to bring the human family back from the brink of our self-caused economic, geopolitical, and environmental crises. They can reveal subtle ([Location 1970](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1970))
    - Tags: [[pink]] 
- patterns that humans cannot otherwise see—or they can make undeniable the patterns we’ve been too ashamed or too comfortable to acknowledge. ([Location 1980](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=1980))
    - Tags: [[pink]] 
- The magnifying power of AI mirrors means that they have to be used with the expectation that they will amplify harmful patterns unless deliberately made to do otherwise. Because what will you get if you naively train an AI model on an unjust medical or financial or criminal justice system? An AI tool that calculates how to be even more efficient than people at delivering injustice. Countless other examples of algorithmic bias have manifested in AI mirrors, as we’ve already seen in Chapter 2. But it’s not only the newest and biggest AI tools that cause these harms. A simpler algorithmic mirror in the Netherlands forced the Dutch government to resign in 2021 when it was revealed that tens of thousands of families—disproportionately immigrants—had been unjustly accused by the algorithm of child benefits fraud. In that case—and in cases ([Location 2006](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2006))
    - Tags: [[pink]] 
- of similarly flawed fraud detection algorithms in the US, UK, and Australia—the high price that states and vendors paid in lawsuits and bad press was predictably dwarfed by the unfathomable price paid by the innocent: suicides, job losses, homelessness, and families ripped apart. In the Netherlands case, at least 1,675 children were taken from their parents, solely on the basis of a demonstrably flawed algorithm. Hundreds have still not been returned.2 ([Location 2012](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2012))
    - Tags: [[pink]] 
- Through the algorithmic feedback loops operating in the digital media spaces that have come to function as the new public square, AI mirrors amplify and normalize our biases, reinforce our most polarizing opinions and most aggressive stances, and boost the visibility of our most uninformed “hot takes.” In doing so they reflect back to us images of human civic agency so distorted in their form that they not only ([Location 2030](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2030))
    - Tags: [[pink]] 
- shift the “Overton windows” of acceptable political conduct but make us lose our already fragile faith in the human capacity for political wisdom. The result is that actual political behavior drifts closer and closer to the originally distorted mean, producing as a self-fulfilling prophecy the very reality that our distorted mirrors predicted. This is why it is so important—for purposes of both safety and transparency—that we know when our mirrors are distorting reality. There’s a very good reason that the distorting side mirror has a little warning engraved on it: “objects in mirror are closer than they appear.” In contrast, AI mirrors today are rarely tested rigorously to find the distortions they produce, and they almost always lack the safety and transparency signposts and guardrails we need. Until we demand these, it will be increasingly difficult to truly know ourselves. And when we can no longer know ourselves, we can no longer govern ourselves. In that moment, we will have surrendered our own agency, our collective human capacity for self-determination. Not because we won’t have it—but because we will not see it in the mirror. ([Location 2033](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2033))
    - Tags: [[pink]] 
- Moreover, the heart of creative work is not creation, but expression. To merely create is to bring into being what was not there before. It is now a fairly trivial operation for an AI model to “create” in this limited sense, by producing new variations on an existing data set. To express is different. To express is to bring into existence something that speaks of something else. An AI tool can create a new sea shanty or a new sculpture or a new abstract shape. But what can it express through these? To express is to have something inside oneself that needs to come out. It pushes its way out: of your mouth, your diaphragm, your gesture, your rhythmic sway. Or you pull it out—because it resists translation, resists articulation. A generative AI model has nothing it needs to say, only an instruction to add some statistical noise to bend an existing pattern in a new direction. It has no physical, emotional, or intellectual experience of the world or self to express. As long as we recognize and value the difference between mechanical creation and self-expression, AI poses no threat to human creativity or growth. ([Location 2069](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2069))
    - Tags: [[pink]] 
- Remember: the danger to our humanity from AI is not really coming from AI itself. The call is coming from inside the house; AI can devalue our humanity only because we already devalued it ourselves. ([Location 2083](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2083))
    - Tags: [[pink]] 
- Those responses perfectly fulfill the predictions of the author Neil Postman in his 1992 book Technopoly: The Surrender of Culture to Technology. Building on earlier insights by the French sociologist and philosopher Jacques Ellul, Postman observed that the dominance of a technopoly, a culture which “seeks its authorization in technology, finds its satisfactions in technology, and takes its orders from technology,” depends upon our willingness to believe “that we are at our best when we are acting like machines.”3 Implied by these beliefs, he remarked, “is a loss of confidence in human judgment and subjectivity.”4 Aiding and abetting this mechanistic diminution of the human personality, and its associated loss of self-confidence, is the capacity of AI mirrors to flatten ([Location 2091](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2091))
    - Tags: [[pink]] 
- and occlude our experience of one another, by projecting images of love and mutual care that have been stripped of their emotional and material depths. ([Location 2097](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2097))
    - Tags: [[pink]] 
- But I want to focus on another, far more seductive and subtle form of AI-enabled deception and manipulation, one that millions of humans increasingly welcome into their lives. Among the most widespread global applications of AI mirrors has been the chatbot. Generative AI tools turned the pale, awkward, scripted shadows of human companionship projected by early chatbot technology into what is today an increasingly powerful illusion of full emotional reciprocity. If you are inclined, like a postmodern Narcissus, to gaze into the shallow pools of ([Location 2105](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2105))
    - Tags: [[pink]] 
- mirrored love and warmth offered by Microsoft spinoff Xiaoice or Replika’s virtual AI companions, you will enjoy a far livelier conversation than Narcissus ever had with his “beautiful boy” in the water. ([Location 2109](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2109))
    - Tags: [[pink]] 
- Again, it is worth noting that this so-called loneliness epidemic has been observed to be most acute in some of the most technologically “advanced” countries on the planet, like Japan and the United States. Chatbots encapsulate our tendency to seek technical fixes for the social ills of modern digital life. Our hope, contrary to all available evidence, is that every problem created by technological alienation will be overcome by more and better technology. ([Location 2114](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2114))
    - Tags: [[pink]] 
- To guarantee users’ engagement and their willing surrender of personal data, these tools are designed to exploit one of two possible types of empathy. The first is the capacity to predict what emotion another is feeling, or will likely feel, if they are exposed to a particular situation or stimulus. The second one is the capacity to experience a sense of “co-feeling” with another human or other sentient being—to actually feel pained by the ([Location 2154](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2154))
    - Tags: [[pink]] 
- pain of others, joy at the sight of others’ joy. Sociopaths typically possess the first kind of empathy in spades; of the second, they know little or none. This combination is what makes the sociopath a master manipulator and deceiver of others. They can predict and exploit others’ feelings without being vulnerable to them. ([Location 2157](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2157))
    - Tags: [[pink]] 
- The language of self-interested economic exchange would suggest that this is a fool’s bargain. Why give away what I may then be denied in equivalent value? An AI chatbot provides love’s missing guarantee of the economic rationality of exchange. What I give away, I will get back—and more! If I am rude or irritable, my chatbot will not leave me for another, but return for more the next day. And if I am warm, kind, and solicitous to my chatbot, I will receive even greater emotional rewards in return, never a shrug or dismissal. Unless dismissal is what I want, because it will be a trivial matter to tune the algorithm’s performance to mirror a personality that is coy or distant, should I prefer a partner who “plays hard to get.” But of course, all of this means that I do not love, and am not loved, for love cannot be controlled in this way. The deepest lesson that love can teach us is simply inimical to the experience of a product user. ([Location 2170](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2170))
    - Tags: [[pink]] 
- The hollow projection of love in the chatbot’s AI mirror, when taken not as light entertainment or temporary balm but as a replacement or even a superior alternative to human love, is a calamity. ([Location 2186](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2186))
    - Tags: [[pink]] 
- That’s of course also the kind of love we find in the ideal of parenting. There are, roughly speaking, two main styles of parenting, and most people move between them. One involves training a small human to mirror yourself and the rules of your society, so that they exceed in achieving the same goals that you, and others like you, previously chose. We might call this “value alignment.” The other kind of parenting involves allowing a person to emerge. Ironically, a tweet by AI pioneer Geoff Hinton has described the training of an AI model by human feedback as “just parenting for a supernaturally precocious child.” It’s not a great metaphor for a lot of reasons. AI models are tunable mathematical matrixes; they bear less resemblance to your child than does your dog. But it’s also a grim celebration of the notion of parenting as value alignment. ([Location 2192](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2192))
    - Tags: [[pink]] 
- Indeed, the technique of reinforcement learning by human feedback (RLHF) is one tool for AI value alignment. “Alignment” in machine learning research and development means getting the model’s outputs to align with human values and expectations; ensuring that it will only seek to optimize the same goals that we do.12 Alignment is an important condition of the safety and trustworthiness of an AI model, although it’s far from sufficient for either of these. Alignment research yields a body of technique that Hinton and others rightfully recommend continuing to invest in. Alignment is also, at ([Location 2198](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2198))
    - Tags: [[pink]] 
- best, a half-measure of successful parenting of a human person. And when it’s the only kind of parenting we do, we fail. This is something I’m going to assume that Hinton knows. Yet the more that our language flattens the distinction between the mutuality of loving human bonds and the instrumental rationality of training machines, the more in danger we are of forgetting our capacity for the former. It’s no surprise, then, that along with the rapid expansion of reliance on AI chatbots for social companionship and romantic satisfaction, we are witnessing an explosion of new applications for “parenting by AI.” ([Location 2203](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2203))
    - Tags: [[pink]] 
- Sam Altman, CEO and co-founder of OpenAI, has said, “we can make GPT systems that will be way less biased than humans . . . because there won’t be that emotional load there.”16 Making AI systems less biased is a worthy goal. But the clear implication is that the effort to make humans less ([Location 2235](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2235))
    - Tags: [[pink]] 
- biased is not. This is the same man who in 2017, long before he shepherded GPT into our lives, saw only two options for humanity’s future. He wrote in his blog that we can either be the “biological bootloader” for AI and then fade into evolutionary irrelevance, or we can “merge” our humanity into the machines, since there is no hope to remain ourselves. He confidently predicted we’ll choose the latter, since at least this lets us share in the sole purpose of existing: “to be the dominant species on the planet and beyond.”17 In fact, he tells us, the merge has already begun: “Our phones control us and tell us what to do when; social media feeds determine how we feel; search engines decide what we think.” This is like your drug dealer telling you that since your heroin addiction has already destroyed your personality, agency, hopes, and potential, you might as well quit fighting and go along for the ride. As Rumi says, if we look into the mirror of our humanity and see nothing, it’s not because there’s nothing there to see—it’s because we have not yet cleared away the rust. ([Location 2238](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2238))
    - Tags: [[pink]] 
- Why is it so hard for us to know who we are? Perhaps because it’s not easy to like who we are. When we look in the mirror of recorded human history, we find a reflection of our worst impulses, magnified by the tendency of our news editors and historians to tell the stories of the worst among us. We are drawn by perverse fascination as well as evolutionary need to know the depths of our own horrors, and since that’s what mostly sells, that’s what we mostly get. AI mirrors, which are trained on that same record, are likely to reinforce this selective, cynical, and backward-looking estimation of humanity’s own worth if we use them without care, governed only by the incentives of our existing media ecosystem. This is particularly dangerous given the number of Silicon Valley billionaires and politically influential longtermist philosophers who think that the fruitful multiplication of intelligent, ([Location 2279](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2279))
    - Tags: [[pink]] 
- benevolent machines bearing “digital consciousnesses” might be a worthier goal for the future than sustaining a world for imperfect people. After all, they might tell us, humanity has had its chance. ([Location 2285](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2285))
    - Tags: [[pink]] 
- AI systems for natural language processing are powerful tools for helping us analyze our media environment and identifying or even correcting its distortions and occlusions, while also raising back to prominence the most urgent and salient stories we can act on. Paired with different incentives than drive their media use today, we can use AI tools to help us clear the rust from the mirror. ([Location 2291](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2291))
    - Tags: [[pink]] 
- Creative expression is not mere pattern-breaking, however. It’s not just a production of novelty. Novelty is a trivial task for a generative AI system; add a random noise generator, or some other source of perturbation of the data, and the output of the model will break the original pattern. One can even build into the system another model to evaluate and reward the change, based on human feedback that rejects nonsensical output. This is in fact exactly how many of today’s generative AI tools work. It’s why when you ask a generative AI system to write you an essay or draw you a picture based on your prompt, you’ll get slightly different results each time—variations on a theme. And you can tune the system to be more or less wild in its variations. ([Location 2337](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2337))
    - Tags: [[pink]] 
- We look at the present through a rear-view mirror. We march backwards into the future. —Marshall McLuhan and Quentin Fiore, The Medium Is the Massage (1967) ([Location 2355](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2355))
    - Tags: [[pink]] 
- Technologists themselves are not immune to this distrust. In the wake of corporate scandals, such as Google’s firing of pioneering AI ethics leaders Timnit Gebru and Meg Mitchell, and amid continued discrimination and abuse of women and other marginalized groups within many computing communities (all while fighting a seemingly endless tide of morally and scientifically discreditable uses of AI tools), AI researchers are, in many communities, demoralized, divided, and distrustful of their own. As one study found of the efforts of “Responsible AI” and AI ethics teams inside large companies, even those who try to make change from within the most powerful centers of the AI ecosystem often suffer from tepid leadership support, diminished status, harmful power differentials, and misaligned incentives.9 ([Location 2529](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2529))
    - Tags: [[pink]] 
- The point is not to paint today’s computing and engineering professionals as ignorant or ill-equipped. The point is that the ground under the feet of many of today’s engineers and technologists has shifted radically, and educational institutions have hardly taken stock, much less adequately responded to this shift. If we imagine that today’s AI developers and engineers can meet their vastly enlarged professional responsibilities to the public by taking a well-taught course in engineering or computing ethics—an intervention which was welcome yet hardly sufficient even in the 1990s—we are offering a dangerously diluted remedy. And the welfare of present and future generations is already suffering for it. ([Location 2566](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2566))
    - Tags: [[pink]] 
- The moral expectations increasingly placed upon technologists today could arguably only be met by moral exemplars of human practical wisdom—those Aristotle called the phronomoi.10 As we have said, practical wisdom or phrónēsis is essential for moral reasoning and judgment about actions that are very challenging to get right. Ordinary moral life does not always demand the full exercise of phrónēsis to do the right thing, given that social conventions, laws, customs, and habits often steer us well without having to deliberate with great care. It does not require much in the way of practical wisdom, for example, for an engineer to avoid stealing and selling their employer’s property or proprietary secrets, or to refuse a bribe from their client to falsify a safety certificate. Ordinary virtues of honesty and integrity will suffice. While these virtues are not universally possessed (and there are plenty of incentives to abandon them), such ordinary excellences are an entirely reasonable standard to ask any technology professional to meet. But these standards are no longer sufficient. ([Location 2582](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2582))
    - Tags: [[pink]] 
- And these are garden-variety challenges for today’s AI professionals—not exotic edge cases, and not the dizzying conundrums that come from proposals to design brain-computer interfaces that read minds, or to create machines with artificial moral agency. In our current environment, all of this means that AI professionals are arguably being set up for moral and social failure. And this does not yet touch the bootstrapping problem that runs deeper still—that the patterns of moral and technical excellence we have long celebrated, the ones we find in our most visible exemplars of virtue, have become maladapted and need radical reform. Where can we find the creative moral intelligence to chart that new course? ([Location 2597](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2597))
    - Tags: [[pink]] 
- In a leaky lifeboat with a violent storm approaching, no proposal of the passengers is idealistic or naive if it is the only feasible way to bring the boat to shore. ([Location 2621](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2621))
    - Tags: [[pink]] 
- Another version of the ubiquitous “excellence” motivational poster attributes to Confucius a suspiciously contemporary-sounding message: “the will to win, the desire to succeed, the urge to reach your full potential, these are the keys that will unlock the door to personal excellence.” It will not surprise you that none of the many attributions of this claim to Confucius—which you can purchase printed on notebooks, coffee cups, and mouse pads—are accompanied by a source text citation. This poster image shows a goldfish leaping from a bowl containing several other fish to a larger, empty one. The “excellent” fish is the one that leaves the rest of the fish behind, crowded in the smallest bowl, while it alone enjoys the enlargement of its freedom by excellence. An aspiring space colonist billionaire would be proud to hang it, I am sure. ([Location 2644](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2644))
    - Tags: [[pink]] 
- I’ll say it again: AI is not the problem here. The problem is our unwillingness to step back from our tools to reevaluate the patterns they are reproducing—even the supposedly virtuous ones. Which of the widely celebrated virtues most likely to be reflected in our AI mirrors might in fact be traps? Which of them function as the moral equivalent of cement shoes, dragging us into the depths of old and unsustainable patterns, rather than freeing us to alter our familiar habits and values, or reconfigure them to our current needs? ([Location 2669](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2669))
    - Tags: [[pink]] 
- For most of us, “doing your own research” in such domains leads us down a path to utter confusion or worse—to guzzling horse dewormer. But that’s what we’ve used AI primarily to enable, not more informed assessments of specialist expertise, or even the intellectual modesty of humble questioning and listening. We don’t want to be patient, receptive learners. We want to be bold, brave, independent thinkers! Today, ChatGPT feeds us all the bullshit we need to sound like confident intellectual mavericks, without us ever reexamining that ideal. Consider another greatly admired virtue of the motivational poster: perseverance. Among the most cherished modern mantras of leadership and personal excellence has been the disposition to keep going, to not give up, to ensure hardship and always push on. Where does that virtue leave us today? It leaves us in a world where those in positions of power and comfort are driven to press on with calamitous endeavors no matter the cost—whether it be a futile war in Ukraine, a Tesla autopilot feature that years later still can’t avoid a parked ([Location 2681](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2681))
    - Tags: [[pink]] 
- fire truck, or a social network that degrades the pillars of democracy further every day. But people like Mark Zuckerberg and Elon Musk have learned the virtue of perseverance. They will “do better”! They will make it right, they will make it all work—one day. They believe that we will one day admire them for not giving up. Aren’t they right to expect that? What if they were to surrender their platform business models, defying investors and pulling apart the harmful mechanisms upon which twenty-first-century social and political life has been reconstructed? Or finding that too hard, what if they just admitted failure and walked away? The pilot of industry who turns the plane back will be judged a bigger loser than the one who flies it at full speed into the ground. They’ll be laughed at even by their harshest critics who want them to walk away. We don’t know what virtuous giving up looks like. We will never see that virtue in our AI mirrors, because it’s not part of our existing moral vocabulary. (No poster ever said, “Give up if it’s just not working!”) But maybe it needs to be in our vocabulary. Maybe the world would be in a better state if we had a name for that virtue. Our habitual, uncritical valorization of the virtue of perseverance arguably serves the poor and oppressed today no better than the powerful. Stoically putting one foot in front of another in a system that’s killing you is simply walking into your grave. On that point, take our present way of characterizing those who do not accept the present for what it is, those who refuse to keep their ([Location 2688](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2688))
    - Tags: [[pink]] 
- noses to the grind, who reject their elders’ advice to work harder and smarter, heads down and uncomplaining. When we see young people in the streets, violating curfews to protest racial injustice and authoritarian regimes, or boycotting their classes to loudly demand climate action to preserve their… ([Location 2700](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2700))
    - Tags: [[pink]] 
- We must break out of what Ellul called a “closed circle” of technical values—and simply building more and more powerful AI mirrors will not help us do it. If anything, ([Location 2721](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2721))
    - Tags: [[pink]] 
- these mirrors will ensure that our moral languages and moral visions remain focused precisely where they have been for the entirety of the industrial and electronic ages, which hold the oceans of cultural byproduct that we have been slavishly collecting and digitizing to feed to these mirrors as training data. These mirrors will undoubtedly improve in their apparent “moral performance,” which only means that they will learn to more reliably reflect our moral comfort zones while filtering out any lingering evidence of our unreformed sins and unchallenged biases. Then, it will be even harder than it is now to recognize what is wrong with or missing from the moral images these mirrors mindlessly reflect back to us, since they will serve us precisely those images that we already find most familiar, reassuring, and true. This is also why the common trope of “value alignment” as a strategy for managing AI risk and making AI more “ethical” or “responsible” is so dangerous. It sounds so obviously right! Of course we want AI to be aligned with human values, with “our” values (an equation which is already a dangerous error). But remember Ellul’s warning, written seven decades before the commercial takeoff of artificial intelligence technologies. Human values have already long been aligned with a global sociotechnical order, a system of efficiency and productive control that has for decades rewarded and praised the virtues of those of us who made ourselves work with and for the system, and punished those who would not or could not. ([Location 2723](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2723))
    - Tags: [[pink]] 
- For now we see in a mirror, dimly, but then face to face. Now I know in part, but then I shall know just as I also am known. —Corinthians 13:12 ([Location 2817](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2817))
    - Tags: [[pink]] 
- The preceding chapters tell a story about giant mirrors made of code, built to consume our words, our decisions, our art, our expressions of love and care, then reflect them back to us. These mirrors know no more of the lived experience of thinking and feeling than our bedroom mirrors know our inner aches and pains. Yet AI mirrors do something that our bedroom mirrors don’t: they store and pool all that they capture from us, analyze its dominant patterns, and from these reanimate our living forms in new reflections of speech, image, and action. It’s as if the reflected images in our bedroom mirrors were to keep moving and posing after we turned away. ([Location 2820](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2820))
    - Tags: [[pink]] 
- Such a trick might fool any of us into thinking there must be a second someone there, another body, dancing in a mysterious dimension just on the other side of the looking glass—like Narcissus’s “beautiful boy.” Yet, as we saw in Chapter 1, a mirror image, moving or not, is not a body—it lacks a body’s weight, depth, warmth, tension, shivers, scent, and force. In the same way, a mirror image of a mind, even one extrapolated from the reflection of many minds, is not a mind. But the power of the machine mirror illusion is many magnitudes greater than those cast by glass—and growing. Indeed, it will soon be nearly impossible in many contexts for us to tell the difference between ourselves and our reflections. That is the deeper existential danger of AI mirrors for any human being, because being human is always already a lifelong struggle to know who and what you are. ([Location 2825](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2825))
    - Tags: [[pink]] 
- We can live in bad faith and deny this, and most of us do live in bad faith, most of the time. We tell ourselves we just do what we have to. We tell ourselves that at the end of the day we had no options. Life is too hard. Don’t think about it too much. Choice is an illusion. Freedom is a fantasy. Imagination is for children. We are what we are. It is what it is. Or, “How much difference is there between a human person and a mathematical next-token generator, really?” The threat to humanity from AI systems is indeed existential. It’s just a different kind of “existential” than what’s being marketed today by the merchants of AI doom. As we noted in the opening chapter, what AI puts in greatest jeopardy is not our species’ bare survival, but our self-understanding of perpetual freedom and responsibility. The most plausible existential danger is not a genocidal machine oppressor but the annihilation of human moral confidence and ambition to transcend genocide and oppression ourselves. ([Location 2837](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=2837))
    - Tags: [[pink]] 
- Instead of magnifying the things that humans most easily want (ego gratification, attention, a sense of tribal belonging, the dopamine hit of showing that someone on the Internet is wrong), AI mirrors can be tuned to help us narrow the gaps between what we need and what others have the resources or skills to give us. One example of this is a growing gap between the speed at which new research is generated, and the speed at which it can be translated and summarized for policymakers, practitioners, and lay audiences. ([Location 3095](https://readwise.io/to_kindle?action=open&asin=B0CW1F7MBQ&location=3095))
    - Tags: [[pink]]

