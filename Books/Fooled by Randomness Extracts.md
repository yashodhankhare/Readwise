---
tags:
  - readwise
---

# Fooled by Randomness Extracts

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/default-book-icon-7.09749d3efd49.png)

## Metadata
- Author: [[Yashodhan Khare ]]
- Full Title: Fooled by Randomness Extracts
- Category: #books

## Highlights
- Problem of Stationarity
  # Why Don’t Statisticians Detect Rare Events?
  Suppose I am drawing from an urn containing red and black balls. My confidence level about the relative proportion of red and black balls after 20 drawings is not twice the one I have after 10 drawings; it is merely multiplied by the square root of 2 (that is, 1.41). Where statistics becomes complicated, and fails us, is when we have distributions that are not symmetric, like the urn above. If there is a very small probability of finding a red ball in an urn dominated by black ones, then our knowledge about the absence of red balls will increase very slowly—more slowly than at the expected square root of n rate. On the other hand, our knowledge of the presence of red balls will dramatically improve once one of them is found. This asymmetry in knowledge is not trivial; it is central in this book—it is a central philosophical problem for such people as the ancient skeptics David Hume and Karl Popper (on that, later). To assess an investor’s performance, we either need more astute, and less intuitive, techniques or we may have to limit our assessments to situations where our judgment is independent of the frequency of these events. 
  # A Mischievous Child Replaces the Black Balls
  But there is even worse news. In some cases, if the incidence of red balls is itself randomly distributed, we will never get to know the composition of the urn. This is called “the problem of stationarity.” Think of an urn that is hollow at the bottom. As I am sampling from it, and without my being aware of it, some mischievous child is adding balls of one color or another. My inference thus becomes insignificant. I may infer that the red balls represent 50% of the urn while the mischievous child, hearing me, would swiftly replace all the red balls with black ones. This makes much of our knowledge derived through statistics quite shaky. The very same effect takes place in the market. We take past history as a single homogeneous sample and believe that we have considerably increased our knowledge of the future from the observation of the sample of the past. What if vicious children were changing the composition of the urn? In other words, what if things have changed?
- :Nobody Has to Be Competent::
  Let’s push the argument further to make it more interesting. We create a cohort that is composed exclusively of incompetent managers. We will define an incompetent manager as someone who has a negative expected return, the equivalent of the odds being stacked against him. We instruct the Monte Carlo generator now to draw from an urn. The urn has 100 balls, 45 black and 55 red. By drawing with replacement, the ratio of red to black balls will remain the same. If we draw a black ball, the manager will earn $10,000. If we draw a red ball, he will lose $10,000. The manager is thus expected to earn $10,000 with 45% probability, and lose $10,000 with 55%. On average, the manager will lose $1,000 each round—but only on average. 
  At the end of the first year, we still expect to have 4,500 managers turning a profit (45% of them), the second, 45% of that number, 2,025. The third, 911; the fourth, 410; the fifth, 184. Let us give the surviving managers names and dress them in business suits. True, they represent less than 2% of the original cohort. But they will get attention. Nobody will mention the other 98%.What can we conclude? 
  > The first counterintuitive point is that a population entirely composed of bad managers will produce a small amount of great track records. As a matter of fact, assuming the manager shows up unsolicited at your door, it will be practically impossible to figure out whether he is good or bad. The results would not markedly change even if the population were composed entirely of managers who are expected in the long run to lose money. Why? Because owing to volatility, some of them will make money. We can see here that volatility actually helps bad investment decisions.
  > The second counterintuitive point is that the expectation of the maximum of track records, with which we are concerned, depends more on the size of the initial sample than on the individual odds per manager. In other words, the number of managers with great track records in a given market depends far more on the number of people who started in the investment business (in place of going to dental school), rather than on their ability to produce profits. It also depends on the volatility. Why do I use the notion of expectation of the maximum? Because I am not concerned at all with the average track record. I will get to see only the best of the managers, not all of the managers. This means that we would see more “excellent managers” in 2006 than in 1998, provided the cohort of beginners was greater in 2001 than it was in 1993—I can safely say that it was.
- Skill V/S Luck
  Let us use the Monte Carlo generator introduced earlier and construct a population of 10,000 fictional investment managers (the generator is not terribly necessary since we can use a coin, or even do plain algebra, but it is considerably more illustrative—and fun). Assume that they each have a perfectly fair game; each one has a 50% probability of making $10,000 at the end of the year, and a 50% probability of losing $10,000. Let us introduce an additional restriction; once a manager has a single bad year, he is thrown out of the sample, good-bye and have a nice life. Thus we will operate like the legendary speculator George Soros who was said to tell his managers gathered in a room: “Half of you guys will be out by next year” (with an Eastern European accent). Like Soros, we have extremely high standards; we are looking only for managers with an unblemished record. We have no patience for low performers. 
  The Monte Carlo generator will toss a coin; heads and the manager will make $10,000 over the year, tails and he will lose $10,000. We run it for the first year. At the end of the year, we expect 5,000 managers to be up $10,000 each, and 5,000 to be down $10,000. Now we run the game a second year. Again, we can expect 2,500 managers to be up two years in a row; another year, 1,250; a fourth one, 625; a fifth, 313. We have now, simply in a fair game, 313 managers who made money for five years in a row. Out of pure luck. 
  Meanwhile if we throw one of these successful traders into the real world we would get very interesting and helpful comments on his remarkable style, his incisive mind, and the influences that helped him achieve such success. Some analysts may attribute his achievement to precise elements among his childhood experiences. His biographer will dwell on the wonderful role models provided by his parents; we would be supplied with black-and-white pictures in the middle of the book of a great mind in the making. And the following year, should he stop outperforming (recall that his odds of having a good year have stayed at 50%) they would start laying blame, finding fault with the relaxation in his work ethics, or his dissipated lifestyle. They will find something he did before when he was successful that he has subsequently stopped doing, and attribute his failure to that. The truth will be, however, that he simply ran out of luck.
- Luck v/s Skill
  Let us use the Monte Carlo generator introduced earlier and construct a population of 10,000 fictional investment managers (the generator is not terribly necessary since we can use a coin, or even do plain algebra, but it is considerably more illustrative—and fun). Assume that they each have a perfectly fair game; each one has a 50% probability of making $10,000 at the end of the year, and a 50% probability of losing $10,000. Let us introduce an additional restriction; once a manager has a single bad year, he is thrown out of the sample, good-bye and have a nice life. Thus we will operate like the legendary speculator George Soros who was said to tell his managers gathered in a room: “Half of you guys will be out by next year” (with an Eastern European accent). Like Soros, we have extremely high standards; we are looking only for managers with an unblemished record. We have no patience for low performers. 
  The Monte Carlo generator will toss a coin; heads and the manager will make $10,000 over the year, tails and he will lose $10,000. We run it for the first year. At the end of the year, we expect 5,000 managers to be up $10,000 each, and 5,000 to be down $10,000. Now we run the game a second year. Again, we can expect 2,500 managers to be up two years in a row; another year, 1,250; a fourth one, 625; a fifth, 313. We have now, simply in a fair game, 313 managers who made money for five years in a row. Out of pure luck. 
  Meanwhile if we throw one of these successful traders into the real world we would get very interesting and helpful comments on his remarkable style, his incisive mind, and the influences that helped him achieve such success. Some analysts may attribute his achievement to precise elements among his childhood experiences. His biographer will dwell on the wonderful role models provided by his parents; we would be supplied with black-and-white pictures in the middle of the book of a great mind in the making. And the following year, should he stop outperforming (recall that his odds of having a good year have stayed at 50%) they would start laying blame, finding fault with the relaxation in his work ethics, or his dissipated lifestyle. They will find something he did before when he was successful that he has subsequently stopped doing, and attribute his failure to that. The truth will be, however, that he simply ran out of luck.
- ::Regression to the Mean::
  The “hot hand in basketball” is another example of misperception of random sequences: It is very likely in a large sample of players for one of them to have an inordinately lengthy lucky streak. As a matter of fact it is very unlikely that an unspecified player somewhere does not have an inordinately lengthy lucky streak. This is a manifestation of the mechanism called regression to the mean. I can explain it as follows: 
  > Generate a long series of coin flips producing heads and tails with 50% odds each and fill up sheets of paper. If the series is long enough you may get eight heads or eight tails in a row, perhaps even ten of each. Yet you know that in spite of these wins the conditional odds of getting a head or a tail is still 50%. Imagine these heads and tails as monetary bets filling up the coffers of an individual. The deviation from the norm as seen in excess heads or excess tails is here entirely attributable to luck, in other words, to variance, not to the skills of the hypothetical player (since there is an even probability of getting either). 
  > A result is that in real life, the larger the deviation from the norm, the larger the probability of it coming from luck rather than skills: Consider that even if one has 55% probability of heads, the odds of ten wins is still very small. This can be easily verified in stories of very prominent people in trading rapidly reverting to obscurity, like the heroes I used to watch in trading rooms. This applies to height of individuals or the size of dogs. In the latter case, consider that two average-sized parents produce a large litter. The largest dogs, if they diverge too much from the average, will tend to produce offspring of smaller size than themselves, and vice versa. This “reversion” for the large outliers is what has been observed in history and explained as regression to the mean. Note that the larger the deviation, the more important its effect. 
  > Again, one word of warning: All deviations do not come from this effect, but a disproportionately large proportion of them do.
- ::Ergodicity::
  To get more technical, I have to say that people believe that they can figure out the properties of the distribution from the sample they are witnessing. When it comes to matters that depend on the maximum, it is altogether another distribution that is being inferred, that of the best performers. We call the difference between the average of such distribution and the unconditional distribution of winners and losers the survivorship bias—here the fact that about 3% of the initial cohort discussed earlier will make money five years in a row. **In addition, this example illustrates the properties of ergodicity, namely, that time will eliminate the annoying effects of randomness.** Looking forward, in spite of the fact that these managers were profitable in the past five years, we expect them to break even in any future time period. They will fare no better than those of the initial cohort who failed earlier in the exercise. Ah, the long term. 
  > A few years ago, when I told one A., a then Master-of-the-Universe type, that track records were less relevant than he thought, he found the remark so offensive that he violently flung his cigarette lighter in my direction. The episode taught me a lot. Remember that nobody accepts randomness in his own success, only his failure. His ego was pumped up as he was heading up a department of “great traders” who were then temporarily making a fortune in the markets and attributing the idea to the soundness of their business, their insights, or their intelligence. They subsequently blew up during the harsh New York winter of 1994 (it was the bond market crash that followed the surprise interest rate hike by Alan Greenspan). The interesting part is that several years later I can hardly find any of them still trading (ergodicity). 
  > Recall that the survivorship bias depends on the size of the initial population. The information that a person derived some profits in the past, just by itself, is neither meaningful nor relevant. We need to know the size of the population from which he came. In other words, without knowing how many managers out there have tried and failed, we will not be able to assess the validity of the track record. If the initial population includes ten managers, then I would give the performer half my savings without a blink. If the initial population is composed of 10,000 managers, I would ignore the results. The latter situation is generally the case; these days so many people have been drawn to the financial markets. Many college graduates are trading as a first career, failing, then going to dental school.
- ::BackTesting:: 
  A programmer helped me build a back tester. It is a software program connected to a database of historical prices, which allows me to check the hypothetical past performance of any trading rule of average complexity. I can just apply a mechanical trading rule, like buy NASDAQ stocks if they close more than 1.83% above their average of the previous week, and immediately get an idea of its past performance. The screen will flash my hypothetical track record associated with the trading rule. If I do not like the results, I can change the percentage to, say, 1.2%. I can also make the rule more complex. I will keep trying until I find something that works well. 
  What am I doing? The exact same task of looking for the survivor within the set of rules that can possibly work. I am fitting the rule on the data. This activity is called data snooping. The more I try, the more I am likely, by mere luck, to find a rule that worked on past data. A random series will always present some detectable pattern. I am convinced that there exists a tradable security in the Western world that would be 100% correlated with the changes in temperature in Ulan Bator, Mongolia.
- ::Comparative Luck::
  A far more acute problem relates to the outperformance, or the comparison, between two or more persons or entities. While we are certainly fooled by randomness when it comes to a single times series, the foolishness is compounded when it comes to the comparison between, say, two people, or a person and a benchmark. Why? Because both are random. Let us do the following simple thought experiment. Take two individuals, say, a person and his brother-in-law, launched through life. Assume equal odds for each of good and bad luck. Outcomes: lucky-lucky (no difference between them), unlucky-unlucky (again, no difference), lucky-unlucky (a large difference between them), unlucky-lucky (again, a large difference). simulator). The problem is that they did not want these tables to exhibit any form of regularity. Yet real randomness does not look random!
- ::Professor Pearson Goes to Monte Carlo (Literally):::
  **Randomness Does Not Look Random!** 
  - At the beginning of the twentieth century, as we were starting to develop techniques to deal with the notion of random outcomes, several methods were designed to detect anomalies. Professor Karl Pearson (father of Egon Pearson of Neyman-Pearson fame, familiar to every person who sat in a statistics 101 class) devised the first test of non-randomness (it was in reality a test of deviation from normality, which, for all intents and purposes, was the same thing). He examined millions of runs of what was called a Monte Carlo (the old name for a roulette wheel) during the month of July 1902. He discovered that, with a high degree of statistical significance (with an error of less than one to a billion), the runs were not purely random. What! The roulette wheel was not random! Professor Pearson was greatly surprised at the discovery. But this result in itself tells us nothing; we know that there is no such thing as a pure random draw, for the outcome of the draw depends on the quality of the equipment. With enough minutiae one would be able to uncover the non-randomness somewhere (e.g., the wheel itself may not have been perfectly balanced or perhaps the spinning ball was not completely spherical). 
  - Philosophers of statistics call this the reference case problem to explain that there is no true attainable randomness in practice, only in theory. Besides, a manager would question whether such non-randomness can lead to any meaningful, profitable rules. If I need to gamble $1 on 10,000 runs and expect to make $1 for my efforts, then I would do much better in the part-time employment of a janitorial agency.
  - But the result bears another suspicious element. Of more practical relevance here is the following severe problem about non-randomness. Even the fathers of statistical science forgot that a random series of runs need not exhibit a pattern to look random; as a matter of fact, data that is perfectly patternless would be extremely suspicious and appear to be man-made. A single random run is bound to exhibit some pattern—if one looks hard enough. Note that Professor Pearson was among the first scholars who were interested in creating artificial random data generators, tables one could use as inputs for various scientific and engineering simulations (the precursors of our Monte Carlo
- # Non-Linearity
  - In time—and much to the onlooking child’s delight—my castle inevitably topples to rejoin the rest of the sand on the beach. It could be said that the last grain of sand is responsible for the destruction of the entire structure. What we are witnessing here is a nonlinear effect resulting from a linear force exerted on an object. A very small additional input, here the grain of sand, caused a disproportionate result, namely the destruction of my starter Tower of Babel. Popular wisdom has integrated many such phenomena, as witnessed by such expressions as “the straw that broke the camel’s back” or “the drop that caused the water to spill.” 
  - These nonlinear dynamics have a bookstore name, “chaos theory,” which is a misnomer because it has nothing to do with chaos. Chaos theory concerns itself primarily with functions in which a small input can lead to a disproportionate response. Population models, for instance, can lead to a path of explosive growth, or extinction of a species, depending on a very small difference in the population at a starting point in time. Another popular scientific analogy is the weather, where it has been shown that a simple butterfly fluttering its wings in India can cause a hurricane in New York. But the classics have their share to offer as well: Pascal (he of the wager in Chapter 7) said that if Cleopatra’s nose had been slightly shorter, the world’s fate would have changed. Cleopatra had comely features dominated by a thin and elongated nose that made Julius Caesar and his successor, Marc Antony, fall for her (here the intellectual snob in me cannot resist dissenting against conventional wisdom; Plutarch claimed that it was Cleopatra’s skills in conversation, rather than her good looks, that caused the maddening infatuation of the shakers and movers of her day; I truly believe it).
- # MATHEMATICS INSIDE AND OUTSIDE THE REAL WORLD 
  - A mathematical approach to the problem is in order. While in conventional models (such as the well-known Brownian random walk used in finance) the probability of success does not change with every incremental step, only the accumulated wealth, Arthur suggests models such as the Polya process, which is mathematically very difficult to work with, but can be easily understood with the aid of a Monte Carlo simulator. The Polya process can be presented as follows: Assume an urn initially containing equal quantities of black and red balls. You are to guess each time which color you will pull out before you make the draw. Here the game is rigged. Unlike a conventional urn, the probability of guessing correctly depends on past success, as you get better or worse at guessing depending on past performance. Thus, the probability of winning increases after past wins, that of losing increases after past losses. Simulating such a process, one can see a huge variance of outcomes, with astonishing successes and a large number of failures (what we called skewness). 
  - Compare such a process with those that are more commonly modeled, that is, an urn from which the player makes guesses with replacement. Say you played roulette and won. Would this increase your chances of winning again? No. In a Polya process case, it does. Why is this so mathematically hard to work with? Because the notion of independence (i.e., when the next draw does not depend on past outcomes) is violated. Independence is a requirement for working with the (known) math of probability. 
  - What has gone wrong with the development of economics as a science? Answer: There was a bunch of intelligent people who felt compelled to use mathematics just to tell themselves that they were rigorous in their thinking, that theirs was a science. Someone in a great rush decided to introduce mathematical modeling techniques (culprits: Leon Walras, Gerard Debreu, Paul Samuelson) without considering the fact that either the class of mathematics they were using was too restrictive for the class of problems they were dealing with, or that perhaps they should be aware that the precision of the language of mathematics could lead people to believe that they had solutions when in fact they had none (recall Popper and the costs of taking science too seriously). Indeed the mathematics they dealt with did not work in the real world, possibly because we needed richer classes of processes—and they refused to accept the fact that no mathematics at all was probably better. 
  - The so-called complexity theorists came to the rescue. Much excitement was generated by the works of scientists who specialized in nonlinear quantitative methods—the mecca of those being the Santa Fe Institute near Santa Fe, New Mexico. Clearly these scientists are trying hard, and providing us with wonderful solutions in the physical sciences and better models in the social siblings (though nothing satisfactory there yet). And if they ultimately do not succeed, it will simply be because mathematics may be of only secondary help in our real world. Note another advantage of Monte Carlo simulations is that we can get results where mathematics fails us and can be of no help. In freeing us from equations it frees us from the traps of inferior mathematics. As I said in Chapter 3, mathematics is merely a way of thinking and meditating, little more, in our world of randomness.
  ::The Science of Networks::
  - Why does the Internet hub Google get so many hits as compared to that of the National Association of Retired Veteran Chemical Engineers? The more connected a network, the higher the probability of someone hitting it and the more connected it will be, especially if there is no meaningful limitation on such capacity.
  ::Our Brain:: 
  - Our brain is not cut out for nonlinearities. People think that if, say, two variables are causally linked, then a steady input in one variable should always yield a result in the other one. Our emotional apparatus is designed for linear causality. For instance, you study every day and learn something in proportion to your studies. If you do not feel that you are going anywhere, your emotions will cause you to become demoralized. But reality rarely gives us the privilege of a satisfying linear positive progression: You may study for a year and learn nothing, then, unless you are disheartened by the empty results and give up, something will come to you in a flash. My partner Mark Spitznagel summarizes it as follows: Imagine yourself practicing the piano every day for a long time, barely being able to perform “Chopsticks,” then suddenly finding yourself capable of playing Rachmaninov. Owing to this nonlinearity, people cannot comprehend the nature of the rare event. This summarizes why there are routes to success that are nonrandom, but few, very few, people have the mental stamina to follow them. Those who go the extra mile are rewarded. In my profession one may own a security that benefits from lower market prices, but may not react at all until some critical point. Most people give up before the rewards.
- ::Buridan’s Donkey or the Good Side of Randomness:: 
  - Nonlinearity in random outcomes is sometimes used as a tool to break stalemates. Consider the problem of the nonlinear nudge. Imagine a donkey equally hungry and thirsty placed at exactly equal distance from sources of food and water. In such a framework, he would die of both thirst and hunger as he would be unable to decide which one to get to first. Now inject some randomness in the picture, by randomly nudging the donkey, causing him to get closer to one source, no matter which, and accordingly away from the other. The impasse would be instantly broken and our happy donkey will be either in turn well fed then well hydrated, or well hydrated then well fed. 
  - The reader no doubt has played a version of Buridan’s donkey, by “flipping a coin” to break some of the minor stalemates in life where one lets randomness help with the decision process. Let Lady Fortuna make the decision and gladly submit. I often use Buridan’s donkey (under its mathematical name) when my computer goes into a freeze between two possibilities (to be technical, these “randomizations” are frequently done during optimization problems, when one needs to perturbate a function). Note that Buridan’s donkey was named after the fourteenth-century philosopher Jean Buridan. Buridan had an interesting death (he was thrown in the Seine tied in a bag and died drowning). This tale was considered an example of sophistry by his contemporaries who missed the import of randomization—Buridan was clearly ahead of his time.
- # WHEN IT RAINS, IT POURS 
  - As I am writing these lines, I am suddenly realizing that the world’s bipolarity is hitting me very hard. Either one succeeds wildly, by attracting all the cash, or fails to draw a single penny. Likewise with books. Either everyone wants to publish it, or nobody is interested in returning telephone calls (in the latter case my discipline is to delete the name from my address book). I am also realizing the nonlinear effect behind success in anything: It is better to have a handful of enthusiastic advocates than hordes of people who appreciate your work—better to be loved by a dozen than liked by the hundreds. This applies to the sales of books, the spread of ideas, and success in general and runs counter to conventional logic. The information age is worsening this effect. This is making me, with my profound and antiquated Mediterranean sense of metron (measure), extremely uncomfortable, even queasy. Too much success is the enemy (think of the punishment meted out on the rich and famous); too much failure is demoralizing. I would like the option of having neither.
- ::Learning to Type::
  Researchers frequently use the example of QWERTY to describe the vicious dynamics of winning and losing in an economy, and to illustrate how the final outcome is more than frequently the undeserved one. The arrangement of the letters on a typewriter is an example of the success of the least deserving method. For our typewriters have the order of the letters on their keyboard arranged in a non-optimal manner, as a matter of fact in such a non-optimal manner as to slow down the typing rather than make the job easy, in order to avoid jamming the ribbons as they were designed for less electronic days. Therefore, as we started building better typewriters and computerized word processors, several attempts were made to rationalize the computer keyboard, to no avail. People were trained on a QWERTY keyboard and their habits were too sticky for change. Just like the helical propulsion of an actor into stardom, people patronize what other people like to do. Forcing rational dynamics on the process would be superfluous, nay, impossible. This is called a path dependent outcome, and has thwarted many mathematical attempts at modeling behavior.

