---
tags:
  - readwise
---

# Safe Haven

![rw-book-cover](https://m.media-amazon.com/images/I/41YhWGesAtL._SY160.jpg)

## Metadata
- Author: [[Mark Spitznagel and Nassim Nicholas Taleb]]
- Full Title: Safe Haven
- Category: #books

## Highlights
- I was burned out from exhaustion, buried in the hail Poisoned in the bushes an’ blown out on the trail Hunted like a crocodile, ravaged in the corn “Come in,” she said, “I'll give ya shelter from the storm” Bob Dylan ([Location 264](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=264))
    - Tags: [[pink]] 
- Spitz has always been hardheaded; perhaps a good excuse is that it came with a remarkable clarity of mind. I must reveal that while I am far more diplomatic and less obstinate in person than I am in print, he is the exact reverse, though he hides it remarkably well to outsiders, say journalists and other suckers. He even managed to fool the author Malcolm Gladwell, who covered us in the New Yorker, into thinking that he would be one breaking up a fight at a bar while I would be one to initiate it. The atmosphere of the office has been playfully unique. Visitors are usually confused by the sprawl of mathematical equations on the board, thinking our main edge is only mathematical. No. Both Mark and I were pit traders before doing quantitative stuff. While our work has been based on detecting mathematical flaws in existing finance models, our edge has been linked to having been in the pit and understanding the centrality of calibration, fine‐tuning, execution, orderflow, and transaction costs. Remarkably, people who have skin in the game, that is, self‐made successful people with their own money at risk (say a retired textile importer or a former shopping center developer), get it right away. On the other hand the neither‐this‐nor‐that MBA in finance with year‐end evaluation ([Location 306](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=306))
    - Tags: [[pink]] 
- filed by the personnel department needs a helping hand—they can neither connect to the intuitions nor to the mathematics. At the time when I met Mark, we both were at the intersection of pit trading and novel branches of probability theory (such as Extreme Value Theory), an intersection that at the time (and still, presently) included no more than two persons. MUTUA MULI Now what was the dominant idea to emerge? There are activities with remove payoff and no feedback that are ignored by the common crowd. With the associated corollary: Never underestimate the effect of absence of feedback on the unconscious behavior and choices of people. Mark kept using the example of someone playing piano for a long time with no improvement (that is, hardly capable of performing Chopsticks) yet persevering; then, suddenly, one day, impeccably playing Chopin or Rachmaninoff. No, it is not related to modern psychology. Psychologists discuss the notion of deferred payoff and the inability to delay one's gratification as a hindrance. They hold that people who prefer a dollar now versus two in the future will eventually fare poorly in the course of life. But this ([Location 316](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=316))
    - Tags: [[pink]] 
- is not at all what Spitz's idea is about, since you do not know whether there might be a payoff at the end of the line, and, furthermore, psychologists are shoddy scientists, wrong almost all the time about almost all the things they discuss. The idea that delayed gratification confers some socioeconomic advantage to those who defer was eventually debunked. The real world is a bit different. Under uncertainty, you must consider taking what you can now, since the person offering you two dollars in one year versus one today might be bankrupt then (or serving a jail sentence). So what this idea is about isn't delayed gratification, but the ability to operate without external gratification—or rather, with random gratification. Have the fortitude to live without promises. Hence the second corollary: Things that are good but don't look good must have some edge. The latter point allows she or he who is perseverant and mentally equipped to do the right thing with an endless reservoir of suckers. Never underestimate people's need… ([Location 330](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=330))
    - Tags: [[pink]] 
- It does not matter if your idea is eventually proved right; there are intermediary steps in between that can be won. So “research” will be eventually gamed into some brand of nonresearch that looks cosmetically like research. You publish in a “prestige” journal and you are done, even if the full idea never materializes in the future. The game creates citation rings and clubs in fields like academic finance and economics (with no tangible feedback) where one can BS endlessly and collect accolades by peers. For instance, the theory of portfolio construction (or the associated “risk parity”) à la Markowitz requires correlations between assets to be both known and nonrandom. You remove these assumptions and you have no case for portfolio construction (not counting other, vastly more severe flaws, such as ergodicity, discussed in this book). Yet one must have no knowledge of the existence of computer screens and no access to data to avoid noticing that correlations are, if anything, not fixed, changing randomly. People's only excuse for using these models is that other… ([Location 342](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=342))
    - Tags: [[pink]] 
- COST‐EFFECTIVE RISK MITIGATION Most financial and business returns come from rare events—what happens in ordinary times is hardly relevant for the total. Financial models have done just the opposite. A fund miscalled Long Term Capital Management that blew up in 1998 was representative of such decorated mutua muli misunderstanding. The Nobel‐decorated academics proved in a single month the fakeness of their models. Practically everyone in the 1980s, particularly after the crash of 1987, must have known it was quackery. However, most if not all financial analysts exhibit the clarity of mind of a New York sewer after a long weekend, which explains how the mutua muli can take hold of an entire industry. Indeed the investment world is populated by analysts who, while using patently wrong mathematics, managed to look good and cosmetically sophisticated but eventually harm their clients in the long run. Why? Because, simply, it is OPM (other people's money) they are risking while the returns are theirs—again, absence of skin in the game. Steady returns (… ([Location 354](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=354))
    - Tags: [[pink]] 
- barrels of dynamite—so we needed to destroy these models as tools of deception. This risk transfer is visible in all business activities: corporations end up obeying the financial analyst dictum to avoid tail insurance: in their eyes, a company that can withstand storms can be inferior to one that is fragile to the next slight downturn or rise in interest rates, if the latter's earning per share exceed the former's by a fraction of a penny! So the tools of modern finance helped create a “rent‐seeking” class of people whose interest diverged from those of their clients—and ones who get eventually bailed out by taxpayers. While the financial rent seekers were clearly the enemies of society, we found actually worse enemies: the imitators. For, at Universa, Spitz built a structure that tail‐hedged portfolios, hence insulated him from the need for delayed random gratification. As introduced (and formulated) in Safe Haven, risk mitigation needs to be “cost‐effective” (i.e., it should raise your wealth), and to do that it needs to mitigate the risks… ([Location 366](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=366))
    - Tags: [[pink]] 
- Accordingly, the idea grew on people and a new category was born. This led to a legion of imitators—those very same mutua muli persons who had previously been fooled by modern finance tools, finding a new thing to sell. Universa proved the following: not only is there no substitute to tail risk hedging, but, when it comes to tail risk hedging, simply—as per the boast in the Porsche advertisement—there is no substitute. For when you go from a principle to execution, things are much more complicated: the output is simple to the outsider, the process is hard seen from the inside. Indeed, it takes years of study and practice, not counting natural edges and understanding of the payoffs and probabilistic mechanisms. I said earlier that Mark's edge came from pit trading and a natural (noncontrived) understanding of the mathematics of tails. Not quite. His edge has been largely behavioral, and my description of hardheaded was an understatement.… ([Location 379](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=379))
    - Tags: [[pink]] 
- Talk is cheap. Ideas and commentary are just that. Significance only comes from the doing, from action within ([Location 406](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=406))
    - Tags: [[pink]] 
- the arena. It is not my business, like Sherlock Holmes, “to know what other people do not know.” It is my business to do what other people do not and cannot do (as well as, just as importantly, to know what I do not know). Doing and demonstrating effective safe haven investing is far, far more important than arguing about what it should be. And even among most of those who claim to do it, they neglect those pithy words from Hemingway to “never confuse movement with action.” This book tells of the foundation and methodology behind how, as of this writing, Universa risk‐mitigated portfolios have, over their decade‐plus life to date, outperformed the S&P 500 by over 3% on an annualized, net basis. More to the point, this performance is a direct consequence of having far less risk. This level of outperformance is rare in the hedge fund industry and among risk‐mitigation strategies in general, which have pretty much all underperformed the S&P 500 during this and most periods. The markets have been good to us because we haven't tried to cheat them; we haven't tried to predict or outsmart them. We have only aligned our investing, in a focused way, with our beliefs about the way they work. People think of risk mitigation as a liability, as a tradeoff against wealth creation, because it usually is. Universa is, if nothing else, a real‐life case study and out‐of‐sample test that unequivocally proves the point ([Location 407](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=407))
    - Tags: [[pink]] 
- that risk mitigation doesn't have to be viewed that way. Risk mitigation can and should be thought of as being additive to portfolios over time—with the right risk mitigation, that is. This is the mark that I want Universa to make in the markets. ([Location 420](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=420))
    - Tags: [[pink]] 
- His words still ring true today: Take care of the losses; the profits will then take care of themselves. Profits matter only relative to the losses; stay in the game by protecting your capital base, your means of playing the game. Don't predict. Pretty obvious stuff, except people don't really focus on losses, especially the potential for big ones. In all my ([Location 452](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=452))
    - Tags: [[pink]] 
- experience, most investors don't think about the impact of the downside the way they need to; they just don't. ([Location 454](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=454))
    - Tags: [[pink]] 
- We have many diverging roads ahead, many potential paths forward with so many twists and turns, more than we can ever count. Some of those potential paths will be very pleasant, and some of those potential paths won't be. Of all the potential paths, we don't know which is the one and only path that we will actually traverse. Now, that's risk! A safe haven is an investment that mitigates risk, or the bad potential economic contingencies in your investment portfolio. That is a necessary condition for safe haven status. It protects against consequential loss that happens to everyone, everywhere, all at the same time, because that loss is tied to the cycles of broad macroeconomic growth and contraction. Because of its ubiquitous and systematic nature, you can't just diversify that risk away with groupings of things that supposedly won't experience such loss simultaneously. And remember this: A safe haven isn't so much a thing or an asset. It is a payoff, one that can take many different forms. It might be a chunk of metal, a stock selection criterion, a crypto‐currency, or even a derivatives portfolio. Whatever forms they may take, it is their function that makes safe havens what they are: They preserve and protect your capital. They are a shelter from financial storms. ([Location 491](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=491))
    - Tags: [[pink]] 
- So safe haven investing is risk mitigation. To me, these two terms are synonymous, and I will be using them interchangeably throughout this book. (The former made for a catchier title.) What's more, risk mitigation is investing itself. Treat this as a fundamental premise. Even the most renowned proponent of the bottom‐up approach to investing, Benjamin Graham, the “father of value investing,” declared: “The essence of investment management is the management of risks, not the management of returns. Well‐managed portfolios start with this precept.” Moreover, “Confronted with a challenge to distil the secret of sound investment into three words, we venture the motto, Margin of Safety.” Truer words have never been written on the subject. For Graham, “safety of principal” is what separates investing from speculating. It makes investing—investing! (He learned the hard way, in the 1929 stock market crash, that all great ideas can be dashed, simultaneously and systematically.) But this is the pretty obvious part. It still misses what's so special about what a safe haven should be. Any punter can devise… ([Location 502](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=502))
    - Tags: [[pink]] 
- different than they are alike. We run into issues similar to what biologists encountered when trying to define what a species is. We will need a specific safe haven concept—like their species concept—in order to classify them and evaluate if they are even what they claim to be. This will be a major line of inquiry in this… ([Location 514](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=514))
    - Tags: [[pink]] 
- THE GREAT DILEMMA There is a monumental problem facing investors, the great dilemma of risk. If you take too much risk, it will likely cost you wealth over time. And at the same time, if you don't take enough risk, it will also likely cost you wealth over time. You are trapped in a “Catch‐22”: damned if you do and damned if you don't. Pick your poison. You can try calibrating between these two bad choices in hopes of finding a happy medium, but this still leaves you with a bad choice—it is still poison. Modern finance is really all about the quest for this theoretical happy medium, the supposed “Holy Grail of investing.” Despite this valiant quest and lofty name, the results have shown that this Holy Grail is a myth; the happy medium is… ([Location 519](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=519))
    - Tags: [[pink]] 
- This great dilemma is the most important problem in all of investing; it is one that desperately needs solving. It is also the rationale for what I do as a hedge fund manager, and the reason for this book. Thanks to the sheer scale and scope of the problem, the stakes have never been higher. In particular, the broader problem is of liabilities exceeding assets, and this applies to mammoth pools of capital and even to individuals with small investment accounts. Just think of the massively underfunded public and private pension funds today, which must generate specific, high‐target rates of return over many years or else face insolvency as their liabilities consume their capital. They can't just hide away, idling in less risky assets in an impaired portfolio, or try to diversify away their risks; and yet investing in riskier assets brings, by definition, acute risks of unrecoverable loss. The standard approach to risk mitigation has really failed them—just as it has failed everyone. And the problem is only going to get worse. It is a looming, ticking time bomb. The consequences of failing to solve the great… ([Location 527](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=527))
    - Tags: [[pink]] 
- This monumental problem is further complicated today by the massive distortions built up in global financial markets from years of hubristic monetary interventions by global central banks, enabling the reckless accumulation of debt and leverage. Though these distortions are on an unprecedented scale and are intricately related to the underfunding problem itself, they are nonetheless beside the point. They are both beyond the scope of this book (I have already written plenty about them elsewhere) and, most importantly, completely unnecessary to the book's message. I don't need to convince you of any ideological, Cassandra‐like premise that markets are risky so that you will accept my conclusions about safe havens. It will not matter to our methodology. We can and will remain agnostic, not roll the dice, and, most important, not predict. To find a solution to this monumental problem, we need to reduce the costliness of risk—specifically the costliness of losses—and do so in a way that does not end up costing us even more. In other words, we need a cure that is not worse than the… ([Location 538](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=538))
    - Tags: [[pink]] 
- think about losses and our investment returns differently, through a different lens and a different framing. As in all things, “the good God is in the details.” And in our case, these details, while not terribly complicated, often appear counterintuitive and paradoxical. As we will see, there are emergent dynamics at play here that make cost‐effective risk mitigation extremely challenging, perhaps more so than anything else in the realm of investing. We need to proceed cautiously. The problem is that investing is approached by most professionals and academics (and even the reigning PhD quants of modern finance) in a highly… ([Location 549](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=549))
    - Tags: [[pink]] 
- Investing really needn't be about making grandiose forecasts, any more than it is in, say, sports or other games like poker or backgammon—though one could easily make that mistaken assumption from the outside looking in. It isn't even necessarily about getting the probabilities right. You can get the probabilities right all day but still do very poorly. It's really about getting the payoffs right. Playing good defense that leads to good offense. So there's more room for error, more room for being right, more room to get it right after getting it wrong. This ([Location 565](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=565))
    - Tags: [[pink]] 
- is cost‐effective risk mitigation. You look and feel like you can see around corners, even though, in actuality, you can't. As an archer, you don't try to forecast or pinpoint exactly where your arrow will hit once it leaves your bow. That would be an unproductive way to approach it—leading to target panic. Once you shoot the arrow (and even as you shoot the arrow), it is out of your control and susceptible to endless perturbations. So, instead, as in Herrigel's Zen in the Art of Archery, you aim by deliberately not taking aim—you hone your process and structure (focusing “behind the line” rather than down range) with the intent to specifically tighten your shot grouping around your target. There is this ancient Stoic notion of a dichotomy of control that applies here to investing, as it does to archery: We need to control what we can control in a way that gets us closer to our target (of higher wealth)—and certainly not further from it. This is cost‐effective risk mitigation. You look and feel like you can see around corners and can always hit the bullseye, even though, in actuality, of course, you can't. You see, a cost‐effective safe haven doesn't just slash risk. It actually lets you simultaneously take more risk. If that twist gave you pause for a moment, then good. It should! ([Location 569](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=569))
    - Tags: [[pink]] 
- Principle number one is that investing is a process that happens sequentially through time. Investing is not static. It does not occur in just one interval of time, nor in many intervals of time aggregated together as one. (Albert Einstein purportedly noted that “the only reason for time is so that everything doesn't happen at once.”) Time is the medium through which life takes place, and so it is the medium through which investing takes place. We are stretched across time. Investing and risk are a multi‐period problem; and returns are an iterative, multiplicative process. They compound: In each period, we generally invest what we are left with from the last period. Like the geometric growth of offspring across generations, we parlay our capital. This principle fundamentally determines the nature of investing and the way we need to think about and interpret returns. ([Location 595](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=595))
    - Tags: [[pink]] 
- But as obvious as it is, just try telling that to a hedge fund manager whose incentive fee is based on annual performance: investing happens through time. Or, deliver that message to the pension fund that is harshly judged on its ability to meet an annual benchmark over the short term rather than over a timeline consistent with its beneficiaries. And try telling that to the economics and behavioral finance communities who label behavior “irrational” when it doesn't appear optimal within their single‐period, timeless framework. Do so and you should expect funny looks. But they criticize what they can't understand; they're no Einsteins. As for us, we need to ask ourselves every day: What is the meaning of time in investing? The answer, as you'll see, changes everything. Principle number two is that there is only one explicit purpose or goal of investing, and that is to maximize our wealth over time. Period. This is exactly what we are trying to do with every additional, incremental decision that we make as investors. It is the target we shoot at. I'm not talking about the elusive mathematical expectation of wealth, nor our wealth relative to some arbitrary benchmark (though there are plenty of managers incentivized to care only about that). Rather, I'm talking about our actual realized ending wealth—meaning the outcome we're actually left with. (They are not the same.) This is equivalent to maximizing the rate that we grow ([Location 602](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=602))
    - Tags: [[pink]] 
- or compound wealth over time—our compound annual growth rate, or CAGR. All investors are absolute return, compounding investors. I don't believe any thinking person, and certainly not any practitioner, should disagree with this principle. It is common sense. And yet, some would still protest that the goal of investing should be to further humanity's progress, ease its burdens, do good to consumers and the world—and the profits will follow. But this is only another way of restating our principle. The consumer is the sovereign king whom capital must serve in order to be profitable; it is because of this that capital investment and entrepreneurship have objectively done more good for the world than any government or charity ever could. Others might still protest that the goal of investing should be to maximize our wealth, given a certain level of theoretical risk taken. (This is where things would start to get a little muddled were it not for our next principle.) Since we know that risk mitigation is investing, we can deduce that the explicit purpose of risk mitigation is… ([Location 614](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=614))
    - Tags: [[pink]] 
- lowering a portfolio's risk, then adding that strategy raises the portfolio's CAGR over time. It makes sense. If we mitigate risk effectively by constraining it deliberately, shouldn't the point be to experience less loss as a result, such that over time we end up making more? And if we don't end up making more, will we still be glad we did it? What would the point have been? Is there any other reason to mitigate risk? Risk mitigation, when done well, should provide a tangible, positive economic effect relative to its cost. That is, it should be cost‐effective, and thus a good value proposition. Accordingly, a risk‐mitigation strategy should be evaluated based on its degree of cost‐effectiveness at lowering risk—not just on its effectiveness at lowering risk. Of course, we may have mitigated the risk of a remote, extreme loss that never happened. And yet, such a remote loss could happen suddenly at any time, and our risk mitigation could thus raise our CAGR (relative to our position had we not used that mitigation). This is the problem of induction, where… ([Location 626](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=626))
    - Tags: [[pink]] 
- epistemological problems. (We will address this with what is known as a bootstrap in later chapters.) Amusingly, this principle that risk mitigation, done well, should raise our CAGR over time is actually quite controversial. In fact, most practitioners and academics would probably call it a crackpot idea. Lower risk comes at a cost, they believe, so risk mitigation is incompatible with higher returns. To wit, one of the historic commodities trading houses had the German motto: “Besser gut schlafen, als gut essen.” (“It is better to sleep well than to eat well.”) And academics claim that lower returns actually accompany lower risk or volatility as a consequence, ipso facto. Their story goes, as you hedge and diversify away all of your correlated and uncorrelated risks, respectively, your returns will approach the lowly risk‐free rate. Or going the other way, the academics argue that in order to induce an investor to hold an asset that is relatively volatile, its price drops until its expected return becomes high enough to justify the additional risk. In their world, it sounds… ([Location 637](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=637))
    - Tags: [[pink]] 
- lowering or calibrating a portfolio's volatility relative to its average return—the risk‐adjusted return or dreaded Sharpe ratio—unwittingly at the expense of the growth rate of wealth. They thus claim an intellectually dishonest victory based on their own theoretical scoreboard. It is a solution in search of a problem, and a bad idea. (It's even a big reason for our great dilemma.) I don't really believe that most investors even have this bad idea. Rather, to paraphrase Carl Jung, the idea has them. We need to measure our success as investors by the practical scoreboard that counts, rather than the theoretical ones that don't. And there is just one scoreboard that counts, just one bullseye. But we are often lured away from such practical objectives by gratuitous mathematical formulas. Modern quantitative finance suffers from a certain science or physics envy. After all, according to the American physicist Richard Feynman, “Physics is like sex: sure, it may give some practical results, but… ([Location 649](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=649))
    - Tags: [[pink]] 
- Aristotle is generally considered to be the earliest and foremost developer of the idea of deductive reasoning, or sullogismos. Deduction is “top‐down” logic, whereby general rules or premises are applied to particular cases or conclusions. This contrasts with induction, which is “bottom‐up” logic and goes in the opposite direction, whereby particular cases or premises are applied to reach a general rule or conclusion. Examining the geometry of a die to estimate the frequency that any side will come up over repeated rolls is deductive reasoning. Reasoning in the other direction, by repeatedly rolling a die and using those results to estimate the geometry of the die, is inductive reasoning. (We will be rolling the dice in both directions in this book.) A syllogism applies deductive reasoning to draw a valid conclusion from assumed premises. One example is the syllogism called modus tollens or “denying the consequent.” It is the main… ([Location 663](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=663))
    - Tags: [[pink]] 
- A modus tollens takes the form of “If H, then O. Not O. Therefore, not H” (with H for hypothesis and O for observable). There are two premises—an explanatory hypothesis, made up of an antecedent and consequent, paired with an observable; brought together, they yield a conclusion, which follows logically from the premises. The logic goes, if a statement is true, then so is its contrapositive. Think of this example of modus tollens involving my dog Nana: If Nana is good at catching groundhogs, then I won't have a groundhog problem. I have a groundhog problem. Therefore, Nana isn't good at catching groundhogs. We can see that a modus tollens serves the specific role of falsifying or eliminating a hypothesis. But neither it, nor anything else for that matter, can ever be used to verify a hypothesis as true. When we pair our proposed hypothesis with a minor premise that is an observable fact, we have a well‐constructed test of that hypothesis. Modus tollens, then, is the logical principle of the… ([Location 674](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=674))
    - Tags: [[pink]] 
- When, like sleuths, we disqualify false theories whenever we can, then step by step we approach the truth. It's all very Sherlock Holmesian: “When you have eliminated the impossible, whatever remains, however improbable, must be the truth.” Most significantly, the twentieth‐century Austrian philosopher of science Karl Popper constructed his whole falsification principle around it—as the fundamental demarcation between science and pseudoscience. “Universal statements are never derivable from singular statements, but can be contradicted by singular statements,” as Popper wrote in The Logic of Scientific Discovery. “Consequently, it is possible by means of purely deductive inferences (with the help of the modus tollens of classical logic) to argue from the truth of singular statements to the falsity of universal statements. Such an argument to the falsity of universal statements is the only strictly deductive kind of inference that proceeds, as it were, in the ‘inductive direction’; that is, from singular to universal statements.” So far, we… ([Location 687](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=687))
    - Tags: [[pink]] 
- in investing. Have you noticed?) Taking such a conclusion for granted is begging the question. It might even appear that we did this in our principle number three. However, the principle only claimed what risk mitigation should be, not necessarily what it always is. Cost‐effective risk mitigation could still be only theoretical, and not actually possible. So, instead, we need to treat this principle as a conditional premise. It is an explanatory hypothesis, and this conveniently suggests our own modus tollens syllogism for safe havens, which we will be testing and investigating over and over: If a strategy cost‐effectively mitigates a portfolio's risk, then adding that strategy raises the portfolio's CAGR over time. Adding that strategy doesn't raise the portfolio's CAGR over time. Therefore, it does not cost‐effectively mitigate the portfolio's risk. What we have here is a natural, testable… ([Location 699](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=699))
    - Tags: [[pink]] 
- then the null hypothesis—that the strategy cost‐effectively mitigates the portfolio's risk—does not hold. If it disagrees with experiment, it is wrong—it is not a cost‐effective safe haven strategy. What we cannot do, however, is prove that something is a cost‐effective safe haven strategy. Such is the scientific method. To illustrate why you can't prove things in reverse, it's important to note that I could not have posed this syllogism instead, as the inverse of our premises: If a strategy does not cost‐effectively mitigate a portfolio's risk, then adding that strategy lowers the portfolio's CAGR over time. That would be deductively invalid; it mistakes a sufficient condition for a necessary condition. Observing that adding the strategy raises the portfolio's CAGR over time actually proves nothing about cost‐effective risk mitigation. This is because there are other ways that the strategy could have raised the portfolio's CAGR; the strategy needn't have even mitigated risk at all, and it may have even added risk. We would need to delve deeper into the source of that outperformance. (As Hemingway… ([Location 711](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=711))
    - Tags: [[pink]] 
- will observe this data. We observe this data; therefore, my theory is correct.” In my previous example with Nana, what if I don't have a groundhog problem? Can I proudly claim that my Nana is good at catching groundhogs? After all, there could be myriad other possible reasons that I don't have a groundhog problem. Maybe they were scared off by our resident fox. Or perhaps my son has been playing in our woods with his bow and arrow and ghillie suit. We would similarly mistake sufficiency for necessity with the fallacy of denying the antecedent. In this case, we might conclude that I have a groundhog problem as a logical consequence of knowing that Nana is not good at hunting groundhogs. All knowledge is a hypothesis; it is all conjectural and provisional, and it can only ever be falsified, never confirmed. Now, a critical part of this scientific method is the way we go about choosing the very hypothesis that we are putting to the test. We specifically need to avoid ad hoc hypotheses that simply fit our… ([Location 723](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=723))
    - Tags: [[pink]] 
- The deductive thinking behind my hypothesis “Nana is good at catching groundhogs” was so important because it's going to hang around as sort of our working hypothesis until I manage to falsify it. Did I have a sound deductive reason to think that her skill, if it exists, would really result in the disappearance of groundhogs? Skilled or not, does she prefer to spend her summer days sleeping indoors? (As a Bernese Mountain Dog, she… ([Location 737](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=737))
    - Tags: [[pink]] 
- We need a sound, deductive framework for understanding why and how risk mitigation can lead to higher compound growth rates. Is it even possible? How can we expect risk mitigation to be cost‐effective? What's the mechanism behind it? And how might we recognize this ability if or when we see it? There are so many forces swirling around in investing and markets; any attempts at explaining risk mitigation based on that swirling data will likely get us into trouble. So we will need to figure out, deductively, the… ([Location 743](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=743))
    - Tags: [[pink]] 
- risk mitigation. We need to understand the forces at work to… ([Location 748](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=748))
    - Tags: [[pink]] 
- The best deductive tool at our disposal will be the same deductive tool used from prehistory right up to today to discover and comprehend the general science of… ([Location 749](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=749))
    - Tags: [[pink]] 
- Archaeological excavations have uncovered collections of talus bones, or ankle bones of goats and sheep, dating back to 5,000 BCE. These four‐sided bones were the oldest of all gambling devices. Our more familiar six‐sided “bones” started showing up by 3,000 BCE. Visibly, dice have been embedded in civilization's history as the generators of fate, then chance, and then even skill (in the early precursors of modern backgammon). They were ubiquitous throughout both the depth and breadth of that history and are a part of our collective unconscious. But it took ages, and the need to better understand wagers on games, for dice to become the intuitive pedagogical tools of deductive inference that would set in motion a theory of probability. As early as the fourth‐century BCE, Aristotle casually pointed out that, while it is easy to make a couple of lucky… ([Location 751](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=751))
    - Tags: [[pink]] 
- Greeks and Romans never really got it—they never even bothered to make sure their dice faces were symmetric. If everything was fate anyway, what difference did it make? Julius Caesar's famous line “the die has been cast” was not a statement about probability. (For all the wisdom that we ascribe to the ancients, if you had the ability to go back in time, you would totally clean up gambling against them.) It wasn't until much later, by the seventeenth century, that Galileo and then Blaise Pascal and Pierre de Fermat became gambling advisor‐mercenaries to various noblemen. For instance, the Chevalier de Méré needed advice on his costly observation that betting with even odds on the appearance of a 6 in four rolls of a single die was profitable in the long run, whereas betting with the same odds on a double‐6 in 24 rolls of two dice was not. (In 1952, the famed New York City gambler “Fat the Butch” rediscovered this same deductive fact in his own rather costly hypothesis test.) At that point, probability was all about deductive reasoning, starting with the known properties of the generator (a die) and then reasoning forward with expectations about its particular outcomes.… ([Location 760](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=760))
    - Tags: [[pink]] 
- coming of age as a neat trick to allow mathematicians to pick off degenerate gamblers. These were the original quants—money on the line has a way of sparking innovation. (Heck, it took having an options position for me to ever start really thinking about math.) Of course, we have always understood risk and its mitigation in our bones; that's how we made it this far, after all. But along with advancements in our understanding of probability grew a gradual formalization and sophistication of risk mitigation. And we can think of the growth of that formality first and foremost as the growth of innovations in insurance—which itself would facilitate an explosion in risk taking and innovations. Insurance is an ancient idea, and a key part of the very progress of our civilization. It began as solidarity, as risks were shared—spreading throughout small villages, for instance, as commitments to mutually self‐insure and share the replacement costs of homes within the community. This aggregation of individual risks created a frequentist's perspective where there otherwise was none, effectively expanding… ([Location 771](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=771))
    - Tags: [[pink]] 
- “tendencies,” respectively—went head‐to‐head with the simpleton frequentists. And it doesn't really matter who was right. All that matters is which perspective is being used. When your sample size is small, and worse yet unique and unrepeatable, no matter your subjective probabilities, there is so much noise in your sample you can hardly know anything anyway. Your N equals 1. You are a punter, hoping for good luck or good fate. But if your success or failure relies on many outcomes, over many rolls of the dice, then you naturally care about the properties over many rolls of the dice. Your N is large. You are the house exploiting the “house edge” through repetition, to quash the randomness. And the house doesn't gamble. You are, as the poker theorist David Sklansky wrote, “at war with luck.” Most people would say (or at least their actions imply) that they are the house in their investing. And 93% of people also say that they are above average drivers. They aren't, in either case. “At war with luck”—using our “skills to minimize luck as much as possible”—does… ([Location 783](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=783))
    - Tags: [[pink]] 
- This is one of the most valuable things I have learned from Nassim Taleb, his valid warnings against the ludic fallacy notwithstanding (where “the narrow world of games and dice” have so little in common with the untamed risk of the real world): that playing around with and meditating on simplified Monte Carlo simulations, or “alternative histories,” is the best way to figure things out. After all, according to Popper, science is “the art of systematic over‐simplification.” Beyond epistemological rigor, the biggest advantage I gain from building my safe haven hypothesis deductively and piecemeal using games of dice is transparency. You are going to see some things about safe haven investing that will seem to defy common sense. Couple that with the fact that there are frighteningly many ways that the investment industry regularly smokes people with complicated and unfalsifiable (and thus pseudoscientific) theories and cherry‐picked market data, and you can see my concern about a healthy… ([Location 796](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=796))
    - Tags: [[pink]] 
- In general, we look for a new law by the following process. First, we guess it. Then, we compute the consequences of the guess to see what, if this is right, it would imply. And then we compare the computation results directly with observations to see if it works. If it disagrees with experiment, it's wrong. In that simple statement is the key to science. It doesn't make any difference how beautiful your guess is, it doesn't make any difference how smart you are who made the guess, or what his name is—if it disagrees with experiment, it's wrong. That's all there is to it. This will be my analytical framework for this book. In Part One, we start with “what comes first” (the a priori), with an intuitive construction and examination of those fundamental safe haven mechanisms, with the help of our deductive dice. “First, we guess it.” Then in Part Two, with “what comes after” (the a posteriori), we start to formulate testable safe haven hypotheses based on those mechanisms—hypotheses about how we might expect them to work. We will conduct clinical trials or experiments on different idealized safe havens (what I call cartoons)—to “… ([Location 808](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=808))
    - Tags: [[pink]] 
- that safe havens as a group—and various safe havens in particular—can raise wealth by lowering risk. This is not a foregone conclusion; after all, it is considered a crackpot idea. Through this methodology, you will hopefully understand what works in risk mitigation, what does not, and why. And this understanding will protect you more than any individual safe haven ever could. It will guide you toward our goal as investors. If you think about it, cost‐effective risk mitigation—or raising compound growth rates and thus wealth through lower risk—is really our comprehensive goal as investors. It is the true essence of investment management. In and of itself, it is the specific meta‐purpose or meaning we pursue when we deploy capital—what we hunt for relentlessly, our buried treasure. Yes, there really is a buried treasure for investors, one that solves our monumental problem by showing that the great dilemma of risk—the ostensible tradeoff between higher returns and lower risk—is actually a false choice. But this treasure wasn't so much hidden away by pirates of lore as it was cloaked behind the flawed apparatus of modern finance, shrouded behind its veil of rigor. As a result, it appears as a myth, an idealized and elusive goal. But that's only because investors have been looking too narrowly ([Location 821](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=821))
    - Tags: [[pink]] 
- and in the wrong places for it. We need a more holistic approach; we also need a treasure map to know where to dig. But just because that buried treasure exists doesn't mean we will ever find it. The greatest value—more than in the treasure itself—will be in what we gain from the hunt. ([Location 832](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=832))
    - Tags: [[pink]] 
- But it was Jacob, by then a professor of mathematics at the University of Basel, who really changed everything. Jacob's book Ars Conjectandi—fortunately for the uber‐competitive Johann, it was published posthumously in 1713—included a discovery that remains significant today: the “law of large numbers,” or what he called his Golden Theorem. Put simply, as you accumulate more and more data in a random sample, you should expect that sample's average to converge to the true average of the generator, or population. The more you roll a square (or fair) six‐sided die, for instance, the more the percentage of all those rolls in which you see any particular ([Location 853](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=853))
    - Tags: [[pink]] 
- number will converge toward 1/6, or 16.66%. But here, Bernoulli reversed the reasoning: starting with the properties of the outcomes under many trials and inductively reasoning backward to the generator. This was like a bombshell going off, creating a formal statistical inference and the blossoming of actuarial science. Jacob brought probability from essentially a field of practical argumentation among degenerate gamblers to one of mathematical rigor. Even so, Jacob Bernoulli provided more mathematical grist for the gambler's logic, ostensibly started by Aristotle, Galileo, Pascal, and Fermat, whereby the meaning of probability and expectation came down to the frequency of occurrences over many repeatable experiments—not to single events. After Jacob's death, Johann needed a new target for his mathematical bickering, and he found one in his son, Daniel, yet another talented Bernoulli mathematician. After a slow start in Italy, highlighted by an analysis of the then‐popular Italian casino game of faro, Daniel had a stint as a professor of mathematics at the Academy of Sciences in Saint Petersburg, Russia, from 1725 to 1733. Upon returning home to Basel, he assumed the chair of anatomy and botany at the University of Basel. In 1735, Daniel and his father shared the Grand Prize of the Paris Academy for their work on planetary ([Location 858](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=858))
    - Tags: [[pink]] 
- orbits. That proved too much for the ornery elder Bernoulli. Johann threw Daniel out of the house over the prize he felt should have been his alone (though perhaps it was high time for the 35‐year‐old Daniel to move out anyway). They never spoke again, and Daniel would win that prize many times more, mostly for nautical improvements such as the stability of ships' hulls against stormy seas. And, in 1738, Daniel published his book Hydrodynamica, which he had already completed back in 1733. In it, he established the Bernoulli principle, expounding breakthrough properties of fluid flow by which we understand the lift of aircraft wings today. This so riled Johann, he backdated his own later and curiously… ([Location 869](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=869))
    - Tags: [[pink]] 
- That same year, in 1738, Daniel presented another “Bernoulli principle,” as it should be called—far lesser known though at least as important as the original. The principle was contained in his newly published Specimen theoriae novae de mensura sortis (Exposition of a New Theory on the… ([Location 879](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=879))
    - Tags: [[pink]] 
- Petersburg. In it, Daniel offered a solution to a vexing problem posed by his cousin, Nicolas Bernoulli (the son of another brother of Jacob and Johann—these Bernoullis keep popping up like rabbits), also at the University of Basel, and named after the city where Daniel worked on and published it: the Saint Petersburg paradox. This was yet another case of a simple dice game changing the very way we think. Daniel's solution was monumental in the understanding of risk, its perception, and its effect. But it was little understood and appreciated, then or since; as a result, it would inadvertently end up becoming a profound distraction for economists for centuries to come. For our purposes, though, Daniel Bernoulli's solution to the Saint Petersburg paradox is central to safe haven investing. The original Saint Petersburg paradox involved a simple game with a single die. (Nicolas's game was later described equivalently by others, including Daniel, as a coin‐flipping game, but I'll keep to Nicolas's original die.) Nicolas envisioned a gamble based on rolling a die repeatedly until… ([Location 882](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=882))
    - Tags: [[pink]] 
- payoff continuing to double with each subsequent roll until the number one appeared for the first time. Now, clearly, this game could go on for a very long time. You can imagine a scenario where you could keep rolling the die forever without the number one ever turning up, with the payoff doubling each time. And for a very rare series of rolls, that nonstop doubling is enough to create an expected average payoff—or expected ending wealth—that equals infinity. (More precisely, it is undefined.) So, the big question from Nicolas was, how much would you wager to play this game? Not surprisingly, most people, rightly, wouldn't pay anything close to that infinite expected payoff, or even very much at all, in order to get to play this game. And therein lies the paradox. Clearly this is because you wouldn't be very likely at all to ever receive infinity for your wager—in fact, you never would—even after repeating the wager over and over again. All that gamblers thought they knew about pricing wagers, from Aristotle to Galileo to Bernoulli, went out the… ([Location 893](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=893))
    - Tags: [[pink]] 
- real point. In most discussions of the Saint Petersburg paradox, the takeaway becomes: Just stay away from infinite expected value wagers, and all is fine. But not so fast. We don't need infinity to get the paradox. Any sufficiently positively skewed payoff distribution—those with a few very high payoff outcomes—will do. So I will simplify the game drastically by swapping Nicolas's dice game for a cartoon version of it; and in doing this cartoonization, we won't lose any of the meaning (and that's what I call a good trade). Our new and improved Petersburg wager will require just one roll of a die. The winnings corresponding to whatever side of the die comes up are set according to the approximate size… ([Location 905](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=905))
    - Tags: [[pink]] 
- Now we have a nice straightforward and equivalent game to see just how Daniel Bernoulli approached this paradox. (We will henceforth treat and refer to this simplified wager as the Petersburg wager—and if… ([Location 915](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=915))
    - Tags: [[pink]] 
- infinite case later, on your own, then you get extra credit.) The arithmetic average or expected value of this wager is just the arithmetic average of every possible outcome: $166,705 is nowhere near infinity, but it's still high relative to what most people would surely pay to play. (I could have set the amount corresponding to a roll of a six to something much, much higher than $1 million, but it wasn't necessary.) As you can see, in five of the six rolls, you would regret having paid anything close to $166,705 to play this game. The very first thing Bernoulli showed—his first principle—was that the fair value of a wager was “dependent on the particular circumstances of the person making the estimate,” and so needed to be expressed as a percentage of the player's total wealth. That means some fraction of your wealth that you stand to lose—in other words, how badly the loss would hurt you—would drive what you would risk on a wager. A… ([Location 917](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=917))
    - Tags: [[pink]] 
- For instance, let's assume you have a starting total wealth of, say, $100,000, and you decide to wager half of it, or $50,000, on one roll of the die. (And you have a gambling problem, by the way.) Here's what the result of each outcome of the die would now look like: The Petersburg Wager Ending Wealth Nothing much new here. Your average or expected value of ending wealth is still $216,705 (which is just the same average winning of $166,705 from before, plus your $100,000 starting wealth, less your $50,000 wager). $216,705 is higher than your $100,000 starting wealth, but you're still unlikely to pay $50,000 to play, since you could be down almost 50% of your wealth on five of the six rolls. But there is nothing systematic about this… ([Location 930](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=930))
    - Tags: [[pink]] 
- emolumentum medium. When his paper was finally translated into English from its original Latin (which, incredibly, didn't happen until 1954), emolumentum was translated as either “utility” or “moral,” so emolumentum medium was translated as “mean utility” and even “moral expectation” (borrowed from the Swiss mathematician Gabriel Cramer). A more accurate translation of emolumentum, however, is “advantage,” “benefit,” or even “profit,” and medium is “mean,” “average,” or more literally “in the middle.” (If this implied that Bernoulli's emolumentum medium referred to something more like the middle value of the Petersburg wager's range of potential profits, then, as we'll see later, Bernoulli was definitely on to something.) Bernoulli's approach eventually began to seep into the profession of economics, even though it had been neglected initially by economists for over a century, specifically in the form of “diminishing marginal utility.” Diminishing marginal utility simply means the more you have of something, the less the next additional unit of that… ([Location 942](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=942))
    - Tags: [[pink]] 
- that “something” with “wealth.” The best description, to my mind, was written by my indirect investment partner Ian Fleming (in Moonraker): Before he slept he reflected, as he had often reflected in other moments of triumph at the card table, that the gain to the winner is, in some odd way, always less than the loss to the loser. In some sense, Bernoulli had anticipated risk aversion itself, though what people miss is that Bernoulli's discovery really makes risk aversion something of a tautology. “A bird in the hand is worth two in the bush.” But when your bird compounds (or reproduces), if you lose one bird while trying to get two, then you've just lost more than two birds. Although they didn't refer to Bernoulli, the idea of diminishing marginal utility was a foundational principle in the Marginal Revolution. This refers to the crossover in the early 1870s from classical economics into modern subjective value theory, which is conventionally credited jointly and independently to Carl Menger in Austria, Léon Walras in Switzerland, and William Stanley Jevons in… ([Location 955](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=955))
    - Tags: [[pink]] 
- speaking, people have access to more units of water than they need to satisfy their diverse uses for it; thus, “on the margin,” water has a very low market value. But if you were dying of thirst in the desert, you would certainly give a diamond for a glass of water. Simple as it sounds, without this idea of diminishing marginal utility of particular goods as their stockpile increases, economists couldn't easily explain market prices. The early pioneers of the Marginal Revolution didn't really incorporate Bernoulli's framework because they developed their new approach to utility and value in the context of certainty, not chance. However, by the time von Neumann and Morgenstern published their famous work on the theory of games in 1944, modeling behavior under uncertainty was front and center. Like Bernoulli, von Neumann and Morgenstern assumed rational agents dealt with uncertainty by maximizing the expectation of some objective function. To this day, economists call such an objective function a Bernoulli function or a von Neumann‐Morgenstern utility function, in homage to the developers… ([Location 967](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=967))
    - Tags: [[pink]] 
- income taxes—so he has that mark against him, deserved or not. He was even skewered by people such as the eminent Austrian economists Ludwig von Mises and Murray Rothbard, who focused their ire on the particular application Bernoulli made, using a functional form; in my view, however, they missed his broader point—a broader point which is entirely in sync with the Austrian school. Bernoulli's innovation was a simple expansion of his common sense insight that profit and loss have to be scaled by someone's total wealth, such that “any increase in wealth, no matter how insignificant, will always result in an increase in emolumentum which is inversely proportionate to the quantity of goods already possessed.” (Think of it this way: If Scrooge McDuck won $1,000,000, he likely wouldn't notice. But if the guy on the corner won $1,000,000, or even $100,000, it could change his life. The value of what each of them gains is relative to what they… ([Location 978](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=978))
    - Tags: [[pink]] 
- Put simply, emolumentum is the logarithm of wealth. (Technically, it is directly proportional to the logarithm of wealth, but the value of a and b are unimportant to us here.) Now, Bernoulli defined his emolumentum medium using the following “fundamental rule”: If the emolumentum of each possible profit expectation is multiplied by the number of ways in which it can occur, and we then divide the sum of these products by the total number of possible cases, an emolumentum medium will be obtained, and the profit which corresponds to this emolumentum will equal the value of the risk in question. In mathematical terms, Bernoulli's emolumentum medium (EM) is the… ([Location 992](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=992))
    - Tags: [[pink]] 
- And “the profit which corresponds to this emolumentum” is Bernoulli's “value” in question—the Bernoullian expected value (BEV) of the wager. (For the mathematically minded, this requires the exponential, or the inverse function for the logarithm, in order to back out of the logarithmic mapping and into the units of the profit): So there you have it. Take the exponential of the average of the logs of your different potential ending wealth outcomes, and you have Bernoulli's expected value of your wealth from playing that wager. It's a mouthful, but it's pretty simple, really. Let's make it even simpler: Don't wager $50,000 on the Petersburg wager when your total wealth is $100,000, because the Bernoullian expected value of wagering that amount—based on the average log of the potential ending wealth outcomes after playing—is lower than your current wealth. (… ([Location 1005](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1005))
    - Tags: [[pink]] 
- Thus, for someone starting with $100,000, wagering $50,000 on the dice game… ([Location 1018](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1018))
    - Tags: [[pink]] 
- THE GEOMETRIC AVERAGE On the surface, you can see how academics ran with this over the years, as Bernoulli seemed to have given a psychological explanation for the perception of risk that creates all sorts of opportunities for mathematical torturing of theories and data. (Specifically, economists took Bernoulli to be assuming that people have a logarithmic utility function of wealth.) But what Bernoulli really had in mind was something entirely different. His use of the logarithmic function wasn't just a psychobabble presumption used to create the impression of rigor from esoteric math. On the contrary, it is actually grounded in the physical reality of the real world. Let's see what I mean by that. This logarithmic function harkens back to the Babylonians about 4,000 years ago, and more formally to a Swiss clockmaker (Bürgi) and Scottish mathematician (Napier)… ([Location 1020](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1020))
    - Tags: [[pink]] 
- product (or ratio); similarly, divide the log of a number by n and you get the log of the nth root of that number. (The logarithm is still used for that purpose to this day, as in the slide rules that quickly reduce multiplication problems down to addition problems for geeks immemorial.) You see, that mapping from multiplication to addition conveniently allows us to restate Bernoulli's expected value formula as something much more comprehendible and meaningful: the geometric average: As you can see, the geometric average is multiplicative. Unlike the arithmetic average where we add up all the data points, to get the geometric average we multiply them all together. Then, we need to scale them back down to size. In the case of the arithmetic average, this is done by dividing their sum by the number of data points (let's say there are n of them). In the case of the geometric average,… ([Location 1030](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1030))
    - Tags: [[pink]] 
- the one that typically gets all of the attention; it's what we think of whenever we use the term average on its own (or the word mean, which is interchangeable with the word average). When it comes to investing, however, it should play second fiddle no more. Don't worry about the math here. The big idea is that Bernoulli's expected value of a wager is simply the mathematical equivalent of the geometric average of all potential ending wealth outcomes, wrapped around a slick objective function in the form of the logarithm. Bernoulli was not explicit about how all this works, but he relied on it, nonetheless. It was his whole point. As Bernoulli phrased it, his emolumentum “suggests” the rule of taking the geometric average ending wealth, without ever even calling it by name or making the broader economic case for it. He even wrote, regarding the use of the geometric average to value risky bets, “I would elaborate it into a complete theory as has been done with the traditional analysis, were it not that, despite its usefulness and originality,… ([Location 1045](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1045))
    - Tags: [[pink]] 
- value of risky propositions.” He was the first, and the rest was history. We'll see in the chapters ahead that it literally changes everything, especially our understanding of risk mitigation. But for now, let's return to our previously posed question. What is the most you would be willing to pay to play the Petersburg wager? Keeping with our assumed starting wealth of $100,000, we can try a few more examples. Let's try betting all of it, the entire $100,000—bet the ranch (since we've already determined that you have a gambling problem). Here's what that range of potential ending wealth… ([Location 1058](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1058))
    - Tags: [[pink]] 
- Now your geometric expected value is $136,445. It's finally higher than your starting $100,000, so that's good. We can keep trying more and different bet sizes (expressed as a fraction of your total starting $100,000 wealth), plot the results on a graph, and then see the range of geometric average ending wealth for each. The point at which that expected ending wealth… ([Location 1067](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1067))
    - Tags: [[pink]] 
- In the case of $100,000 starting wealth, the fair price of our Petersburg wager, based on breaking even in the geometric average of all outcomes, is 37.7% of that starting wealth, or $37,708. That's what making this bet is worth to you. THE OTHER SAINT PETERSBURG PARADOX Bernoulli's solution to the… ([Location 1074](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1074))
    - Tags: [[pink]] 
- primary focus was his methodology. And then there was yet another, far lesser‐known Saint Petersburg paradox that Bernoulli addressed briefly in that paper; it was a much more practical case study, as well as a more dramatic and intriguing one. This problem involved a Saint Petersburg merchant who has purchased commodities in Amsterdam and wishes to ship them home to Saint Petersburg to sell for a tidy profit. But he faces substantial financial risk in transporting those commodities some 1,100 nautical miles across the Baltic Sea to Saint Petersburg. It sounds like a benign enough trip. But this was the golden age of piracy, after all; the dreaded Dane, “Jack of the Baltic,” was actively looting cargo ships in and out of Saint Petersburg in his ominously named pirate ship, the Sudden Death. (He was that rare, real pirate cliché who drowned all his victims by making them walk the plank before scuttling their seized ships.) Given those risks, how can our merchant cost‐effectively mitigate them? Let's say the net value of the Petersburg merchant's commodities (net of shipping costs,… ([Location 1079](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1079))
    - Tags: [[pink]] 
- 5 end up seized by pirates or the sea—or a 5% probability of a 10,000‐ruble total shipment loss to the merchant. Perhaps some risk mitigation could help, like insurance. Let's say the best price the merchant can find for insuring his entire precious 10,000‐ruble cargo is 800 rubles—which he considers “outrageously high! Ochen' dorogo!”—and not at all cost‐effective. He would appear to be right: Based on history, the actuarial expected value of such a contract is (–800 × 95/100) + (9,200 × 5/100) = –300. This would really eat into his expected return from each 10,000‐ruble cargo. Without mitigating his risks, this shipment would perhaps be riskier than he could bear. But the insurance industry was seemingly a loser's game, merely preying on its customers' fears; as the calculation indicates, the premium being charged was higher than the actuarially “fair” amount. The Petersburg merchant has quite the dilemma of risk. So, he considers alternative risk‐mitigation strategies, such as diversifying his risk. In fact, Bernoulli made a point of this as a logical derivation of his methodology. (Because of… ([Location 1091](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1091))
    - Tags: [[pink]] 
- exposed to some danger into several portions rather than to risk them all together.” Easier said than done, it turns out to our merchant. He gets a pretty good deal with the shipper that he's been using for years. If he were to start paring that down and trying to send smaller cargos with a handful of other shippers instead, he would suddenly find that he would be paying much higher shipping costs. What's more, the Baltic isn't the Atlantic; there are fewer ships and fewer diversifying routes. And it's pretty naïve to think that old Jack of the Baltic would let a handful of ships sail right by unimpaired, even if separated by days, and choose only one to seize; any diversification value would likely be overstated. (This is an uncanny parallel to the shortcomings of today's financial market diversification, which we will discuss later.) So much for pirate and weather diversification. Our merchant is left hiring a single ship, setting sail at the mercy of Captain Jack and the Baltic. When that ship leaves port, what follows is only one outcome out of all that might happen. In other… ([Location 1102](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1102))
    - Tags: [[pink]] 
- other way that he might reduce his risk is to just take less of it—with a smaller ship and smaller and less valuable cargo, or else lay off some of his interest to partners. Sometimes that can be a good strategy. He could even decide not to sail at all, keeping the ship in the harbor, as it were. But there must be a better way, he thinks. He doesn't want to cut and run. The only way he can remain a successful merchant is by exposing himself to the risks of the high seas and the pirates lurking therein. He even has his motto framed on his Saint Petersburg office wall: “A ship in harbor is safe …” (What follows is implied, as written much later by John Augustus Shedd: “… but that is not what ships are built for.”) He needs to roll the dice on his financial fate. He spends countless days and sleepless nights plotting his course over the Baltic, with reports on the whereabouts and sailing patterns of the Sudden Death and reams of weather reports and forecasts. He sees this as his treasure… ([Location 1113](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1113))
    - Tags: [[pink]] 
- If only our merchant had read Daniel Bernoulli instead of all of those spurious pirate and weather reports. You see, Bernoulli's framework would have provided him with the intuition to solve his otherwise counterintuitive problem: We start with the merchant's 3,000‐ruble savings plus the 10,000 rubles he would receive from selling his commodities in Saint Petersburg. This is point A on the following chart. Next, we subtract the 800‐ruble insurance premium, moving from point A to point B, to see the logarithmic cost—the vertical line from B to C. (You get a blown‐up view of this in the chart on the right.) This is the cost of insuring—and thus removing—a potential loss from point A to point D, representing the 10,000‐ruble total… ([Location 1124](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1124))
    - Tags: [[pink]] 
- The sum of 100 horizontal losses from A to B (the cost of insuring 100 shipments) exceeds the sum of 5 horizontal losses from A to D (the expected 5 times that there will be a claim over those 100 insured shipments). The difference in the average is the –300 expected loss to the merchant for buying insurance (and the expected actuarial profit to the underwriter). However, the sum of 100 vertical losses from B to C does not exceed the sum of 5 vertical losses from D to E. Not even close. And this shows the impact that owning insurance at this price to remove those 10,000‐ruble losses would have on the geometric average of all possible outcomes… ([Location 1135](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1135))
    - Tags: [[pink]] 
- that mitigates the right risk in a portfolio—and thus prevents it from plunging down the logarithmic curve—and at the right price can both lose money on its own (–300 rubles on average per trip, in this case) and yet raise the portfolio's rate of compounding and its ending wealth. This is what's so decisive about the Petersburg merchant trade: The arithmetic cost of its risk mitigation is more than offset by its geometric effect—such that its net portfolio effect is positive. Just let that simmer for a bit. Without the logarithmic shortcut to the geometric average, this net portfolio effect would be really difficult to visualize, let alone believe. So difficult, in fact, that our Petersburg merchant is too busy plotting his treacherous course to give it any attention whatsoever. Notice on the logarithmic map that, if you ever suffered a one‐period loss of 100%, taking you all the way to zero on the x‐axis and down the curve, then it's game over. You lose all your wealth, and no amount of future profits can compensate. In… ([Location 1141](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1141))
    - Tags: [[pink]] 
- In contrast, if we calculate the arithmetic average, then adding in a total return of 0 isn't catastrophic; it just pulls the average down. The arithmetic losses (represented by the horizontal lines) are but an illusion, existing only in a timeless world. This is because those horizontal incremental losses are not all equal when compounded; they don't simply add up in our merchant's accounting ledger—and this is why he is so blind to the correct accounting. The relative vertical losses are what essentially add up to the merchant's eventual wealth. By focusing only on the horizontal profits and losses, and summing (or averaging) them, our merchant concludes that this risk mitigation is a net cost. Our merchant believes he would be paying more than the insurance is “actuarially worth.” What he doesn't see is that by summing (or averaging) his vertical profit and loss, he gets the real picture of what is going on with his wealth, and why buying (seemingly) “overpriced” insurance is well worth it. To… ([Location 1155](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1155))
    - Tags: [[pink]] 
- plus the 10,000 ruble proceeds (either from selling his commodities or from the insurance underwriter) less the 800 ruble insurance premium, which is 3,000 + 9,200 = 12,200 rubles. On the other hand, without insurance, his geometric average fortune would be 3,000 rubles plus 10,000 rubles in proceeds on 95 trips, and on 5 trips he would only have his original 3,000 rubles (10,000 rubles in commodities lost to Captain Jack). We thus get a Bernoullian geometric expected value, like in the Petersburg wager, of: Strangely, the insurance contract is not a zero‐sum game. The merchant has a geometric expected value gain (from 12,081 rubles to 12,200 rubles, or +119 rubles per shipment) and the insurance underwriter has an actuarial arithmetic expected value gain (of 300 rubles per shipment). Thus, the granting of the insurance contract represents a gain (measured in their own frameworks) for both the merchant and the insurer—it's a win–win,… ([Location 1166](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1166))
    - Tags: [[pink]] 
- Now think about what the geometric average means here from an economic standpoint. Think of the merchant's profits on each shipment in terms of a total return on whatever capital investment was needed to fund that shipment. The total return ratio is simply the ending wealth divided by the beginning wealth, or one plus the return on the starting wealth, which produced the ending wealth. Let's say that the investment needed for that 10,000 rubles in proceeds for his commodities sale was 8,000 rubles. This means he started with 3,000 + 8,000 = 11,000 rubles; if successful, he ends up with 3,000 + 10,000 = 13,000 rubles, or a 13/11 = 1.18 total return (or an 18% profit). But if his shipment is lost, he ends up with just 3,000 rubles, or a 3,000/11,000 = 0.27 total return (or a 73% loss!). Of course, our merchant wouldn't be done after he unloads his commodities in Saint Petersburg. This is his business, and he plans to keep doing this for as long as he can, parlaying his capital on shipment after shipment. His aim is to compound his capital by adding (or subtracting) each of his previous winnings (or losses) to the capital needed for each next shipment, and thus grow his capital geometrically. The words compound and geometric refer to a change or growth in the size of something that is proportional to that thing itself—as in his wealth. Compound or geometric growth is thus multiplicative growth, represented by a geometric progression of returns, where each subsequent outcome is determined by the previous outcome multiplied by the next total return. (And this is the wonderful thing about working… ([Location 1179](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1179))
    - Tags: [[pink]] 
- An Insidious Wealth Tax: The Greater the Loss, the Greater the Profit Needed to Get Back to Even And this is just another way of thinking about the meaning of that logarithmic map. (Flip this curve over horizontally and it becomes something like the logarithmic curve.) Let's say for the merchant's next 100 shipments, 5 of them are total losses (exactly as expected). In that case, his geometric… ([Location 1197](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1197))
    - Tags: [[pink]] 
- And, sure enough, his starting capital of 11,000 rubles times 1.098 equals 12,081 rubles, his geometric expected wealth after just one shipment. (These total return calculations assume that our merchant reinvests the same fraction of his total wealth each shipment, and don't worry about that.) He can expect to parlay his wealth at the rate of 9.8% per shipment without insurance—with a lot of risk. With insurance, he will parlay his wealth at the rate of 12,200/11,000 = 1.11, or 11% per shipment—and he will achieve this higher rate of return with no risk. This is a bizarre notion that even most in the insurance industry likely don't fully appreciate. (The modern investment industry certainly does not.) It should sort of blow your mind. In this example, we've seen that it's possible to invest in an asset (an insurance policy) that by itself yields an expected loss, and yet in so doing we remove all risk from the portfolio while also raising the expected rate of return on the… ([Location 1206](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1206))
    - Tags: [[pink]] 
- iterative, multiplicative impact of that result on the next wager, and on the next! A large loss disproportionately lowers our merchant's geometric average return, because it leaves him with a much lower stake, or capital base, to reinvest and compound on his next shipment. The logarithmic loss shows the true (higher) value‐added for him when he insures against it. But, sadly, the Petersburg merchant will never know, because he never looks at things that way. The subtle implication, then, is if you're going to play a wager once, it had better make sense to make that same wager repeatedly, compounded many times—for an eternity even—whether you actually will or not. One wager or a million wagers, the geometric average return is the one that matters. CONCAVITY OF CURVE Now, clearly, Bernoulli could have just said “geometric average” and been done with it (and saved generations of… ([Location 1217](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1217))
    - Tags: [[pink]] 
- In using the logarithmic function the way he did, Bernoulli gave us a way to think about the problem that we might not have arrived at naturally. As we saw in the logarithmic map of the Petersburg merchant trade—translating from arithmetic to geometric returns—the logarithmic function allows us to better process mentally the ongoing, recursive accruing of geometric returns. It makes the math of compounding intuitive. And it allows us to view and think about raw returns correctly—in the way that they actually impact our wealth over time. Without this map, I'm not sure we could otherwise do that. This is how Bernoulli intended this function to be used. We're not viewing returns, or profit and loss, simply as we experience them, one at a time, as distinct and separate events—“exclusively in terms of themselves”—in their raw, linear, arithmetic form. To get what's going on, we need to experience our returns through the lens of the logarithmic function. In other words, geometrically. But here's the rub. The math of arithmetic averaging is intuitive; the math… ([Location 1228](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1228))
    - Tags: [[pink]] 
- risk and the disastrous impact of losses on wealth. But it is highly counterintuitive. Here you face an inconvenient, uncomfortable but crucial truth: Your raw, linear returns are a lie; your true returns are crooked. Bernoulli's call to map returns through the logarithmic function was thus a normative one, not a positive one. In basing decisions on the geometric average of expected wealth or returns, not on the arithmetic average, Bernoulli was showing us how we should view risk—not how we necessarily do view risk. And this is precisely where economists got it so wrong. In fact, in 1979 behavioral economists Daniel Kahneman and Amos Tversky developed a theory of decision‐making under uncertainty known as prospect theory. This theory implied that people have diminishing marginal utility with increasing gains, like the logarithmic function—as well as with increasing losses. The latter completely contradicts the logarithmic function's increasing marginal utility with… ([Location 1240](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1240))
    - Tags: [[pink]] 
- matter. (There's no grand conspiracy theory needed, just a bit of humanness.) As investors, what we are really doing is trying to perform a mathematical optimization of this logarithmic objective function so we can maximize our geometric return. This mathematical optimization is a loss or cost function that maps raw returns onto their cost to the portfolio's rate of compounding. The goal, therefore, is to maximize that loss function, or minimize its cost. The mathematics of compounding is translated into this objective function. It becomes a way to gauge risk based on how it mathematically describes the consequence of that risk and loss. It shows us what matters to compounding. It is a risk‐enforcer and focuses the mind on which risks move the needle and which do not. Whether we interpret Bernoulli's fundamental idea as a log utility maximization criterion (as economists and even most in mathematical finance would describe it), a geometric mean maximization criterion, or, simply, a way to protect wealth given that… ([Location 1252](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1252))
    - Tags: [[pink]] 
- effective way to value risky gambles—Bernoulli inadvertently revealed the geometric average as the optimal criterion for valuing those risky gambles. Arithmetic returns are false hopes; the truth lies in geometric returns. This criterion is the other Bernoulli principle. The first Bernoulli principle, if not violated, prevents airplanes from crashing; and this one, if not violated, likewise prevents portfolios from crashing. (And this was a very pleasing link for me back in my active pilot years.) THE LOGARITHMIC RHINE FALLS Bernoulli's academic fascination with the behavior of turbulent fluids makes it easy to picture his day trips from Basel up the High Rhine to the Rhine Falls in Schaffhausen, the most powerful waterfall in all of Europe. It is also easy to picture in their cascading cliffs what Bernoulli called the concavity of curve: deceptively placid waters that grow incrementally steeper and more turbulent as you plunge over their precipice into the abyss—from which you might never return.… ([Location 1264](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1264))
    - Tags: [[pink]] 
- this frightful image becomes etched in your mind to help you easily access the meaning of the logarithmic function to investing. Over the Falls We Go: The Logarithmic Curve and the Logarithmic Rhine Falls Bernoulli described this logarithmic concavity of curve as “nature's admonition to avoid the dice altogether.” As we will keep seeing, even “absolutely fair” games of dice (and, often, of investing) can be exceedingly unfair. Best to avoid them. Because the logarithm is a concave function that curves downward, it increasingly penalizes negative raw returns the more negative they are. The steeper the losses, the disproportionately larger the damage they inflict—far greater than… ([Location 1276](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1276))
    - Tags: [[pink]] 
- Petersburg merchant's ship plunged down the curve and over the falls). We know this concavity of curve in our bones—the real bones. It pervades our collective wisdom about investing, perhaps most practically today from Graham's “safety of principal” admonition. And then along came his greatest pupil, Warren Buffett, whose single‐minded emphasis on compounding capital required his cardinal rule: “Don't lose money.” And now we really know why. The corollary is clear: Profit is finite. Risk is infinite. You need to avoid plunging down the logarithmic Bernoulli Falls! This is, by far, the most important concept in safe haven investing—nay, of all investing. In the end, time resolves the Petersburg paradox. If you take the exponential of the average log return of your next wager, then you get the geometric return that you can expect by parlaying that same wager forever. You do not have to run the machine through time to figure that out. So, you had… ([Location 1285](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1285))
    - Tags: [[pink]] 
- return distributions, or whatever. Rather, it is a physical fact of precisely how compounding and investing work in the real world. As we saw, it is why an arithmetic cost can be more than offset by a geometric effect in the Petersburg merchant trade. This will become clearer… ([Location 1297](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1297))
    - Tags: [[pink]] 
- Nietzsche eventually expanded the eternal return into a book of quasi‐biblical parables, his 1885 magnum opus Also sprach Zarathustra (Thus Spake Zarathustra). First, though, he would introduce it by sending up a ([Location 1320](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1320))
    - Tags: [[pink]] 
- trial balloon. At the end of his 1882 book Die fröhliche Wissenschaft, or The Gay Science (not to be confused with the truly “dismal science” of economics), under the heading “The Greatest Weight,” Nietzsche proposed a thought experiment: ([Location 1322](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1322))
    - Tags: [[pink]] 
- What if some day or night a demon were to steal after you into your loneliest loneliness and say to you: ‘This life as you now live it and have lived it, you will have to live once more and innumerable times more; and there will be nothing new in it, but every pain and every joy and every thought and sigh and everything unutterably small or great in your life will have to return to you, all in the same succession and sequence—even this spider and this moonlight between the trees, and even this moment and I myself. The eternal hourglass of existence is turned upside down again and again, and you with it, speck of dust!’ Would you not throw yourself down and gnash your teeth and curse the demon who spoke thus? Or have you once experienced a tremendous moment when you would have answered him: ‘You are a god and never have I heard anything more divine.’ If this thought gained possession of you, it would change you as you are or perhaps crush you. The question in each and every thing, ‘Do you desire this once more and innumerable times more?’ would lie upon your actions as the greatest weight. Or how well disposed would you have to become to yourself and to life? I must admit, the first time I encountered this, it rattled me. I started looking at things differently. Every moment seemed to slow down and somehow became perfect, even when it wasn't. It had to ([Location 1326](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1326))
    - Tags: [[pink]] 
- be. Nietzsche called this his “highest formula of affirmation”—life affirmation. And in it I also found something that applied specifically to investing, something I had not been able to put my finger on or articulate before. There is so much muddled, superficial narrative in the investment industry. So much movement, so little action. There are grandiose forecasts of when to take risk and when to retrench—but which ignore the results of these forecasts. Wise people speak of shunning risk through diversification, dubbed “the only free lunch in finance,” using financial engineering terms that few even bother to understand, and spreading risk across assets in hopes of capturing some safer, mediocre average performance. No matter what it cost you, your intentions were good, and at least you evaded disaster; your risk‐adjusted returns were high—though you’re poorer. ([Location 1337](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1337))
    - Tags: [[pink]] 
- The conventional approach to risk mitigation in the investment industry is deceptive and defeatist, with so little substance and significance, and so much smoke and mirrors. It disregards economic meaning in favor instead of quantitative meaning and accepts bad results all in the name of safety from bad results. Fate loves irony. It is nihilistic financial theater. ([Location 1345](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1345))
    - Tags: [[pink]] 
- Investing can't just be about taking bold bets on our clever expectations and then downplaying their outcomes, as if renouncing any attachment to the fruits of our actions. “I was right, but unlucky.” We know we cannot judge our decisions only by their outcomes—as good decisions can easily have bad outcomes. But we only get one outcome. If Nietzsche's demon is correct, and we must live with our results “once more and innumerable times more,” do you really want to keep on ignoring the same bad outcomes over and over for eternity? You need a better perspective to become a better investor and, whether we accept Nietzsche's perspective as true or not, I am convinced his is the one. Nietzsche's “joyful wisdom” has been around a long time. It's an ancient idea, this concept of a cyclically repeating time. As a woodland dwarf perched on the pyramidal rock exclaims to Zarathustra, “Everything straight lies, all truth is crooked, time itself is a circle.” This belief has been consistent throughout our human history, in the ancient Mayan, Aztec, Egyptian, Judaic, and Greek traditions (with… ([Location 1349](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1349))
    - Tags: [[pink]] 
- When Nietzsche writes that “the task is to live in such a way that you must wish to live it again,” it sounds as if his teaching is all about the wish; but then he follows that with “—you will do so [live again] in any case!” Nietzsche was seemingly compelled by the eternal return as a cosmological fact, and even worked out physical proofs in his unpublished notes exploring the eternal return as material reality. And this notion was taken up eight years later by the great French polymath mathematician Henri Poincaré, in his “recurrence theorem,” which asserted that certain mechanical systems will inevitably and eternally return to any given state. This was a more rigorous version of Nietzsche's own attempt, where he observed: “In the great dice game of existence, [the world] must pass through a calculable number of combinations. In infinite time, every possible combination would at some time be realized; even more, it would be realized an infinite number of times.” Since this implies that we aren't just repeating one path, but all paths, Nietzsche's proof here loses some of its punch, but it deserves props for effort. Nevertheless, the proofs of tradition… ([Location 1360](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1360))
    - Tags: [[pink]] 
- all previous values are devalued.” The act of believing was far more important than the validity of the belief. The eternal return was intended by Nietzsche to be a normative, existential imperative. Like Bernoulli's emolumentum medium, it was prescriptive, an internal valuation metric, and a practical guide or perspective for our actions; it was not a positivist claim. At its heart, it is even a psychological hypothesis: “Do you desire this once more and innumerable times more?” Would you curse or kiss the demon? This question is at the very heart of successful investing in general, and safe haven investing in particular. The ability to answer “yes” to the prospect of experiencing the same investment return as an eternal return is a most powerful force and focuses the mind. It should change the way you invest by changing your internal valuation metric: that is, the value of getting this path right eclipses the value of getting the expected path right. It's a little unsettling to think about: You ultimately endure the weight of only one path, the actual path. And really grasping this… ([Location 1373](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1373))
    - Tags: [[pink]] 
- as if you will. If taken seriously, Nietzsche's idea can have a monumental impact, the greatest weight—shattering and transforming your temperament and disposition. Arguably, these two sentiments are the most important things to get right as an investor. We have just one life, but our fate is a range of outcomes. The one realized outcome is naturally not deterministic (even though our ancient ancestors would have disagreed). Against this realization, Nietzsche's demon throws down a psychological gauntlet: care more about getting it right than casually gambling with that range of fate. In Nietzsche's thought experiment, the sample size equals 1, Nietzsche's N = 1. His demon just wakes us up to that fact. Thanks to multiplicative compounding—as we saw in the Petersburg game—we don't really have a series of moments that just aggregate. We don't have an ensemble of games to play, though it seems like we do. We get to select just one outcome from the infinity of the sample space. So we cannot afford much sampling… ([Location 1386](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1386))
    - Tags: [[pink]] 
- That's not so obvious to understand—and it's even harder to act consistently with that reality. What Nietzsche was surely trying to do was shine a bright light on the significance of this path—the one you're on—and ignore all the others. Own up to it: you're going to live this one path for eternity. So, to hell with all the other alternative paths; to hell with your guestimates of probability, expectation, and risk. No more, “Oh, I just got unlucky, but my expectation was right!” We don't have the luxury to just be right in expectation or in theory; we have to just be right. We only get one go at this, and that's it. This certainly doesn't mean that expectations don't matter. The eternal return cuts both ways. Focusing on this path means not succumbing to any potential path—no matter how unlikely—that gives you a horrible expectation, just as it means not having a great expectation that you'll rarely if ever realize. And yes, there are repeatable trials in investing; sometimes along our one path we can get many bites at the same apple. But it's not automatic. And it's… ([Location 1397](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1397))
    - Tags: [[pink]] 
- Mantle took it over). But what if he was given just one at bat for his entire career? Then what? By giving all the weight to this path, we essentially need to have gotten pretty much every possible path right. We need to be robust to the realized path—to have “covered all the bases.” This means optimizing risk by investing in a way that, whatever happens, we can declare, as Nietzsche exhorts, “Thus I willed it!” When it comes to the function of risk mitigation in an investment portfolio, what better statement could there be? INTO THE MULTIVERSE Think of the opening line to that Robert Frost poem “The Road Not Taken” (a poem which my dad always reminds me of, still): Two roads diverged in a yellow wood, And sorry I could not travel both And be one traveler, long I stood Are we sure we cannot travel both? If we could, it would be the opposite of the… ([Location 1409](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1409))
    - Tags: [[pink]] 
- loneliest loneliness. This time, he tells you that, rather than reliving this life once more and innumerable times more, you are going to live an innumerable number of parallel, alternate lives—all at once and at the very same time. “Don't believe that other demon from the night before,” he snarls. “Instead of living just one life repeatedly and infinitely, you're actually going to live infinite lives, each one branching off, side‐by‐side.” You are your own Schrödinger's cat, the thought experiment concocted in 1935 by Austrian physicist Erwin Schrödinger, whereby events branch off in such a way that a cat trapped inside a box and randomly poisoned gruesomely exists both alive and dead, simultaneously. More precisely, Schrödinger's cat is in a quantum mechanical state, and the accounting can get a little tricky when you try to calculate all of the potential dead and alive states of this poor, abused (thankfully, hypothetical) cat. But mathematically it's perfectly valid. According to this new demon—let's call him Schrödinger's demon—you, too, will… ([Location 1423](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1423))
    - Tags: [[pink]] 
- universes coexist. In this version, starting right now, a new universe is spawned with everything that happens to you—“everything unutterably small or great,” whether it's your luck randomly turning a different way, your next decision changing, or whatever. Every new fork in every new path is followed by another copy of you—your doppelgänger. Instead of Nietzsche's circle, time is now a tree with infinitely many tangled branches. The multiverse is the entire sample space of all the branches and all the ways that things could have happened. This notion of the multiverse is supported by science and is even indirectly, experimentally testable, in a way that is ironically very similar to Nietzsche's own “great dice game of existence” proof of the eternal return. Here, quantum mechanics imagines a thrown die landing on all six sides simultaneously. It's just like from Nordic lore, where a rolled die miraculously splintered into six pieces, such that all six sides turned up on the same roll. While we see just one side land from the narrow perspective of our own universe, there are five other branching universes, each… ([Location 1434](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1434))
    - Tags: [[pink]] 
- Sound crazy? Well, consider this: from this perspective, you'll actually know what it feels like to be the casino, to get to run repeated, concurrent trials of your life's rolls of the dice, over and over again for eternity. No more good or bad luck, no more sampling error, just one realized expectation across the multiverse. You can make sound decisions based on that expected value, as you get to experience every possible path. These two perspectives from our two opposing demons parallel the opposing perspectives of probability itself—the single subjective trial vis‐à‐vis the many frequentist trials. Which demon do you believe, and how does your choice affect your approach to life and to your investing? Is your choice a decisive factor in the way that you would… ([Location 1446](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1446))
    - Tags: [[pink]] 
- In probability theory, a random process is called ergodic when its arithmetic average across the sample space of all possible outcomes over a period of time (known as the ensemble average) is the same as its geometric average outcome over that same period (known as the time average). But let's not overthink this, and let's keep it simple: Non‐ergodicity effectively just means that your average outcome is much higher than your median outcome; so, your distribution is very positively skewed. Focusing on that average means you are focusing on something that, unlike the median, you ([Location 1618](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1618))
    - Tags: [[pink]] 
- expect to exceed less than (and sometimes far, far less than) half of the time. That's it. The multiverse, then, is ergodic—as you actually experience the arithmetic average return compounded over time (and the average outcome is thus the same as the median). But none of us lives in that ergodic multiverse. Only with Schrödinger's demon do we get to experience the average return across many 300‐roll games. Alas, we are not a casino. Rather, we are more like a single lottery ticket (though, in this case, one with a very positive edge) as we stand in just one universe, experiencing only one 300‐roll game. The eternal return is clearly highly non‐ergodic. Even when we have many compounding steps, or 300 rolls of the die, because of non‐ergodicity our N still equals 1. We should feel the greatest weight from that. To sum it up here briefly, the two demons' perspectives are mutually exclusive and collectively exhaustive; we have to accept one or the other. Our expectation formed from the multiverse return won't tell us much about what to expect from the eternal return. And, of course, the latter best represents our reality. The frequentist perspective of the multiverse is an illusion, and it will therefore abjectly fail us; it will fool us into doing the wrong thing. ([Location 1624](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1624))
    - Tags: [[pink]] 
- Like the Bob Dylan song goes, “Tomorrow is never what it is supposed to be. Thanks to non‐ergodicity… ([Location 1636](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1636))
    - Tags: [[pink]] 
- The big advantage to the geometric average return calculation is that it avoids the non‐ergodicity problem; it actually maps and tracks the evolution of your capital base through time, something which is lost within the arithmetic average. The geometric return actually is your capital base—it directly translates from returns to wealth. With the arithmetic return you also need to know what the path looks like in order to make that translation; it is path dependent. The capital base is the stake—the very thing that returns are built on, so modern finance's focus on returns while ignoring what they mean for that capital base is just nonsensical. It's shortsighted and naïve; it's as if time is irrelevant, and “everything happens at once.” It's like a farmer focusing on crop yields while ignoring soil degradation. Oops, most do that… ([Location 1639](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1639))
    - Tags: [[pink]] 
- But when you shift your focus to that capital base and the geometric average of returns, magical things can start to happen. So, can you do the same thing with your demonic dice games, something a little more regenerative (like those farsighted farmers preserving the soil)? Let's say that, instead of always going all‐in on each roll, you only bet 40% of your total remaining cash on each roll. You keep the remaining 60% on the sidelines earning nothing, and this means that you are cutting by 60% your… ([Location 1648](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1648))
    - Tags: [[pink]] 
- Our suggested betting strategy is an example of what is known as the Kelly criterion, dating back to 1956, and named after John Kelly, who was a researcher at Bell Labs. Kelly came up with the criterion as an extension of his colleague Claude Shannon's concept of information entropy (or the degree of information or “surprise” within a crackly communicated message). Kelly's simple formula sized gambling bets based on one criterion: maximizing ([Location 1678](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1678))
    - Tags: [[pink]] 
- the expected geometric average of ending wealth (even at the expense of the arithmetic average). You could think of it as formalizing what Daniel Bernoulli first demonstrated back in 1738. And it was first applied formally to the world of investing by Henry Latané in 1959, though abjectly scorned. (Of the two, only Latané read and was heavily influenced by Bernoulli and his paper that was recently translated at the time.) My dice game examples in this chapter very much piggyback on Latané's important work, specifically; Latané was a trailblazer, and deserves so much more credit in investing than he ever gets. Since then, others have carried the ball for Bernoulli, Kelly, and Latané. There was John Burr Williams in 1936 (perhaps the first to emphasize geometric mean maximization since Bernoulli) and Leo Breiman in 1960 (who showed that a geometric mean maximizing strategy both minimized the time to reach a target level of wealth and maximized the level of wealth reached after a given amount of time—and who wouldn't sign up for that?). Ironically, even Harry Markowitz, the original architect of modern portfolio theory in 1952, had become a proponent of the geometric mean criterion by 1959 (and very much so by 1976); but it was too late, as his modern portfolio theory framework had already taken hold—and the rest is history. Perhaps most notable was the magisterial work of Ed Thorp, who has both written ([Location 1682](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1682))
    - Tags: [[pink]] 
- about it and put it into practice since the 1960s. Much more recently, Ole Peters has written exhaustive and insightful papers on non‐ergodicity's implications for economic theory. And, of course, Nassim Taleb took up the point in his 2018 book Skin in the Game of the non‐ergodicity of the one‐period ensemble average versus the multi‐period time average. (As Nassim wrote, “more than two decades ago, practitioners such as Mark Spitznagel and myself built our entire business careers around…the effect of the difference between ensemble and time.” That pretty much sums it up.) For a good, not‐too‐technical read on all of this, see the 2005 book Fortune's Formula by William Poundstone; by 2005 I had already long been up to my neck in all of this, and yet it further opened my eyes to the implications of this simple distinction. All three of our triad, Bernoulli, Kelly, and Latané, had their own spin—as well as those who have carried it on. But each points to the very same geometric mean maximizing criterion of our Petersburg merchant trade. Kelly's exact formula here isn't… ([Location 1692](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1692))
    - Tags: [[pink]] 
- recalculating the geometric average return or median ending wealth for each weight. (Recall that this is very similar to the iterative search that we did to find the fair value of the Petersburg wager.) The weight with the highest median ending wealth is the Kelly‐optimal… ([Location 1704](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1704))
    - Tags: [[pink]] 
- It seems the Kelly criterion could be more descriptively called the Goldilocks criterion; it must be just right. Setting aside too much of your cash is a bad idea because you aren't betting enough; it's too conservative. Not setting aside enough cash is also a bad idea because you're betting too much; it's too aggressive. Somewhere in between—in this case, just under 40%—is just right. (Don't think that this… ([Location 1710](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1710))
    - Tags: [[pink]] 
- This also shows why, in case you were tempted, you can't just bet 1/300th of your wealth each toss, and thus receive the arithmetic average across 300 tiny bets. Well you can, but it would be a waste of time. Only a casino can do this by dicing its bets up each period (diversifying its risk, Daniel Bernoulli‐style), not just dicing them up across time, because it has so many independent, simultaneous rolls of the dice available to it each period. But you don't have a room full of Nietzschean demons to play simultaneous, independent games against. (You are not a casino.) One might say that there is a certain arbitrariness to selecting the 50th percentile to maximize. It could seem rather chauvinistic toward other percentiles. The other, lower curve on the graph shows what happens to the 5th percentile ending wealth outcome (the lower bound of the shaded middle 90% confidence interval in previous graphs), meaning the level of wealth that 95% of the time you expect to meet or exceed. That curve peaks at just under a 10% bet size, a much lower percentage of wealth per roll than the almost 40% where the median curve peaks… ([Location 1714](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1714))
    - Tags: [[pink]] 
- size, which effectively maximizes arbitrarily lower percentile outcomes like this 5thpercentile curve (which is maximized at about a quarter‐Kelly), at the expense of the median outcome. This 5th percentile outcome is known in the investment industry as value at risk, or the 5% VaR. In our case, where the sample space of outcomes is well defined, this 5% VaR is an excellent way to define the degree of risk in the game. After all, we defined risk as exposure to bad contingencies, or these worst potential paths. So think of these worst paths as Graham's margin of safety; the higher that 5th percentile outcome, the greater the margin of safety, and the safer the wager. In the real world, of course, these bad outcomes are not so well‐defined. There is a spuriousness to the measurement of a portfolio's VaR, and an extremely naïve lack of robustness to its estimation, to the point that its use can do far more harm than good when actually relied upon. This will be a very important point for us in later chapters. But for our dice games, the 5% VaR is an ideal proxy… ([Location 1725](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1725))
    - Tags: [[pink]] 
- insist that leverage is basically always good when the expected arithmetic returns are positive like this. After all, leverage simply raises the arithmetic average, or expected return, and it doesn't affect the ratio of the average return to the standard deviation of those returns. (A plot of the Sharpe ratios overlaid on the previous chart would simply be a horizontal line—more free money for all as leverage increases, meanwhile ending wealth plunges.) And less risk would always only mean less return. What a disaster those superficial, pseudoscientific tools are! Leverage can indeed kill the golden goose. (Just ask the investors of the hedge fund Long Term Capital Management.) Now think about this for a second. If setting aside 60% of your stack of cash raises your end‐point wealth from 0 to 7 times your starting wealth over 300 rolls, then in a vacuum you could reason that the rate of return on that cash must have compounded at a fixed 0.8% on each toss—like a fixed annuity. But in fact, our sidelined cash did not earn any interest… ([Location 1738](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1738))
    - Tags: [[pink]] 
- dynamics of the game—in other words lessening the pain of bad contingencies (the pain of the concavity of curve) in a way that raises the median contingency. Under multiplicative dynamics, it's really hard to recover from big losses. And another good measure of the improvement from moving to the Kelly optimal weighting from a larger bet size is the improvement to that 5th percentile outcome that we saw in the previous graph.… ([Location 1748](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1748))
    - Tags: [[pink]] 
- And here's a better look at the two frequency distributions, the all‐in bets next to the 40%… ([Location 1756](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1756))
    - Tags: [[pink]] 
- The interesting thing is that the arithmetic average return is lowered (visible in the arrow pointing to the left), and everything else being equal that would also lower the geometric average return. But the geometric average or median return is actually raised, in what we will call the net portfolio effect (visible in the arrow pointing to the right). There are really two contrary forces acting on our… ([Location 1761](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1761))
    - Tags: [[pink]] 
- effect. When the latter is greater than the former as it is here, the result is a positive net portfolio effect and cost‐effective risk mitigation. The tension between these two often hidden… ([Location 1765](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1765))
    - Tags: [[pink]] 
- A GLIMPSE OF TREASURE Let's summarize what you have seen in our deductive games of dice up to this point. (And if you skipped the math, you can catch up here, although that means you'll just have to trust me, and you missed out on all the dramatic reveals—poor you!) To start, you have seen what the dynamics of compounding mean for risk mitigation. More specifically, you have seen how the multiplicative dynamics of gains and losses, compounding one after the other, bring you to your wealth at any moment; and you have seen how changes in those dynamics through risk mitigation can impact the expected growth rate of that compounding. The bigger a loss, the more it incrementally and disproportionately lowers that growth rate, more than just the visible amount of that loss. Not all losses and not all risks are created equal, so not all risk mitigation is created equal. ([Location 1894](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1894))
    - Tags: [[pink]] 
- Our aim as investors is to maximize the rate at which we compound our wealth over time on our one and only realized outcome. This is among our first principles of investing, what we now know as Daniel Bernoulli's principle of investing. And it entails raising or maximizing our expectation of the geometric average—or the median as well as, better yet, all the other percentiles—across all our potential ending wealth outcomes. To do this, we need the concave logarithmic function as our objective function. Don't plunge off Bernoulli Falls! Put simply, we need a risk‐mitigation strategy that makes our returns both more accurate and more precise, to win the bloody “war with luck.” Best of all, you have seen the fundamental mechanism in action that does that—the mechanism underlying the Petersburg merchant trade and essentially all cost‐effective risk mitigation. You have seen it in two basic safe haven strategies: the store‐of‐value safe haven (or Kelly‐optimal strategy) and the insurance safe haven. These two strategies will represent the two far ends of the diverse spectrum of safe haven mechanisms. As we will see in Part Two, in the real world, when cost‐effective safe havens like these actually exist—if they do at all—they fall somewhere along this spectrum. And depending on where they fall, they ([Location 1902](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1902))
    - Tags: [[pink]] 
- can be very different from each other in their cost‐effectiveness. Most importantly, we now have the deductive machinery in place to establish our safe haven hypothesis. We are on a treasure hunt. We have a compass, facing true north—to maximize our compound growth rate. We are still in search of our map leading to that elusive buried treasure. But we know we are getting close. ([Location 1915](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1915))
    - Tags: [[pink]] 
- You see, people tend to accept the classification of safe havens by common parlance. Think of our previous definition as a payoff that mitigates risk or the bad potential economic contingencies in a portfolio; as such, a cost‐effective safe haven is one that, in addition, raises wealth over time. But how do we recognize a safe haven's capacity to do this before it does? (What good is knowing after?) Is there anything particular about them—some ([Location 1944](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1944))
    - Tags: [[pink]] 
- essence, or lines of demarcation that define them for what they are? More broadly, is “safe‐haven‐ness” even a classifiable thing—what we would call a “kind,” or a group with shared traits? If so, is this kind basically one homogeneous blob? And if not, how can we further organize them across their variations such that we can better understand them and, most of all, use them? ([Location 1948](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1948))
    - Tags: [[pink]] 
- In this sense, Aristotle and his nineteenth‐century fellow naturalist and biologist Charles Darwin had more in common than is often thought (beyond Aristotle's dice contemplations and Darwin's obsessive nightly backgammon game). Darwin was rather unconvinced about the existence of species in the first place. In particular, diversity and change were so dramatic, they could no longer be thought of as static. This led him, of course, to a theory of natural selection and his opus, On the Origin of Species. ([Location 1979](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1979))
    - Tags: [[pink]] 
- What Aristotle and Darwin observed in the natural world can guide us in our study of safe havens. The diversity and change within the safe haven species is so great that it, too, could form new ones. Its members have their own different phenotypes, making some far more advantaged or cost‐effective (fitter) than others. Thus, we have our own safe haven species problem: Can we identify a safe haven “essence” and use it to classify them? Or are they all just individual things—each one of a kind? Further confounding the problem, our classifications are a moving target. Essential safe haven features may emerge at one point in time, and later vanish, just as biological traits can change with time. Treating them like they are fixed—like Plato's unchanging essences, and as many did when considering species before Darwin—is to naïvely succumb to the retrospective safe haven fallacy. But if we cannot classify them by their essentials, it will be impossible to see if our dice game “guesses” thus far about how they work actually agree with real safe havens. If we can't get that far, then this was all just more of the same financial theater—more ambiguous risk‐mitigation narratives or, worse yet, academic exercises. To put it in blunt terms, if we cannot identify safe havens that are cost‐effective, then they are only places to hide out—like a ship in harbor. (“A ship in harbor is safe…”) ([Location 1983](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=1983))
    - Tags: [[pink]] 
- Among investment strategies, the best example of this problem of classification is in value investing. Started by Benjamin Graham, it is about buying securities cheap compared to their intrinsic value—and good luck agreeing on the meaning of intrinsic value. In Graham's case, this mostly meant book value, or tangible value of a company's assets. For Graham, buying cheap to book often meant purchasing “cigar butts,” as Warren Buffett called them, or companies that were on their last puff and priced accordingly. These companies typically have very low profit margins and very low returns on invested capital. In fact, most basic value screens tend to align with these low returns on invested capital. But tell that to Warren Buffett, considered the greatest value investor ever, and who explicitly screens stocks based on high returns on invested capital. A company's intrinsic value is elevated by higher perceived returns on its invested capital, and this can create value relative to its stock price. It is difficult to find an essence of the species among value stocks. They are too different, and those differences are always in flux; there are too many “accidents.” Value can become a misnomer. ([Location 2011](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2011))
    - Tags: [[pink]] 
- It might be even harder to find an essence of safe havens. And yet people nonchalantly classify them that way anyway. They are more of a heterogeneous than a homogeneous set. As we will see, not all safe havens are created equal. Indeed, not all safe havens are even safe havens—and certainly very few, if any, are cost‐effective. But we owe it to ourselves to find out, and to at least establish a criterion for measuring them against each other. ([Location 2020](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2020))
    - Tags: [[pink]] 
- I prefer to call the asymmetric and explosive downside protection provided by the insurance cartoon payoff its crash‐bang‐for‐the‐buck. The more, the merrier. ([Location 2093](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2093))
    - Tags: [[pink]] 
- Safe havens can be exceedingly costly, so much so that, as a cure, they can be worse than the disease. Nietzsche said it best: “Whoever fights monsters should see to it that in ([Location 2099](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2099))
    - Tags: [[pink]] 
- the process he does not become a monster.” This is the risk‐mitigation irony (and fate loves irony). ([Location 2100](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2100))
    - Tags: [[pink]] 
- The vast majority of presumed safe havens suffer from this same irony. They involve much movement, with little action. And they even do more harm than good—as monsters in disguise fighting monsters. They simply do not provide very much (if any) portfolio protection at all when it matters; therefore, the only way for them to ever provide meaningful protection is by representing a very large allocation within a portfolio. The problem, then, is that this ([Location 2111](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2111))
    - Tags: [[pink]] 
- very large allocation will naturally create a very large cost, or drag, when times are good—or most of the time—and even on average. After the dust has settled, you would have likely been safer with no safe haven at all. Here we see the fundamental difference between a tactical versus a strategic investment, particularly in the context of safe haven investing. A strategic safe haven is about mitigating systematic risk in a portfolio through asset allocations that are more fixed in nature and then letting the dynamic interplay between its parts create the portfolio effect. A tactical safe haven, on the other hand, is about mitigating systematic risk in a portfolio by periodically and actively moving in and out of certain “safe” allocations, with the well‐intentioned purpose of saving on the high cost of that safety when times are good. Such a tactical approach to risk mitigation is a very binary one, meaning either “on” or “off.” Doing this cost‐effectively, by definition, requires timing and short‐term forecasting skill—you need a magic crystal ball. But this is an internal contradiction. Cost‐effective risk mitigation can never require a magic crystal ball. We mitigate risk specifically as an acknowledgment and presupposition that we don't possess a magic crystal ball; if you had one, then you wouldn't have risk to mitigate, and you certainly wouldn't need this book. And lest I forget to mention, there are no magic crystal balls! (And the more ([Location 2114](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2114))
    - Tags: [[pink]] 
- someone disagrees with that statement, in my experience, the worse their crystal ball tends to be.) If your risk‐mitigation strategy requires one to be successful, well, then you are just doing it wrong. While you can perhaps afford the luxury of prediction in other aspects of your investing, you certainly cannot in your risk‐mitigation strategy, where the costs of being wrong are too great. Don't fall for it, and “don't predict.” As we will see later, to work cost‐effectively, safe haven investing needs to be agnostic investing. Cassandras typically and ironically lose more in their safety from looming crashes than those crashes would have even harmed them. (Cassandras make very bad investors.) Markets scare us far more than they harm us. They are very, very good at making us feel safe when we shouldn't and scared when we needn't. This is the market's inherent, constant deception to rid investors of their positions. Cost‐effective risk mitigation cannot be a specific act; it must be an ongoing policy. In the words of Aristotle: “As it is not one swallow or a… ([Location 2127](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2127))
    - Tags: [[pink]] 
- The hopeful haven as risk mitigation is like jumping out of an airplane with a parachute that only sometimes deploys; you're better off not wearing one in the first place and making a more informed decision about the risk you're taking. ([Location 2156](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2156))
    - Tags: [[pink]] 
- The retrospective safe haven fallacy, put simply, is playing Monday morning, armchair quarterback (meaning making judgments after a game is over, from the safety of an armchair, as opposed to while actually playing on Sunday when NFL games are typically played), second‐guessing or reenacting real‐time decisions after those decisions were actually made by someone else. It is also known more formally as retrospective determinism, hindsight bias, or, best of all, the knew‐it‐all‐along phenomenon, whereby it is accepted that because a series of events, such as a market crash, happened a certain way under specific historical circumstances, what occurred was therefore the inevitable ([Location 2165](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2165))
    - Tags: [[pink]] 
- consequence of those circumstances. Risk somehow always appears so obvious and predictable, and the last crash always made so much sense, retrospectively, that is—based on what we now know, but what wasn't known at the time. It's a funny thing, isn't it? Given the brilliant and confident insights that one receives from the retrospective fallacy, one might easily extend that into grandiose forecasts about how things will happen next, and further spin that into a brilliantly effective risk‐mitigation strategy. People actually do this, like all the time. I call this the prospective safe haven fallacy, and it takes the form of presumed skill in macroeconomic and market timing—based on the presumptions that the next crash will have similar characteristics and internal market relationships (or “cross‐correlations”) to past crashes. The next crash rarely does—or it does just enough to catch those committing the retrospective safe haven fallacy in its trap. To borrow the wise words of Victor Niederhoffer, there are “ever‐changing cycles.” In many ways, the creeping escalation of complacency in naïve and “knew‐it‐all‐along” risk mitigation is at the heart of why crashes happen in the first place. A reliable indication that this fallacy is at work is when bold forward‐looking statements about a particular risk‐mitigation strategy are uttered by someone who has never actually done it, in real time (as in during the Sunday ([Location 2170](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2170))
    - Tags: [[pink]] 
- game, as opposed to on the following Monday from their armchair). It is a kissing cousin to datamining, or overfitting, surely the most well‐trodden pitfall in the data sciences. There will always be flawless, successful strategies to be gleaned from past data, from randomness alone. There is a deceptive narrative basis to such strategies that always sound so reasonable and plausible; they have charm and seductive powers. So it's a pretty easy sale, really. Sad to say, but heuristic storytelling plays a huge roll in what risk mitigation has become. It is financial theater. This narrative is what also leads to the second variety of our imposters, the unsafe haven. The unsafe haven looks very attractive because this asset or strategy has so far always gone up, so it likely has a good story for why that should always be the case. The logic is then extended to their performance in a crash. But they are often as vulnerable in a crash (or even more so) as that which they are intended to protect. Perhaps they have even shown some evidence of that vulnerability. But that doesn't change the optimism around their presumed safe haven status. This… ([Location 2182](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2182))
    - Tags: [[pink]] 
- Often, it's a fool's errand to even try to make logical statements against it. Best to just recognize it for what it is… ([Location 2193](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2193))
    - Tags: [[pink]] 
- THE DOGMA OF DIVERSIFICATION Our third variety of safe haven imposters, the diworsifier haven is without a doubt the most common form of safe haven imposter. It is pervasive throughout almost all investment portfolios. This is because diversification as a risk‐mitigation strategy is the central pillar to the central paradigm in all of investing: modern portfolio theory. Most, and likely pretty close to all, investors have been led to accept this dogma of diversification. It is considered “the only free lunch in finance.” Recall from Chapter 2 that the credit for this formal concept of diversification actually goes all the way back to eighteenth‐century Basel, Switzerland, where Daniel Bernoulli proposed it as a solution for his hapless Petersburg merchant to get his cargo ship past pirates and across the Baltic Sea: break his cargo up into smaller cargos and send all those smaller cargos on different ships. It was a diworsifier for the merchant back then, much like it is for us now. The diworsifier haven is named after what Peter Lynch referred to as diworsification. The thinking goes like this: ([Location 2196](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2196))
    - Tags: [[pink]] 
- Fill your portfolio with things that don't all move around together and, as a result, your portfolio will move around less. And thanks to this diversification, your portfolio's performance in a crash will likely fare somewhat better than the broad market (which, by the way, is also pretty diversified). Best of all, your volatility will be lowered. But so, too, will your returns, as this diversification comes at a pretty price in the form of underperformance costs during noncrash periods (by the same logic as its outperformance during crashes). Over time, the “diworsification” ends up costing more than it saved (hence the cute name). But as long as your average returns are lowered less than your volatility (meaning your dreaded Sharpe ratio is raised), something purposeful is presumed to have happened. This is so wrong on so many levels—not a terribly insightful comment by me. As Buffett himself has said, “Wide diversification is only required when investors do not understand what they are doing.” What's more, diversification is “a confession that you don't really understand the businesses that you own.” To add insult to injury, I would add that diversification is a confession that you don't care about cost‐effectiveness in your risk mitigation. You just want less risk, no matter the cost. ([Location 2206](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2206))
    - Tags: [[pink]] 
- Diversification, then, is either about potentially less risk in exchange for less return, or it is about moving from systematic or concentration risk to levered model risk. It is not a free lunch. There is no free lunch (though cost‐effective risk mitigation does seem to look like getting paid to eat lunch). ([Location 2233](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2233))
    - Tags: [[pink]] 
- We have created these toy safe havens. Now, before we start playing around with them, we need to make a new toy to replace our dice from Part One. We are inching closer to the grittiness of the real world. We've moved beyond the punching bag of dice games to now letting our safe haven prototypes spar it out. (As a wise person once said, “Everyone has a plan until they get punched in the mouth.” While punching a bag and sparring are very different from the real thing of a fight, they are necessary training practices for the real thing—as long as ([Location 2237](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2237))
    - Tags: [[pink]] 
- contingencies like getting an elbow to the head or a kick in the groin are never assumed away.) In our various dice games in Part One, we discovered our safe haven mechanisms by observing how different risk‐mitigation strategies, or safe haven payoffs, transformed the potential outcomes of different wagers on a simple sequence of dice rolls. Each roll involved a multiplicative, geometric progression of the wagerer's wealth; and each recursive iteration of that progression was determined by the roll of the six‐sided die and the payoff associated with it. Recall in Chapter 3 how these different corresponding payoff profiles and die faces created a discrete probability distribution for each roll, where the height of the stacked dice indicated the probability of each corresponding return outcome below it. Here it is again, as a reminder: ([Location 2242](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2242))
    - Tags: [[pink]] 
- We have an interesting turn of the dice here. In sampling all these empirical market observations by rolling a d120 die and then attempting to make generalizations about those observations, we are now essentially rolling an inductive die. For instance, across all of these potential paths, notice that the median CAGR is 9.5% and the 5th percentile CAGR is 2.7%. These CAGR values will be key in our tests going forward. This is because this distribution of SPX paths can be thought of as our control group or baseline case as we go about combining them with various safe haven payoffs to see what happens next. And what happens next is where things get interesting. ([Location 2301](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2301))
    - Tags: [[pink]] 
- Reductionism didn't work well for me with cuckoo clocks. The reason? The functional value of the individual components was only a result of their relation to each other. There were what are called emergent properties that do not exist in the individual components. These properties are only apparent when viewed holistically as a whole. Emergent behavior arises in many well‐known systems where interacting individual parts create complex, unpredictable, and irreducible behavior: flocks of birds, schools of fish, herding land animals, language, the mind, economies, markets, and so on. (I used to hone my pit trading by studying the movements of flocks of birds, real and simulated. There, you have a trade secret.) And the same is very true of safe haven investing. ([Location 2322](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2322))
    - Tags: [[pink]] 
- As Aristotle might have said, “The whole is greater than the sum of its parts.” He might have said that, but what he actually wrote in his Metaphysics was something different. In Aristotle's words, “The totality is not, as it were, a mere heap, but the whole is something besides the parts.” Moreover, “the whole is not the same as the sum of its parts.” Aristotle's words, above all others, are our risk‐mitigation creed. Like in his functional essentialism that focused on the interrelated parts of animals, Aristotle was onto something here. And this more precise translation from the Greek is so much more applicable to our context. We saw it in the Saint Petersburg paradox, where the whole (the actual realized wealth from playing the game) was so much less than expected from the sum of the parts (the average of all possible wealth outcomes). We also saw it in the Petersburg merchant trade, where purchasing a standalone, money‐losing insurance contract would have raised the merchant's whole geometric wealth, even though it would have lowered his average wealth. We also saw it in our two demonic dice games—a store‐of‐value safe haven and an insurance safe haven; by moving a portion of your cash to a wager with zero expected return, and away from a wager with a high expected return, you actually raised the whole of your wealth, even though it lowered your average (across the ([Location 2329](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2329))
    - Tags: [[pink]] 
- multiverse). (And I hope that I have convinced you by now that this was all due to the straightforward math of compounding, not some magic trick.) The whole can indeed be much more than the sum of its parts—though it need not always be. The word holistic is a neologism dating back to only the 1920s. Its meaning reflects its Greek root holos, for “whole.” The whole is the only reference where the parts make coherent sense, not as a collection of parts splayed on Grandpa's table or thrown into a covariance matrix box. Investment management so often makes reductionist errors similar to mine as a child with the cuckoo clock, as each piece is analyzed on its own as well as part of a larger whole—a portfolio. Modern finance says to take these individual parts of a portfolio—understand and place a value on each of their individual expected arithmetic returns, volatilities, and covariances with each other—then combine them all within a box; and then the whole of that box is well understood by the sum of their arithmetic returns (and, in particular, by its Sharpe ratio or similar… ([Location 2341](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2341))
    - Tags: [[pink]] 
- In the case of the cuckoo clock, its many interacting parts remain independent, separate pieces. This is known as weak emergence: The interactions of the parts do not change each other; however, their interactions create properties in the whole that can only be observed in the whole, not the parts. Of course, the cuckoo clock's dynamics were predetermined, top‐down, by the clockmaker—in a mechanism dating back to the eighteenth century; and there are Swiss watchmakers in the Vallée de Joux who could have glanced at Grandpa's messy workbench and immediately envisioned the clockwork as a whole. Emergence is relative to the observer. (But anyone who claims that a prewar cuckoo clock doesn't have its own unpredictable and irreducible behavior has likely never owned a prewar cuckoo clock.) In the case of our many previous wagers, one might say that the same weak emergence is clearly at work. In all these wagers, the whole of the wager has properties—specifically its geometric average or median wealth—that the aggregate component wagers do not. The holistic… ([Location 2352](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2352))
    - Tags: [[pink]] 
- the iterative nature of the game. They provide capital for the next dice roll by resetting or rebalancing the size of the wager at the end of each roll. Safe havens can thus top up or feed the wagers in the main game, particularly if the previous roll resulted in a big loss, without really costing the frequent positive wagers enough to matter. These cost‐effective safe havens keep you away from the edge of Bernoulli Falls. They actually transform the dice game—preventing a plunge in the size of any subsequent wager. The wagers now interact, rather than act independently, as they are no longer ring‐fenced from each other. Thus, an entirely new whole is formed—one that is very different from the sum of its parts. This is what's known as strong emergence. This strong emergent property in the Petersburg merchant trade means that the value of a component wager can only be known relative to the whole wager. Its value on its own (in the case of the merchant's insurance contract, an average loss of 300 rubles per shipment) is very different when combined with… ([Location 2363](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2363))
    - Tags: [[pink]] 
- to the observer, or to the larger perspective of the observer's whole portfolio—specifically how it interacts with the multiplicative dynamics of that portfolio. Risk‐mitigation investments are thus highly context dependent. And this is what so eludes the… ([Location 2376](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2376))
    - Tags: [[pink]] 
- There is an old Russian proverb that goes: Dwell on the past and lose an eye. Forget the past and lose both eyes. If we only look at the one way that things happened and obsess over it as the only likely outcome—in other words, if we over‐extrapolate the past— then we are engaged in something called naïve empiricism. To avoid that, we need to look at the past in the context of the many other paths that could have happened, but never did, as well as our sensitivities to those outcomes.… ([Location 2380](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2380))
    - Tags: [[pink]] 
- If you're scratching your head, let me put this as simply as possible: We've taken pains to create an experiment whereby we can test, side by side, what would happen to an all‐SPX portfolio and also SPX‐plus‐safe‐haven cartoon portfolios, based on the range of returns of the SPX over the past 120 years. Got it? Here we go! ([Location 2415](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2415))
    - Tags: [[pink]] 
- Everything in this book up to now has been leading to this point: testing if and how risk mitigation can raise wealth by lowering risk. It's an exciting moment because this is contrary to what we have been taught and what we would have thought. ([Location 2424](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2424))
    - Tags: [[pink]] 
- Bottom line: Safe haven investing has both a measurable arithmetic cost and a measurable geometric effect. A safe haven is cost‐effective when its effect exceeds its cost—for a positive net portfolio effect. ([Location 2436](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2436))
    - Tags: [[pink]] 
- This, then, is the relative score for each of ([Location 2447](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2447))
    - Tags: [[pink]] 
- our risk‐mitigated portfolios. ([Location 2447](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2447))
    - Tags: [[pink]] 
- you can see in the graphic, and as mentioned earlier, the standalone arithmetic average return for both the store‐of‐value and the alpha safe haven is 7% (and yes, that was done on purpose to put them on an even arithmetic footing). The standalone arithmetic average return for the insurance safe haven is 0%. The geometric average return or median CAGR in each portfolio, however, is more nuanced: The 9.5% median CAGR of the SPX portfolio was lowered in the store‐of‐value and alpha risk‐mitigated portfolios to 9.1% (–0.4%) and 9.3% (–0.2%), respectively, but it was raised in the insurance risk‐mitigated portfolio to 10.0% (+0.5%). We know with 95% confidence that the median CAGR of the SPX is 9.4–9.6% (as estimated empirically within the bootstrap); this is the 95% confidence region of that median. Accordingly, a median CAGR of 9.4% sets the boundary of our null hypothesis 95% rejection region. ([Location 2456](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2456))
    - Tags: [[pink]] 
- (Remember, we can't prove that something works, only disprove it when it doesn't.) ([Location 2472](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2472))
    - Tags: [[pink]] 
- To put this in perspective, for a 2% allocation to a fixed annuity (or another store‐of‐value constant payoff) to raise the portfolio's geometric average return by 0.5%, as the insurance payoff did, that annuity would have to yield more than 30% per year—clearly a tall order. And compare that to the insurance payoff, which added that 0.5% with an average yield of 0% per year. Here is a clear‐cut case where the whole is indeed so much more than the sum of its parts. It is another ([Location 2475](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2475))
    - Tags: [[pink]] 
- case of pulling a higher geometric return rabbit out of a lower arithmetic return hat. (I promised you a “what the hell effect” from the explosive crash‐bang‐for‐the‐buck of the insurance cartoon. There it is.) ([Location 2479](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2479))
    - Tags: [[pink]] 
- The pattern that emerges in these three graphs, moving from left to right, is that risk‐mitigation costs diminish somewhat along with the effects. But importantly, the costs diminish more than the effects, and so the cost‐effectiveness increases as we move from left to right. ([Location 2578](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2578))
    - Tags: [[pink]] 
- Because we have torn apart the interacting gears of our safe haven mechanisms (or the coordinated ([Location 2648](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2648))
    - Tags: [[pink]] 
- payoff profiles that mitigate a portfolio's big losses), the whole (or the median CAGR) is no longer greater for the insurance cartoon. All that remains is meager diversification (as the random reshuffling creates uncorrelated pairs of returns) which, visibly, is not nearly enough to provide cost‐effective risk mitigation. If it makes you feel any better, I have found that very few professional investors or allocators would have guessed this right, either. The value of the interacting parts is only visible from within the whole, and that means it is the shape of the safe haven payoff that really matters. As I mentioned while we were fawning over the Kelly criterion and the insurance risk‐mitigation strategies in the demonic dice games—specifically the way they added so much wealth by lowering risk—this is not so easy in the real world, where the risk‐mitigation tradeoff is a more precarious balancing act. Cost‐effective risk mitigation is a nuanced and even pretty hard proposition to evaluate, let alone implement. And this is why modern finance and most practitioners shy away from it—content to instead live with the great dilemma of risk. (It is better to die with the herd than to take a risk on your own, as I've been told countless times in meetings with underfunded pensions.) ([Location 2648](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2648))
    - Tags: [[pink]] 
- Remember, any punter can devise something that does well in a crash and raise that 5th percentile; the trick is to do it while also raising the median (or better yet, all percentiles). This, in a nutshell, is cost‐effective risk mitigation. ([Location 2668](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2668))
    - Tags: [[pink]] 
- But this restricted bootstrap shows another surprising insight: Any skill in predicting crashes (perceived or otherwise) should not impact the decision between these payoffs. While tactically waiting for that crash, both the alpha and the insurance risk‐mitigated portfolios have the same median CAGR for a given level of crash protection (once it arrives); your cost of using those two safe havens as you wait for the proverbial “bell to ring” are the same. Therefore, your optimal choice would default back to what is most cost‐effective strategically, given no skill (or perhaps worse) in predicting crashes. This surprising result makes the tactical risk‐mitigation decision‐making process so much easier, by showing that its reasoning is a virtuous form of circularity: When employing safe havens tactically by switching between different varieties (such as the store‐of‐value, alpha, and insurance payoffs) in order to save costs while awaiting a crash, the least costly choice when there is no crash is the same as the most cost‐effective choice with a crash (that is, the insurance)—thus removing the necessity for tactical skill. We also want to be extremely mindful of the many different ways that our one path can happen. When there is no crash, it stands to reason that you would ([Location 2705](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2705))
    - Tags: [[pink]] 
- of course be better off with no risk mitigation at all (or, in this case, with only the SPX portfolio). But that's not the point. The point is the non‐crash paths do not favor one safe haven payoff over the other (at least between the alpha and the insurance payoffs); our choice of safe haven is surprisingly agnostic—no matter which path we take. ([Location 2717](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2717))
    - Tags: [[pink]] 
- Mind you, I'm certainly not suggesting that anyone should ever do that. My only point is, as you can see, we should avoid comparing highly restrictive (like no crash) performance of risk‐mitigated portfolios with portfolios that have no risk mitigation. Ironically, when we are honest about apples‐to‐apples comparisons of portfolios, the optimal risk‐mitigation solutions are robust and indifferent to when—and even if—there is ever a crash again. (Fat tails are superfluous.) This is winning the war against luck. ([Location 2733](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2733))
    - Tags: [[pink]] 
- Avoiding the concave Bernoulli Falls during the multiplicative compounding of investing carries its own offensive component to safe haven investing. It is how, in our cost‐effectiveness analysis, the geometric effect from risk mitigation can exceed its arithmetic cost. The geometric effect really is the offense. In investing, good defense leads to good offense. ([Location 2781](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2781))
    - Tags: [[pink]] 
- A NARROW, BROKEN WINDOW FRAME It should be very clear by now: We cannot judge the cost‐effectiveness of a given risk‐mitigation strategy ([Location 2786](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2786))
    - Tags: [[pink]] 
- on its own, in a vacuum, based solely on its attributes. Investing's theory of relativity dictates that an investment's value can only be known by the net portfolio effect that it provides and is thus unique and relative to that (and any other) particular portfolio. The whole is often, but not always, much greater than the sum of the parts. This is a big challenge for most observers. And this is particularly so in investing because the math of the sum—or of arithmetic averaging—is so intuitive, while the math of the whole—or of compounding—is so counterintuitive. Portfolio components thus stick out as line items. They are not perceived as soluble in a portfolio, like (just a pinch of) salt; rather, they are perceived as insoluble, like oil. The challenge in general even has a formal name in the field of behavioral economics known as narrow framing. This is the habit or blind spot that people tend to have when looking at investments as parts rather than as wholes—as line items rather than as overall portfolios. It's a small, harmless error by a wide‐eyed little boy seeing the workings of his grandpa's cuckoo clock for the first time; but for investors, it leads to incoherent and costly decisions. As in many things, our capacity to frame a problem coherently and correctly is what creates ([Location 2788](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2788))
    - Tags: [[pink]] 
- our capacity to solve it, not to mention our capacity to monetize that solution. ([Location 2800](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2800))
    - Tags: [[pink]] 
- All risk‐mitigation strategies ultimately require a tradeoff between the degree of loss protection provided—the geometric effect, or the amount of the portfolio's negative compounding that is avoided—versus the degree of opportunity cost from allocating capital to that protection rather than to the rest of the portfolio—the arithmetic cost, or the ([Location 2808](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2808))
    - Tags: [[pink]] 
- amount by which the portfolio's arithmetic average return is lowered. In allocating capital, where narrow framing means each component of a portfolio is judged on its own standalone merits, the optimal choice would typically be the store‐of‐value or the alpha strategy, rather than the insurance strategy. An investor will almost always take, and be able to explain, a strategy in the name of risk reduction that, by itself, has a positive return most of the time—or no explicit cost—even if it lowers the total portfolio returns over that or any time—an implicit cost. This is known as opportunity cost neglect, and it's probably the most pernicious yet hidden bias that we face in risk mitigation. Kudos to the entire hedge fund industry for basically capitalizing on that simple perceived disparity between explicit and implicit costs (and, yes, I'm being sarcastic). Indeed, it is why diversification remains erroneously perceived as “the only free lunch in finance.” Avoiding this incoherent risk‐mitigation decision‐making requires a holistic view, comparing the implicit costs of whole portfolio returns with that of alternatives. Easy to say, hard to embrace. This is probably why we succumb so easily, as we aren't on the lookout for it. But maybe we can learn something ([Location 2811](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2811))
    - Tags: [[pink]] 
- from a few other areas where it's hard and where it's easier to overcome. The best instance of this framing problem was presented by the great libertarian French economist Frédéric Bastiat in his 1850 essay “Ce qu'on voit et ce qu'on ne voit pas” (“That Which Is Seen and That Which Is Not Seen”), where he was perhaps the first to introduce the concept of opportunity cost. In a thought experiment parable, a mischievous boy breaks a shopkeeper's window, and someone in the assembled crowd then tries to argue that this is actually a good thing, because it means more business for the glazier. As Bastiat points out, the fallacy here is obvious when you consider that we should all then simply go about smashing windows to increase economic activity and growth. The narrow framing of that fallacious view overlooks the implicit cost to the shopkeeper, who must now spend funds to fix his window, rather than on other possible items such as a new coat for his wife, which would have provided business for the tailor. The shopkeeper's wealth is lowered (relative to what it otherwise would have been, had the boy not smashed… ([Location 2822](https://readwise.io/to_kindle?action=open&asin=B09CGHBR89&location=2822))
    - Tags: [[pink]]

