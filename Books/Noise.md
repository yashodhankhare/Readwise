---
tags:
  - readwise
---

# Noise

![rw-book-cover](https://m.media-amazon.com/images/I/81lM0xsKXFL._SY160.jpg)

## Metadata
- Author: [[Daniel Kahneman, Olivier Sibony, and Cass R. Sunstein]]
- Full Title: Noise
- Category: #books

## Highlights
- general property of noise is that ([Location 100](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=100))
    - Tags: [[pink]] 
- you can recognize and measure it while knowing nothing about the target or bias. ([Location 100](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=100))
    - Tags: [[pink]] 
- To understand error in judgment, we must understand both bias and noise. Sometimes, as we will see, noise is the more important problem. But in public conversations about human error and in organizations all over the world, noise is rarely recognized. Bias is the star of the show. Noise is a bit player, usually offstage. The topic of bias has been discussed in thousands of scientific articles and dozens of popular books, few of which even mention the issue of noise. This book is our attempt to redress the balance. In real-world decisions, the amount of noise is often scandalously high. ([Location 108](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=108))
    - Tags: [[pink]] 
- Medicine is noisy. Faced with the same patient, different doctors make different judgments about whether patients have skin cancer, breast cancer, heart disease, tuberculosis, pneumonia, depression, and a host of other conditions. Noise is especially high in psychiatry, where subjective judgment is obviously important. However, considerable noise is also found in areas where it might not be expected, such as in the reading of X-rays. ([Location 113](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=113))
    - Tags: [[pink]] 
- Forecasts are noisy. Professional forecasters offer highly variable predictions about likely sales of a new product, likely growth in the unemployment rate, the likelihood of bankruptcy for troubled companies, and just about everything else. Not only do they disagree with each other, but they also disagree with ([Location 120](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=120))
    - Tags: [[pink]] 
- themselves. For example, when the same software developers were asked on two separate days to estimate the completion time for the same task, the hours they projected differed by 71%, on average. ([Location 122](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=122))
    - Tags: [[pink]] 
- Personnel decisions are noisy. Interviewers of job candidates make widely different assessments of the same people. Performance ratings of the same employees are also highly variable and depend more on the person doing the assessment than on the performance being assessed. ([Location 127](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=127))
    - Tags: [[pink]] 
- Wherever you look at human judgments, you are likely to find noise. To improve the quality of our judgments, we need to overcome noise as well as bias. ([Location 139](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=139))
    - Tags: [[pink]] 
- Occasion noise is the variability in judgments of the same case by the same person or group on different occasions. A surprising amount of occasion noise arises in group discussion because of seemingly irrelevant factors, such as who speaks first. ([Location 147](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=147))
    - Tags: [[pink]] 
- The theme that emerges from these three chapters can be summarized in one sentence, which will be a key theme of this book: wherever there is judgment, there is noise—and more of it than you think. Let’s start to find out how much. ([Location 195](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=195))
    - Tags: [[pink]] 
- A frequent misconception about unwanted variability in judgments is that it doesn’t matter, because random errors supposedly cancel one another out. Certainly, positive and negative errors in a judgment about the same case will tend to cancel one another out, and we will discuss in detail how this property can be used to reduce noise. But noisy systems do ([Location 429](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=429))
    - Tags: [[pink]] 
- not make multiple judgments of the same case. They make noisy judgments of different cases. If one insurance policy is overpriced and another is underpriced, pricing may on average look right, but the insurance company has made two costly errors. ([Location 431](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=431))
    - Tags: [[pink]] 
- In noisy systems, errors do not cancel out. They add up. ([Location 434](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=434))
    - Tags: [[pink]] 
- In the case of professional judgments, the belief that others see the world much as we do is reinforced every day in multiple ways. First, we share with our colleagues a common language and set of rules about the considerations that should matter in our decisions. We also have the reassuring experience of agreeing with others on the absurdity of judgments that violate these rules. We view the occasional disagreements with colleagues as lapses of judgment on their part. We have little opportunity to notice that ([Location 456](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=456))
    - Tags: [[pink]] 
- our agreed-on rules are vague, sufficient to eliminate some possibilities but not to specify a shared positive response to a particular case. We can live comfortably with colleagues without ever noticing that they actually do not see the world as we do. One underwriter we interviewed described her experience in becoming a veteran in her department: “When I was new, I would discuss seventy-five percent of cases with my supervisor.… After a few years, I didn’t need to—I am now regarded as an expert.… Over time, I became more and more confident in my judgment.” Like many of us, this person had developed confidence in her judgment mainly by exercising it. The psychology of this process is well understood. Confidence is nurtured by the subjective experience of judgments that are made with increasing fluency and ease, in part because they resemble judgments made in similar cases in the past. Over time, as this underwriter learned to agree with her past self, her confidence in her judgments increased. She gave no indication that—after the initial apprenticeship phase—she had learned to agree with others, had checked to what extent she did agree with them, or had even tried to prevent her practices from drifting away from those of her colleagues. For the insurance company, the illusion of agreement was shattered only by the noise audit. How had the leaders of the company remained unaware of their noise problem? There are several possible answers here, but one that seems to play a large role in many settings is simply the discomfort of disagreement. Most organizations prefer consensus and harmony over dissent and conflict. The procedures in place often seem expressly designed to minimize the frequency of exposure to actual disagreements and, when such disagreements happen, to explain them away. ([Location 460](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=460))
    - Tags: [[pink]] 
- Our conclusion is simple: wherever there is judgment, there is noise, and more of it than you think. ([Location 487](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=487))
    - Tags: [[pink]] 
- The case studies we have discussed thus far involve judgments that are made repeatedly. What is the right sentence for someone convicted of theft? What is the right premium for a particular risk? While each case is in some sense unique, judgments like these are recurrent decisions. Doctors diagnosing patients, judges hearing parole cases, admissions officers reviewing applications, accountants preparing tax forms—these are all examples of recurrent decisions. Noise in recurrent decisions is demonstrated by a noise audit, such as those we introduced in the previous chapter. Unwanted variability is easy to define and measure when interchangeable professionals make decisions in similar cases. It seems much harder, or perhaps even impossible, to apply the idea of noise to a category of judgments that we call singular decisions. ([Location 496](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=496))
    - Tags: [[pink]] 
- Decisions that are made only once, like the president’s Ebola response, are singular because they are not made recurrently by the same individual or team, they lack a prepackaged response, and they are ([Location 510](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=510))
    - Tags: [[pink]] 
- marked by genuinely unique features. In dealing with Ebola, President Obama and his team had no real precedents on which to draw. Important political decisions are often good examples of singular decisions, as are the most fateful choices of military commanders. In the private realm, decisions you make when choosing a job, buying a house, or proposing marriage have the same characteristics. Even if this is not your first job, house, or marriage, and despite the fact that countless people have faced these decisions before, the decision feels unique to you. In business, heads of companies are often called on to make what seem like unique decisions to them: whether to launch a potentially game-changing innovation, how much to close down during a pandemic, whether to open an office in a foreign country, or whether to capitulate to a government that seeks to regulate them. ([Location 512](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=512))
    - Tags: [[pink]] 
- In other words, we cannot measure noise in a singular decision, but if we think counterfactually, we know for sure that noise is there. Just as the shooter’s unsteady hand implies that a single shot could have landed somewhere else, noise in the decision makers and in the decision-making process implies that the singular decision could have been different. ([Location 540](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=540))
    - Tags: [[pink]] 
- This theoretical discussion matters. If singular decisions are just as noisy as recurrent ones, then the strategies that reduce noise in recurrent decisions should also improve the quality of singular decisions. This is a more counterintuitive prescription than it seems. When you have a one-of-a-kind decision to make, your instinct is probably to treat it as, well, one of a kind. Some even claim that the rules of probabilistic thinking are entirely irrelevant to singular decisions made under uncertainty and that such decisions call for a radically different approach. Our observations here suggest the opposite advice. From the perspective of noise reduction, a singular decision is a recurrent decision that happens only once. Whether you make a decision only once or a hundred times, your goal should be to make it in a way that reduces both bias and noise. And practices that reduce error should be just as effective in your one-of-a-kind decisions as in your repeated ones. ([Location 552](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=552))
    - Tags: [[pink]] 
- Judgment can therefore be described as measurement in which the instrument is a human mind. Implicit in the notion of measurement is the goal of accuracy—to approach truth and minimize error. The goal of judgment is not to impress, not to take a stand, not to persuade. It is important to note that the concept of judgment as we use it here is borrowed from the technical psychological literature, and that it is a much narrower concept than the same word has in everyday language. Judgment is not a synonym for thinking, and making accurate judgments is not a synonym for having good judgment. ([Location 570](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=570))
    - Tags: [[pink]] 
- This finding is hardly surprising, because noise is universal in physiology and psychology. Variability across individuals is a biological given; no two peas in a pod are truly identical. Within the same person, there is variability, too. Your heartbeat is not exactly regular. You cannot repeat the same gesture with perfect precision. And when you have your hearing examined by an audiologist, there will be some sounds so soft you never hear them, and others so loud you always do. But there will also be some sounds that you will sometimes hear and sometimes miss. Now look at the five numbers on your phone. Do you see a pattern? For instance, are all five laps shorter than ten seconds, a pattern suggesting that your internal clock is running fast? In this simple task, the bias is the difference, positive or negative, between the mean of your laps and ten seconds. Noise constitutes the variability of your results, analogous to the scatter of shots we saw earlier. In statistics, the most common measure of variability is standard ([Location 586](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=586))
    - Tags: [[pink]] 
- deviation, and we will use it to measure noise in judgments. ([Location 593](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=593))
    - Tags: [[pink]] 
- We will rely extensively on the analogy between judgment and measurement because it helps explain the role of noise in error. People who make predictive judgments are just like the shooter who aims at the bull’s-eye or the physicist who strives to measure the true weight of a particle. Noise in their judgments implies error. Simply put, when a judgment aims at a true value, two different judgments cannot both be right. Like measuring instruments, some people generally show more error than others in ([Location 597](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=597))
    - Tags: [[pink]] 
- a particular task—perhaps because of deficiencies in skill or training. But, like measuring instruments, the people who make judgments are never perfect. We need to understand and measure their errors. ([Location 601](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=601))
    - Tags: [[pink]] 
- A simple conclusion emerges from these chapters: like a measuring instrument, the human mind is imperfect—it is both biased and noisy. Why, and by how much? Let’s find out. ([Location 607](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=607))
    - Tags: [[pink]] 
- This book is about professional judgments, broadly understood, and it assumes that whoever makes such a judgment is competent and aiming to get it right. However, the very concept of judgment involves a reluctant acknowledgment that you can never be certain that a judgment is right. ([Location 611](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=611))
    - Tags: [[pink]] 
- A matter of judgment is one with some uncertainty about the answer and where we allow for the possibility that reasonable and competent people ([Location 615](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=615))
    - Tags: [[pink]] 
- might disagree. But there is a limit to how much disagreement is admissible. Indeed, the word judgment is used mainly where people believe they should agree. Matters of judgment differ from matters of opinion or taste, in which unresolved differences are entirely acceptable. ([Location 616](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=616))
    - Tags: [[pink]] 
- Matters of judgment, including professional judgments, occupy a space between questions of fact or computation on the one hand and matters of taste or opinion on the other. They are defined by the expectation of bounded disagreement. Exactly how much disagreement is acceptable in a judgment is itself a judgment call and depends on the difficulty of the problem. Agreement is especially easy when a judgment is absurd. ([Location 620](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=620))
    - Tags: [[pink]] 
- Incidentally, you may have noticed that the stopwatch exercise and the Gambardi problem illustrate two types of noise. The variability of judgments over successive trials with the stopwatch is noise within a single judge (yourself), whereas the variability of judgments of the Gambardi case is noise between different judges. In measurement terms, the first problem illustrates within-person reliability, and the second illustrates between-person reliability. ([Location 663](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=663))
    - Tags: [[pink]] 
- The outcome does not reveal what the ex ante probability was. If an event that was assigned a probability of 90% fails to happen, the judgment of probability was not necessarily a bad one. After all, outcomes that are just 10% likely to happen end up happening 10% of the time. The Gambardi exercise is an example of a nonverifiable predictive judgment, for two separate reasons: Gambardi is fictitious and the answer is probabilistic. ([Location 672](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=672))
    - Tags: [[pink]] 
- Verifiability does not change the experience of judgment as it takes place. It does, however, change its evaluation after the fact. Verifiable judgments can be scored by an objective observer on a simple measure of error: the difference between the judgment and the outcome. If a weather forecaster said today’s high temperature would be seventy degrees Fahrenheit and it is sixty-five degrees, the forecaster made an error of plus five degrees. Evidently, this approach does not work for nonverifiable judgments like the Gambardi problem, which have no true outcome. How, then, are we to decide what constitutes good judgment? The answer is that there is a second way to evaluate judgments. This approach applies both to verifiable and nonverifiable ones. It consists in evaluating the process of judgment. When we speak of good or bad judgments, we may be speaking either about the output (e.g., the number you produced in the Gambardi case) or about the process—what you did to arrive at that number. One approach to the evaluation of the process of judgment is to observe how that process performs when it is applied to a large ([Location 699](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=699))
    - Tags: [[pink]] 
- number of cases. For instance, consider a political forecaster who has assigned probabilities of winning to a large number of candidates in local elections. He described one hundred of these candidates as being 70% likely to win. If seventy of them are eventually elected, we have a good indication of the forecaster’s skill in using the probability scale. The judgments are verifiable as an ensemble, although no single probability judgment can be declared right or wrong. Similarly, bias for or against a particular group can best be established by examining statistical results for a substantial number of cases. Another question that can be asked about the process of judgment is whether it conforms to the principles of logic or probability theory. A large body of research on cognitive biases of judgment has been in this vein. Focusing on the process of judgment, rather than its outcome, makes it possible to evaluate the quality of judgments that are not verifiable, such as judgments about fictitious problems or long-term forecasts. We may not be able to compare them to a known ([Location 707](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=707))
    - Tags: [[pink]] 
- outcome, but we can still tell whether they have been made incorrectly. And when we turn to the question of improving judgments rather than just evaluating them, we will focus on process, too. All the procedures we recommend in this book to reduce bias and noise aim to adopt the judgment process that would minimize error over an ensemble of similar cases. ([Location 715](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=715))
    - Tags: [[pink]] 
- In summary, what people usually claim to strive for in verifiable judgments is a prediction that matches the outcome. What they are effectively trying to achieve, regardless of verifiability, is the internal signal of completion provided by the coherence between the facts of the case and the judgment. And what they should be trying to achieve, normatively speaking, is the judgment process that would produce the best judgment over an ensemble of similar cases. ([Location 724](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=724))
    - Tags: [[pink]] 
- System noise is inconsistency, and inconsistency damages the credibility of the system. ([Location 760](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=760))
    - Tags: [[pink]] 
- We have now seen that noise can produce costly errors as well. If a manager most often predicts that projects will take half the time they ultimately take, and occasionally predicts they will take twice their actual time, it is unhelpful to say that the manager is “on average” right. The different errors add up; they do not cancel out. ([Location 779](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=779))
    - Tags: [[pink]] 
- Scientists in diverse disciplines were quick to ([Location 866](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=866))
    - Tags: [[pink]] 
- adopt the least squares method. Over two centuries later, it remains the standard way to evaluate errors wherever achieving accuracy is the goal. The weighting of errors by their square is central to statistics. In the vast majority of applications across all scientific disciplines, MSE rules. As we are about to see, the approach has surprising implications. ([Location 866](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=866))
    - Tags: [[pink]] 
- In that regard, if GoodSell decides to reduce noise, the fact that noise reduction makes bias more visible—indeed, impossible to miss—may turn out to be a blessing. ([Location 917](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=917))
    - Tags: [[pink]] 
- Admittedly, reducing noise would be less of a priority if bias were much larger than noise. But the GoodSell example offers another lesson worth highlighting. In this simplified model, we have assumed that noise and bias are equal. Given the form of the error equation, their contributions to total error are equal, too: bias accounts for 50% of overall error, and so does noise. Yet, as we have noted, 84% of the forecasters err in the same direction. It takes a bias this large (six out of seven people making mistakes in the same direction!) to have as much effect as noise has. We should not be surprised, therefore, to find situations in which there is more noise than bias. ([Location 919](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=919))
    - Tags: [[pink]] 
- These examples highlight the need to specify the roles of predictive and evaluative judgments in decisions. A widely accepted maxim of good decision making is that you should not mix your values and your facts. Good decision making must be based on objective and accurate predictive judgments that are ([Location 940](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=940))
    - Tags: [[pink]] 
- completely unaffected by hopes and fears, or by preferences and values. ([Location 942](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=942))
    - Tags: [[pink]] 
- Speaking of the Error Equation “Oddly, reducing bias and noise by the same amount has the same effect on accuracy.” “Reducing noise in predictive judgment is always useful, regardless of what you know about bias.” “When judgments are split 84 to 16 between those that are above and below the true value, there is a large bias—that’s when bias and noise are equal.” “Predictive judgments are involved in every decision, and accuracy should be their only goal. Keep your values and your facts separate.” ([Location 956](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=956))
    - Tags: [[pink]] 
- The previous chapter discussed variability in the measurement or judgment of a single case. When we focus on a single case, all variability of judgment is error, and the two constituents of error are bias and noise. Of course, the judgment systems we are examining, including those involving courts and insurance companies, are designed to deal with different cases and to discriminate among them. Federal judges and claims adjusters would be of little use if they returned the same judgment for all the cases that come their way. Much of the variability in judgments of different cases is intentional. However, variability in judgments of the same case is still undesirable—it is system noise. As we will show, a noise audit in which the same people make judgments about several cases permits a more detailed analysis of system noise. ([Location 964](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=964))
    - Tags: [[pink]] 
- As the black arrows show in figure 9, level noise is 2.4 years and system noise is 3.4 years. This difference indicates that there is more to system noise than differences in average severity across individual judges. We will call this other component of noise pattern noise. ([Location 1043](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1043))
    - Tags: [[pink]] 
- The same simple, additive logic would let you predict every sentence in every column of the table, but in fact you would find deviations from the simple model in most cells. Looking across a row, you will find that judges are not equally severe in their sentencing of all cases: they are harsher than their personal average in some and more lenient in others. We call these residual deviations pattern errors. ([Location 1050](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1050))
    - Tags: [[pink]] 
- You may have noticed that the decomposition of system noise into level noise and pattern noise follows the same logic as the error equation in the previous chapter, which decomposed error into bias and noise. This time, the equation can be written as follows: System Noise2 = Level Noise2 + Pattern Noise2 ([Location 1070](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1070))
    - Tags: [[pink]] 
- Pattern noise is pervasive. Suppose that doctors are deciding whether to admit people for hospitalization, that companies are deciding whom to hire, that lawyers are deciding which cases to bring, or that Hollywood executives are deciding which television shows to produce. In all these cases, there will be pattern noise, with different judges producing different rankings of the cases. ([Location 1075](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1075))
    - Tags: [[pink]] 
- The Components of Noise Our treatment of pattern noise glossed over a significant complexity: the possible contribution of random error. Recall the stopwatch exercise. When you tried to measure ten seconds repeatedly, your results varied from one lap to the next; you showed within-person variability. By the same token, the judges would not have set precisely the same sentences to the sixteen cases if they had been asked to judge them again on another occasion. Indeed, as we will see, they would not have set the same sentences if the original study had been conducted on another day of the same week. If a judge is in a good mood because something ([Location 1080](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1080))
    - Tags: [[pink]] 
- nice happened to her daughter, or because a favorite sports team won yesterday, or because it is a beautiful day, her judgment might be more lenient than it would otherwise be. This within-person variability is conceptually distinct from the stable between-person differences that we have just discussed—but it is difficult to tell these sources of variability apart. Our name for the variability that is due to transient effects is occasion noise. ([Location 1085](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1085))
    - Tags: [[pink]] 
- To summarize, we discussed several types of noise. System noise is undesirable variability in the judgments of the same case by multiple individuals. We have identified its two major components, which can be separated when the same individuals evaluate multiple cases: ([Location 1093](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1093))
    - Tags: [[pink]] 
- Level noise is variability in the average level of judgments by different judges. Pattern noise is variability in judges’ responses to particular cases. ([Location 1095](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1095))
    - Tags: [[pink]] 
- Variability in free throws or in other physical processes comes as no surprise. We are used to variability in our bodies: our heart rate, our blood pressure, our reflexes, the tone of our voice, and the trembling of our hands are different at different times. And however hard we try to produce the same signature, it is still slightly different on every check. It is less easy to observe the variability of our minds. Of course, we have all had the experience of changing our minds, even without new information. The film that made us laugh out loud last night ([Location 1120](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1120))
    - Tags: [[pink]] 
- now seems mediocre and forgettable. The person we judged severely yesterday now seems to deserve our indulgence. An argument that we had not liked or understood sinks in and now appears essential. But as these examples suggest, we usually associate such changes with relatively minor and largely subjective matters. In reality, our opinions do change without apparent reason. This point holds even for matters of careful, considered judgment by professional experts. For instance, it is common to obtain significantly different diagnoses from the same physicians when they are presented twice with the same case (see chapter 22). When wine experts at a major US wine competition tasted the same wines twice, they scored only 18% of the wines identically (usually, the very worst ones). A forensic expert can reach different conclusions when examining the same fingerprints twice, just a few weeks apart (see chapter 20). Experienced software consultants can offer markedly different estimates of the completion time for the same task on two occasions. Simply put, just like a basketball player who never throws the ball twice in exactly the same way, we do not always produce identical judgments when faced with the same facts on two occasions. We have described the process that picks an underwriter, a judge, or a doctor as a lottery that creates system noise. Occasion noise is the product of a ([Location 1124](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1124))
    - Tags: [[pink]] 
- second lottery. This lottery picks the moment when the professional makes a judgment, the professional’s mood, the sequence of cases that are fresh in mind, and countless other features of the occasion. This second lottery usually remains much more abstract than the first. We can see how the first lottery could have selected a different underwriter, for instance, but the alternatives to the actual responses of the selected underwriter are abstract counterfactuals. We know only that the… ([Location 1134](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1134))
    - Tags: [[pink]] 
- Measuring occasion noise is not easy—for much the same reason that its existence, once established, often surprises us. When people form a carefully considered professional opinion, they associate it with the reasons that justify their point of view. If pressed to explain their judgment, they will usually defend it with arguments that they find convincing. And if they are presented with the same problem a second time and recognize it, they will reproduce the earlier answer both to minimize effort… ([Location 1139](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1139))
    - Tags: [[pink]] 
- essay and then rereads the same essay a week later after seeing the original grade, he will be unlikely to give it a very different grade. For this reason, direct measurements of occasion noise are hard to obtain whenever cases are easily memorable. If, for example, you show an underwriter or a criminal judge a case that they previously decided, they will probably recognize the case and just repeat their previous judgment. One review of research on variability in professional judgment (technically known as test-retest reliability, or reliability for short) included many studies in which the experts made the same judgment twice in the same session. Not surprisingly, they tended to agree with themselves. The experiments we mentioned above bypassed this issue by using stimuli that the experts would not recognize. The wine judges took part in a blind tasting. The fingerprint examiners were shown pairs of prints they had already seen, and the software experts were asked about tasks they had already worked on—but some weeks or months later and without being told that these were cases they… ([Location 1143](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1143))
    - Tags: [[pink]] 
- by occasion-specific, irrelevant factors, such as time of day or outside temperature. Statistically significant effects of such irrelevant factors on judgments are evidence of occasion noise. Realistically speaking, there is no hope of discovering all the extraneous sources of occasion noise, but those that can be found illustrate the great variety of these sources.… ([Location 1153](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1153))
    - Tags: [[pink]] 
- Vul and Pashler drew inspiration from the well-known phenomenon known as the wisdom-of-crowds effect: averaging the independent judgments of different people generally improves accuracy. ([Location 1166](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1166))
    - Tags: [[pink]] 
- The reason is basic statistics: averaging several independent judgments (or measurements) yields a new judgment, which is less noisy, albeit not less biased, than the individual judgments. Vul and Pashler wanted to find out if the same effect extends to occasion noise: can you get closer to the truth by combining two guesses from the same person, just as you do when you combine the guesses of different people? As they discovered, the answer is yes. Vul and Pashler gave this finding an evocative name: the crowd within. Averaging two guesses by the same person does not improve judgments as much as does seeking out an independent second opinion. As Vul and Pashler put it, “You can gain about 1/10th as much from asking yourself the same question twice as you can from getting a second opinion from someone else.” This is not a large improvement. But you can make the effect much larger by waiting to make a second guess. When Vul and Pashler let three weeks pass before asking ([Location 1175](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1175))
    - Tags: [[pink]] 
- their subjects the same question again, the benefit rose to one-third the value of a second opinion. Not bad for a technique that does not require any additional information or outside help. And this result certainly provides a rationale for the age-old advice to decision makers: “Sleep on it, and think again in the morning.” Working independently of Vul and Pashler but at about the same time, two German researchers, Stefan Herzog and Ralph Hertwig, came up with a different implementation of the same principle. Instead of merely asking their subjects to produce a second estimate, they encouraged people to generate an estimate that—while still plausible—was as different as possible from the first one. This request required the subjects to think actively of information they had not considered the first time. The instructions to participants read as follows: First, assume that your first estimate is off the mark. Second, think about a few reasons why that could be. Which assumptions and considerations could have been wrong? Third, what do these new considerations imply? Was the first estimate rather too high or too low? Fourth, based on this new perspective, make a second, alternative estimate. ([Location 1182](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1182))
    - Tags: [[pink]] 
- Like Vul and Pashler, Herzog and Hertwig then averaged the two estimates thus produced. Their technique, which they named dialectical bootstrapping, produced larger improvements in accuracy than did a simple request for a second estimate immediately following the first. Because the participants forced themselves to consider the question in a new light, they sampled another, more different version of themselves—two “members” of the “crowd within” who were further apart. As a result, their average produced a more accurate estimate of the truth. The gain in accuracy with two immediately consecutive “dialectical” estimates was about half the value of a second opinion. The upshot for decision makers, as summarized by Herzog and Hertwig, is a simple choice between procedures: if you can get independent opinions from others, do it—this real wisdom of crowds is highly likely to improve your judgment. If you cannot, make the same judgment yourself a second time to create an “inner crowd.” You can do this either after some time has passed—giving yourself distance from your first opinion—or by actively trying to argue against yourself to find another perspective on the problem. Finally, regardless of the type of crowd, unless you have very strong reasons to put more weight on one of the estimates, your best bet is to average them. Beyond practical advice, this line of research confirms an essential insight about judgment. As Vul and Pashler put it, “Responses made by a subject are sampled from an internal probability distribution, rather than deterministically selected on the basis of all the knowledge a subject has.” This observation echoes the experience you had when… ([Location 1191](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1191))
    - Tags: [[pink]] 
- There is at least one source of occasion noise that we have all noticed: mood. We’ve all experienced how our own judgments can depend on how we feel—and we are certainly aware that the… ([Location 1207](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1207))
    - Tags: [[pink]] 
- Some of Forgas’s research confirms what you already think: People who are in a good mood are generally more positive. They find it easier to recall happy memories than sad ones, they are more approving of people, they are more generous and helpful, and so on. Negative mood has the opposite effects. As Forgas writes, “The same smile that is seen as friendly by a person in a good mood may be judged as awkward when the observer is in a negative mood; discussing the weather could be seen as poised when the person is in a good mood but boring when that person is in a bad mood.” In other words, mood has a measurable influence on what you think: what you notice in your environment, what you retrieve from your memory, how you make sense of these signals. But mood has another, more surprising effect: it also changes how you think. And here, the effects are not those you might imagine. ([Location 1214](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1214))
    - Tags: [[pink]] 
- Being in a good mood is a mixed blessing, and bad moods have a silver lining. The costs and benefits of different moods are situation-specific. ([Location 1221](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1221))
    - Tags: [[pink]] 
- People who are in a good mood are more likely to let ([Location 1230](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1230))
    - Tags: [[pink]] 
- their biases affect their thinking. ([Location 1231](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1231))
    - Tags: [[pink]] 
- Sure enough, some people are more receptive than others to bullshit. They can be impressed by “seemingly impressive assertions that are presented as true and meaningful but are actually vacuous.” But here again, this gullibility is not merely a function of permanent, unchanging dispositions. Inducing good moods makes people more receptive to bullshit and more gullible in general; they are less apt to detect deception or identify misleading information. Conversely, eyewitnesses who are exposed to misleading information are better able to disregard it—and to avoid false testimony—when they are in a bad mood. ([Location 1236](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1236))
    - Tags: [[pink]] 
- Even moral judgments are strongly influenced by mood. In one study, researchers exposed subjects to the footbridge problem, a classic problem in moral philosophy. In this thought experiment, five people are about to be killed by a runaway trolley. Subjects are to imagine themselves standing on a footbridge, underneath which the trolley will soon pass. They must decide whether to push a large man off the footbridge and onto the tracks so that his body will stop the trolley. If they do so, they are told, the large man will die, but the five people will be saved. The footbridge problem illustrates the conflict between approaches to moral reasoning. Utilitarian calculation, associated with English philosopher Jeremy Bentham, suggests that the loss of one life is preferable to the loss of five. Deontological ethics, associated with Immanuel Kant, prohibits killing someone, even in the service of saving several others. The footbridge problem clearly contains a salient element of personal emotion: physically pushing a man off a bridge into the path of an oncoming trolley is a particularly repugnant act. Making the utilitarian choice to push the man off the bridge requires people to overcome their aversion to a physically violent act against a stranger. Only a minority of people (in this study, fewer than one in ten) usually say they would do so. However, when the subjects were placed in a positive mood—induced by watching a five-minute video ([Location 1241](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1241))
    - Tags: [[pink]] 
- segment—they became three times more likely to say that they would push the man off the bridge. Whether we regard “Thou shalt not kill” as an absolute principle or are willing to kill one stranger to save five should reflect our deepest values. Yet our choice seems to depend on what video clip we have just watched. We have described these studies of mood in some detail because we need to emphasize an important truth: you are not the same person at all times. As your mood varies (something you are, of course, aware of), some features of your cognitive machinery vary with it (something you are not fully aware of). If you are shown a complex judgment problem, your mood in the moment may influence your approach to the problem and the conclusions you reach, even when you believe that your mood has no such influence and even when you can confidently justify the answer you found. In short, you are noisy. ([Location 1251](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1251))
    - Tags: [[pink]] 
- Even the weather has a measurable influence on professional judgments. Since these judgments are often made in air-conditioned rooms, the effect of weather is probably “mediated” by mood (that is, the weather does not directly affect decisions but modifies the decision maker’s mood, which in turn does change how they decide). Bad weather is associated with improved memory; judicial sentences tend to be more severe when it is hot outside; and stock market performance is affected by sunshine. In some cases, the effect of the weather is less obvious. Uri Simonsohn showed that college admissions officers pay more attention to the academic attributes of candidates on cloudier days and are more sensitive to nonacademic attributes on sunnier days. The title of the article in which he reported these findings is memorable enough: “Clouds Make Nerds Look Good.” ([Location 1264](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1264))
    - Tags: [[pink]] 
- Another source of random variability in judgment is the order in which cases are examined. When a person is considering a case, the decisions that immediately preceded it serve as an implicit frame of reference. Professionals who make a series of decisions in sequence, including judges, loan officers, and baseball umpires, lean toward restoring a form of balance: after a streak, or a series of decisions that go in the same direction, they are more likely to decide in the opposite direction than would be strictly justified. As a result, errors (and unfairness) are inevitable. Asylum judges in the United States, for instance, are 19% less likely to grant asylum to an applicant when the previous two cases were approved. A person might be approved for a loan if the previous two applications were denied, but the same person might have been rejected if the previous two applications had been granted. This behavior reflects a cognitive bias known as the gambler’s fallacy: we tend to underestimate the likelihood that streaks will occur by chance. ([Location 1270](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1270))
    - Tags: [[pink]] 
- Or to put it differently, you are not always the same person, and you are less consistent over time than you think. But somewhat reassuringly, you are more similar to yourself yesterday than you are to another person today. ([Location 1288](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1288))
    - Tags: [[pink]] 
- Even in this tightly controlled setting, exactly what factors drive occasion noise was a mystery. ([Location 1303](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1303))
    - Tags: [[pink]] 
- It is very likely that intrinsic variability in the functioning of the brain also affects the quality of our judgments in ways that we cannot possibly hope to control. This variability in brain function should give pause to anyone who thinks occasion noise can be eliminated. The analogy with the basketball player at the free-throw line was not as simplistic as it may have initially appeared: just as the player’s muscles never execute exactly the same gesture, our neurons never operate in exactly the same way. If our mind is a measuring instrument, it will never be a perfect one. ([Location 1311](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1311))
    - Tags: [[pink]] 
- “Judgment is like a free throw: however hard we try to repeat it precisely, it is never exactly identical.” “Your judgment depends on what mood you are in, what cases you have just discussed, and even what the weather is. You are not the same person at all ([Location 1317](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1317))
    - Tags: [[pink]] 
- times.” “Although you may not be the same person you were last week, you are less different from the ‘you’ of last week than you are from someone else today. Occasion noise is not the largest source of system noise.” ([Location 1319](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1319))
    - Tags: [[pink]] 
- There is a related point. We have pointed to the wisdom of crowds: if you take a large group of people and ask them a question, there is a good chance that the average answer will be close to the target. Aggregating judgments can be an excellent way of reducing noise, and therefore error. But what happens if people are listening to one another? You might well think that their doing so is likely to help. After all, people can learn from one another and thus figure out what is right. Under favorable circumstances, in which people share what they know, deliberating groups can indeed do well. But independence is a prerequisite for the wisdom of crowds. If people are not making their own judgments and are relying instead on what other people think, crowds might not be so wise after all. Research has revealed exactly that problem. In simple estimation tasks—the number of crimes in a city, population increases over specified periods, the ([Location 1400](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1400))
    - Tags: [[pink]] 
- length of a border between nations—crowds were indeed wise as long as they registered their views independently. But if they learned the estimates of other people—for example, the average estimate of a group of twelve—the crowd did worse. As the authors put it, social influences are a problem because they reduce “group diversity without diminishing the collective error.” The irony is that while multiple independent opinions, properly aggregated, can be strikingly accurate, even a little social influence can produce a kind of herding that undermines the wisdom of crowds. ([Location 1407](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1407))
    - Tags: [[pink]] 
- Some of the studies we are describing involve informational cascades. Such cascades are pervasive. They help explain why similar groups in business, government, and elsewhere can go in multiple directions and why small changes can produce such different outcomes and hence noise. We are able to see history only as it was actually run, but for many groups and group decisions, there are clouds of possibilities, only one of which is realized. ([Location 1411](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1411))
    - Tags: [[pink]] 
- The trick in this example is that Arthur’s initial judgment has started a process by which several people are led to participate in a cascade, leading the group to opt unanimously for Thomas—even if some of those who support him actually have no view and even if others think he is not the best choice at all. ([Location 1432](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1432))
    - Tags: [[pink]] 
- This example, of course, is highly artificial. But ([Location 1435](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1435))
    - Tags: [[pink]] 
- within groups of all kinds, something like it happens all the time. People learn from others, and if early speakers seem to like something or want to do something, others might assent. At least this is so if they do not have reason to distrust them and if they lack a good reason to think that they are wrong. For our purposes, the most important point is that informational cascades make noise across groups possible and even likely. In the example we have given, Arthur spoke first and favored Thomas. But suppose that Barbara had spoken first and favored Sam. Or suppose that Arthur had felt slightly differently and preferred Julie. On plausible assumptions, the group would have turned to Sam or Julie, not because they are better but because that is how the cascade would have worked itself out. That is the central finding of the music download experiment (and its cousins). Note that it is not necessarily irrational for people to participate in informational cascades. If people are unsure about whom to hire, they might be smart to follow others. As the number of people who share the same view gets larger, relying on them becomes smarter still. Nonetheless, there are two problems. First, people tend to neglect the possibility that most of the people in the crowd are in a cascade, too—and are not making independent judgments of their own. When we see three, ten, or twenty people embracing ([Location 1435](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1435))
    - Tags: [[pink]] 
- some conclusion, we might well underestimate the extent to which they are all following their predecessors. We might think that their shared agreement reflects collective wisdom, even if it reflects the initial views of just a few people. Second, informational cascades can lead groups of people in truly terrible directions. After all, Arthur might have been wrong about Thomas. Information is not, of course, the only reason that group members are influenced by one another. Social pressures also matter. At a company or in government, people might silence themselves so as not to appear uncongenial, truculent, obtuse, or stupid. They want to be team players. That is why they follow the views and actions of others. People think that they know what is right or probably right, but they nonetheless go along with the apparent consensus of the group, or the views of early speakers, to stay in the group’s good graces. ([Location 1445](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1445))
    - Tags: [[pink]] 
- Across groups, social influences also produce noise. If someone starts a meeting by favoring a major change in the company’s direction, that person might initiate a discussion that leads a group unanimously to support the change. Their agreement might be a product of social pressures, not of conviction. If someone else had started the meeting by indicating a different view, or if the initial speaker had decided to be silent, the discussion might have headed in an altogether different direction—and for the same reason. Very similar groups can end up in divergent places because of social pressures. ([Location 1458](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1458))
    - Tags: [[pink]] 
- Recall the basic finding of group polarization: after people talk with one another, they typically end up at a more extreme point in line with their original inclinations. Our experiment illustrates this effect. ([Location 1489](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1489))
    - Tags: [[pink]] 
- The explanations for group polarization are, in turn, similar to the explanations for cascade effects. Information plays a major role. If most people favor a severe punishment, then the group will hear many arguments in favor of severe punishment—and fewer arguments the other way. If group members are listening to one another, they will shift in the direction of the dominant tendency, rendering the group more unified, more confident, and more extreme. And if people care about their reputation within the group, they will shift in the direction of the dominant tendency, which will also produce polarization. ([Location 1493](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1493))
    - Tags: [[pink]] 
- We have seen that level noise and pattern noise make differences between the opinions of group members larger than they should be (and larger than we would expect). We have also seen that occasion noise—fatigue, mood, comparison points—may affect the judgment of the first person who speaks. Group dynamics can amplify this noise. As a result, deliberating groups tend to be noisier than statistical groups that merely average individual judgments. ([Location 1503](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1503))
    - Tags: [[pink]] 
- “Everything seems to depend on early popularity. We’d better work hard to make sure that our new release has a terrific first week.” “As I always suspected, ideas about politics and economics are a lot like movie stars. If people think that other people like them, such ideas can go far.” “I’ve always been worried that when my team gets together, we end up confident and unified—and firmly committed to the course of action that we choose. I guess there’s something in our internal processes that isn’t going all that well!” ([Location 1511](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1511))
    - Tags: [[pink]] 
- A measure that captures this intuition is the percent concordant (PC), which answers a more specific question: Suppose you take a pair of employees at random. What is the probability that the one who scored higher on an evaluation of potential also performs better on the job? If the accuracy of the early ratings were perfect, the PC would be 100%: the ranking of two employees by potential would be a perfect prediction of their eventual ranking by performance. If the predictions were entirely useless, concordance would occur by chance only, and the “higher-potential” employee would be just as likely as not to perform better: PC would be 50%. ([Location 1527](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1527))
    - Tags: [[pink]] 
- PC is an immediately intuitive measure of covariation, which is a large advantage, but it is not the standard measure that social scientists use. The standard measure is the correlation coefficient (r), which varies between 0 and 1 when two variables are positively related. In the preceding example, the correlation between height and foot size is about .60. There are many ways to think about the correlation coefficient. Here is one that is intuitive enough: the correlation between two variables is their percentage of shared determinants. Imagine, for instance, that some trait is entirely genetically determined. We would expect to find a .50 correlation on that trait between siblings, who have 50% of their genes in common, and a .25 correlation between first cousins, who have 25% of their genes in common. We can also read the .60 correlation between height and foot size as suggesting that 60% of the causal factors that determine height also determine shoe size. ([Location 1533](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1533))
    - Tags: [[pink]] 
- The informal approach you took to this problem is known as clinical judgment. You consider the information, perhaps engage in a quick computation, consult your intuition, and come up with a judgment. In fact, clinical judgment is the process that we have described simply as judgment in this book. ([Location 1577](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1577))
    - Tags: [[pink]] 
- This technique, called multiple regression, produces a predictive score that is a weighted average of the predictors. It finds the optimal set of weights, chosen to maximize the correlation between the composite prediction and the target variable. The optimal weights minimize the MSE (mean squared error) of the predictions—a prime example of the dominant role of the least squares principle in statistics. As you might expect, the predictor that is most closely correlated with the target variable gets a large weight, and useless predictors get a weight of zero. Weights could also be negative: the candidate’s number of unpaid traffic tickets would probably get a negative weight as a predictor of managerial success. The use of multiple regression is an example of mechanical prediction. There are many kinds of mechanical prediction, ranging from simple rules (“hire anyone who completed high school”) to sophisticated artificial intelligence models. But linear regression models are the most common (they have been called “the workhorse of judgment and decision-making research”). To minimize jargon, we will refer to linear models as simple models. The study that we illustrated with Monica and Nathalie was one of many comparisons of clinical and mechanical predictions, which all share a simple structure: A set of predictor variables (in our example, the ratings of candidates) are used to predict a target outcome (the job evaluations of the same people); Human judges make clinical predictions; A rule (such as multiple regression) uses the same predictors to produce mechanical predictions of the same outcomes; ([Location 1591](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1591))
    - Tags: [[pink]] 
- The overall accuracy of clinical and mechanical predictions is compared. ([Location 1605](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1605))
    - Tags: [[pink]] 
- When people are introduced to clinical and mechanical prediction, they want to know how the two compare. How good is human judgment, relative to a formula? The question had been asked before, but it attracted much attention only in 1954, when Paul Meehl, a professor of psychology at the University of Minnesota, published a book titled Clinical Versus Statistical Prediction: A Theoretical Analysis and a Review of the Evidence. Meehl reviewed twenty studies in which a clinical judgment was pitted against a mechanical prediction for such outcomes as academic success and psychiatric prognosis. He reached the strong conclusion that simple mechanical rules were generally superior to human judgment. Meehl discovered that clinicians and other professionals are distressingly weak in what they often see as their unique strength: the ability to integrate information. ([Location 1606](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1606))
    - Tags: [[pink]] 
- Meehl’s results strongly suggest that any satisfaction you felt with the quality of your judgment was an illusion: the illusion of validity. ([Location 1627](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1627))
    - Tags: [[pink]] 
- The illusion of validity is found wherever predictive judgments are made, because of a common failure to distinguish between two stages of the prediction task: evaluating cases on the evidence available and predicting actual outcomes. You can often be quite confident in your assessment of which of two candidates looks better, but guessing which of them will actually be better is an altogether different kettle of fish. It is safe to assert, for instance, that Nathalie looks like a stronger candidate than Monica, but it is not at all safe to assert that Nathalie will be a more successful executive than Monica. The reason is straightforward: you know most of what you need to know to assess the two cases, but gazing into the future is deeply uncertain. ([Location 1628](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1628))
    - Tags: [[pink]] 
- Unfortunately, the difference gets blurred in our thinking. If you find yourself confused by the distinction between cases and predictions, you are in excellent company: Everybody finds that distinction confusing. If you are as confident in your predictions as you are in your evaluation of cases, however, you are a victim of the illusion of validity. ([Location 1634](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1634))
    - Tags: [[pink]] 
- Meehl himself was ambivalent about his findings. Because his name is associated with the superiority of statistics over clinical judgment, we might imagine him as a relentless critic of human insight, or as the godfather of quants, as we would say today. But that would be a caricature. Meehl, in addition to his academic career, was a practicing psychoanalyst. A picture of Freud hung in his office. He was a polymath who taught classes not just in psychology but also in philosophy and law and who wrote about metaphysics, religion, political science, and even parapsychology. (He insisted that “there is something to telepathy.”) None of these characteristics fits the stereotype of a hard-nosed numbers guy. Meehl had no ill will toward clinicians—far from it. But as he put it, the evidence for the advantage of the mechanical approach to combining inputs was “massive and consistent.” ([Location 1640](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1640))
    - Tags: [[pink]] 
- The findings support a blunt conclusion: simple models beat humans. ([Location 1652](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1652))
    - Tags: [[pink]] 
- Goldberg: The Model of You Beats You ([Location 1652](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1652))
    - Tags: [[pink]] 
- The question that drove Goldberg’s research was how well a simple model of the judge would predict real outcomes. Since the model is a crude approximation of the judge, we could sensibly assume that it cannot perform as well. How much accuracy is lost when the model replaces the judge? The answer may surprise you. Predictions did not lose accuracy when the model generated predictions. They improved. In most cases, the model out-predicted the professional on which it was based. The ersatz was better than the original product. This conclusion has been confirmed by studies in many fields. An early replication of Goldberg’s work involved the forecasting of graduate school success. ([Location 1672](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1672))
    - Tags: [[pink]] 
- Why is that so? To understand Goldberg’s finding, we need to understand what accounts for the differences between you and the model of you. What causes the discrepancies between your actual judgments and the output of a simple model that predicts them? ([Location 1687](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1687))
    - Tags: [[pink]] 
- one who achieves the same average with clear strengths and marked weaknesses, the model of you will not reproduce your complex rules—even if you apply them with flawless consistency. Failing to reproduce your subtle rules will result in a loss of accuracy when your subtlety is valid. Suppose, for instance, that you must predict success at a difficult task from two inputs, skill and motivation. A weighted average is not a good formula, because no amount of motivation is sufficient to overcome a severe skill deficit, and vice versa. If you use a more complex combination of the two inputs, your predictive accuracy will be enhanced and will be higher than that achieved by a model that fails to capture this subtlety. On the other hand, complex rules will often give you only the illusion of validity and in fact harm the quality of your judgments. Some subtleties are valid, but many are not. In addition, a simple model of you will not represent the pattern noise in your judgments. It cannot replicate the positive and negative errors that arise from arbitrary reactions you may have to a particular case. Neither will the model capture the influences of the momentary context and of your mental state when you make a particular judgment. Most likely, these noisy errors of judgment are not systematically correlated with anything, which means that for most purposes, they can be considered random. The effect of removing noise from your judgments will always be an improvement of your predictive accuracy. ([Location 1692](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1692))
    - Tags: [[pink]] 
- In short, replacing you with a model of you does two things: it eliminates your subtlety, and it eliminates your pattern noise. The robust finding that the model of the judge is more valid than the judge conveys an important message: the gains from subtle rules in human judgment—when they exist—are generally not sufficient to compensate for the detrimental effects of noise. You may believe that you are subtler, more insightful, and more nuanced than the linear caricature of your thinking. But in fact, you are mostly noisier. ([Location 1705](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1705))
    - Tags: [[pink]] 
- Speaking of Judgments and Models “People believe they capture complexity and add subtlety when they make judgments. But the complexity and the subtlety are mostly wasted—usually they do not add to the accuracy of simple models.” “More than sixty years after the publication of Paul Meehl’s book, the idea that mechanical prediction is superior to people is still shocking.” “There is so much noise in judgment that a noise-free model of a judge achieves more accurate predictions than the actual judge does.” ([Location 1732](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1732))
    - Tags: [[pink]] 
- More Simplicity: Robust and Beautiful ([Location 1756](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1756))
    - Tags: [[pink]] 
- Robyn Dawes was another member of the Eugene, Oregon, team of stars that studied judgment in the 1960s and 1970s. In 1974, Dawes achieved a breakthrough in the simplification of prediction tasks. His idea was surprising, almost heretical: instead of using multiple regression to determine the precise weight of each predictor, he proposed giving all the predictors equal weights. ([Location 1757](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1757))
    - Tags: [[pink]] 
- Dawes labeled the equal-weight formula an improper linear model. His surprising discovery was that these equal-weight models are about as accurate as “proper” regression models, and far superior to clinical judgments. Even the proponents of improper models admit that this claim is implausible and “contrary to statistical intuition.” Indeed, Dawes and his assistant, Bernard Corrigan, initially struggled to publish their paper in scientific journals; editors simply did not believe them. If you think about the example of Monica and Nathalie in the previous chapter, you probably believe that some predictors matter more than others. Most people, for instance, would give leadership a higher weight than technical skills. How can a straight unweighted average predict someone’s performance better than a carefully weighted average, or better than the judgment of an expert? Today, many years after Dawes’s breakthrough, the statistical phenomenon that so surprised his contemporaries is well understood. As explained earlier in this book, multiple regression computes “optimal” weights that minimize squared errors. But multiple regression minimizes error in the original data. The formula therefore adjusts itself to predict every random fluke in the data. If, for instance, the sample includes a few managers who have high technical skills and who also performed exceptionally well for unrelated reasons, the model will exaggerate the weight of technical skill. ([Location 1760](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1760))
    - Tags: [[pink]] 
- The immediate implication of Dawes’s work deserves to be widely known: you can make valid statistical predictions without prior data about the outcome that you are trying to predict. All you need is a collection of predictors that you can trust to be correlated with the outcome. ([Location 1785](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1785))
    - Tags: [[pink]] 
- To use Dawes’s phrase, which has become a meme among students of judgment, there is a “robust beauty” in equal weights. The final sentence of the seminal article that introduced the idea offered another pithy summary: “The whole trick is to decide what variables to look at and then to know how to add.” ([Location 1793](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1793))
    - Tags: [[pink]] 
- Even More Simplicity: Simple Rules Another style of simplification is through frugal models, or simple rules. Frugal models are models of ([Location 1795](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1795))
    - Tags: [[pink]] 
- reality that look like ridiculously simplified, back-of-the-envelope calculations. But in some settings, they can produce surprisingly good predictions. ([Location 1797](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1797))
    - Tags: [[pink]] 
- The example illustrates a general rule: the combination of two or more correlated predictors is barely more predictive than the best of them on its own. Because, in real life, predictors are almost always correlated to one another, this statistical fact supports the use of frugal approaches to prediction, which use a small number of predictors. Simple rules that can be applied with little or no computation have produced impressively accurate predictions in some settings, compared with models that use many more predictors. ([Location 1801](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1801))
    - Tags: [[pink]] 
- Speaking of Rules and Algorithms “When there is a lot of data, machine-learning algorithms will do better than humans and better than simple models. But even the simplest rules and algorithms have big advantages over human judges: they are free of noise, and they do not attempt to apply complex, usually invalid insights about the predictors.” “Since we lack data about the outcome we must predict, why don’t we use an equal-weight model? It will do almost as well as a proper model, and will surely do better than case-by-case human judgment.” “You disagree with the model’s forecast. I get it. But is there a broken leg here, or do you just dislike the prediction?” ([Location 1927](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1927))
    - Tags: [[pink]] 
- “The algorithm makes mistakes, of course. But if human judges make even more mistakes, whom should we trust?” ([Location 1933](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1933))
    - Tags: [[pink]] 
- One review of intuition in managerial decision making defines it as “a judgment for a given course of action that comes to mind with an aura or conviction of rightness or plausibility, but without clearly articulated reasons or justifications—essentially ‘knowing’ but without knowing why.” We propose that this sense of knowing without knowing why is actually the internal signal of judgment completion that we mentioned in chapter 4. The internal signal is a self-administered reward, one people work hard (or sometimes not so hard) to achieve when they reach closure on a judgment. It is a satisfying emotional experience, a pleasing sense of coherence, in which the evidence considered and the judgment reached feel right. All the pieces of the jigsaw puzzle seem to fit. (We will see later that this sense of coherence is often bolstered by hiding or ignoring pieces of evidence that don’t fit.) What makes the internal signal important—and misleading—is that it is construed not as a feeling but as a belief. This emotional experience (“the evidence feels right”) masquerades as rational confidence in the validity of one’s judgment (“I know, even if I don’t know why”). ([Location 1945](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1945))
    - Tags: [[pink]] 
- Confidence is no guarantee of accuracy, however, and many confident predictions turn out to be wrong. While both bias and noise contribute to prediction errors, the largest source of such errors is not the limit on how good predictive judgments are. It is the limit on how good they could be. This limit, which we call objective ignorance, is the focus of this chapter. ([Location 1954](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1954))
    - Tags: [[pink]] 
- Both intractable uncertainty (what cannot possibly be known) and imperfect information (what could be known but isn’t) make perfect prediction impossible. These unknowns are not problems of bias or noise in your judgment; they are objective characteristics of the task. This objective ignorance of important unknowns severely limits achievable accuracy. We take a terminological liberty here, replacing the commonly used uncertainty with ignorance. This term helps limit the risk of confusion between uncertainty, which is about the world and the future, and noise, which is variability in judgments that should be identical. There is more information (and less objective ignorance) in some situations than in others. Most professional judgments are pretty good. With respect to many illnesses, doctors’ predictions are excellent, and for many legal disputes, lawyers can tell you, with great accuracy, how judges are likely to rule. In general, however, you can safely expect that people who engage in predictive tasks will underestimate their objective ignorance. Overconfidence is one of the best-documented cognitive biases. In particular, judgments of one’s ability to make precise predictions, even from limited information, are notoriously overconfident. What we said of noise in predictive judgments can also be said of objective ignorance: wherever there is prediction, there is ignorance, and more of it than you think. ([Location 1978](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=1978))
    - Tags: [[pink]] 
- Our conclusion, then, is that pundits should not be blamed for the failures of their distant predictions. They do, however, deserve some criticism for attempting an impossible task and for believing they can succeed in it. ([Location 2010](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2010))
    - Tags: [[pink]] 
- The previous chapters may have given you the impression that algorithms are crushingly superior to predictive judgments. That impression, however, would be misleading. Models are consistently better than people, but not much better. There is essentially no evidence of situations in which people do very poorly and models do very well with the same information. In chapter 9, we mentioned a review of 136 studies that demonstrated the superiority of mechanical aggregation over clinical judgment. While the evidence of that superiority is indeed “massive and consistent,” the performance gap is not large. Ninety-three of the studies in the review ([Location 2021](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2021))
    - Tags: [[pink]] 
- focused on binary decisions and measured the “hit rate” of clinicians and formulas. In the median study, clinicians were right 68% of the time, formulas 73% of the time. A smaller subset of 35 studies used the correlation coefficient as a measure of accuracy. In these studies, clinicians achieved a median correlation with the outcome of .32 (PC = 60%), while formulas achieved .56 (PC = 69%). On both metrics, formulas are consistently better than clinicians, but the limited validity of the mechanical predictions remains striking. The performance of models does not change the picture of a fairly low ceiling of predictability. What about artificial intelligence? As we noted, AI often performs better than simpler models do. In most applications, however, its performance remains far from perfect. ([Location 2026](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2026))
    - Tags: [[pink]] 
- By insisting on the impossibility of perfect prediction, we might seem to be stating the obvious. Admittedly, asserting that the future is unpredictable is hardly a conceptual breakthrough. However, the obviousness of this fact is matched only by the regularity with which it is ignored, as the consistent findings about predictive overconfidence demonstrate. The prevalence of overconfidence sheds new light on our informal poll of gut-trusting decision makers. We have noted that people often mistake their subjective sense of confidence for an indication of predictive validity. After you reviewed the evidence in ([Location 2047](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2047))
    - Tags: [[pink]] 
- chapter 9 about Nathalie and Monica, for instance, the internal signal you felt when you reached a coherent judgment gave you confidence that Nathalie was the stronger candidate. If you were confident in that prediction, however, you fell for the illusion of validity: the accuracy you can achieve with the information you were given is quite low. People who believe themselves capable of an impossibly high level of predictive accuracy are not just overconfident. They don’t merely deny the risk of noise and bias in their judgments. Nor do they simply deem themselves superior to other mortals. They also believe in the predictability of events that are in fact unpredictable, implicitly denying the reality of uncertainty. In the terms we have used here, this attitude amounts to a denial of ignorance. The denial of ignorance adds an answer to the puzzle that baffled Meehl and his followers: why his message has remained largely unheeded, and why decision makers continue to rely on their intuition. When they listen to their gut, decision makers hear the internal signal and feel the emotional reward it brings. This internal signal that a good judgment has been reached is the voice of confidence, of “knowing without knowing why.” But an objective assessment of the evidence’s true predictive power will rarely justify that level of confidence. Giving up the emotional reward of intuitive certainty is not easy. Tellingly, leaders say they are especially likely to resort to intuitive decision making in situations that they perceive as highly uncertain. When the facts deny them the sense of understanding and confidence they crave, they turn to their intuition to provide it. The denial of ignorance is all the more tempting when ignorance is vast. ([Location 2051](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2051))
    - Tags: [[pink]] 
- Intuitive judgment comes with its reward, the internal signal. People are prepared to trust an algorithm that achieves a very high level of accuracy because it gives them a sense of certainty that matches or exceeds that provided by the internal signal. But giving up the emotional reward of the internal signal is a high price to pay when the alternative is some sort of mechanical process that does not even claim high validity. This observation has an important implication for the improvement of judgment. Despite all the evidence in favor of mechanical and algorithmic prediction methods, and despite the rational calculus that clearly shows the value of incremental improvements in predictive accuracy, many decision makers will reject decision-making approaches that deprive them of the ability to exercise their intuition. As long as algorithms are not nearly perfect—and, in many domains, objective ignorance dictates that they will never be—human judgment will not be replaced. That is why it must be improved. ([Location 2073](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2073))
    - Tags: [[pink]] 
- “Wherever there is prediction, there is ignorance, and probably more of it than we think. Have we checked whether the experts we trust are more accurate than dart-throwing chimpanzees?” “When you trust your gut because of an internal signal, not because of anything you really know, you are in denial of your objective ignorance.” “Models do better than people, but not by much. Mostly, we find mediocre human judgments and slightly better models. Still, better is good, and models are better.” “We may never be comfortable using a model to make these decisions—we just need the internal signal to have enough confidence. So let’s make sure we have the best possible decision process.” ([Location 2080](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2080))
    - Tags: [[pink]] 
- We now turn to a broader question: how do we achieve comfort in a world in which many problems are easy but many others are dominated by objective ignorance? After all, where objective ignorance is severe, we should, after a while, become aware of the futility of crystal balls in human affairs. But that is not our usual experience of the world. Instead, as the previous chapter suggested, we maintain an unchastened willingness to make bold predictions about the future from little useful information. In this chapter, we address the prevalent and misguided sense that events that could not have been predicted can nevertheless be understood. What does this belief really mean? We raise that question in two contexts: the conduct of social science and the experience of the events of daily life. ([Location 2089](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2089))
    - Tags: [[pink]] 
- The logic behind this pessimistic conclusion requires some elaboration. When the authors of the Fragile Families challenge equate understanding with prediction (or the absence of one with the absence of the other), they use the term understanding in a specific sense. There are other meanings of the word: if you say you understand a mathematical concept or you understand what love is, you are probably not suggesting an ability to make any specific predictions. However, in the discourse of social science, and in most everyday conversations, a claim to understand something is a claim to understand what causes that thing. The sociologists who collected and studied the thousands of variables in the Fragile Families study were looking for the causes of the outcomes they observed. Physicians who understand what ails a patient are claiming that the pathology they have diagnosed is the cause of the symptoms they have observed. To understand is to describe a causal chain. The ability to make a prediction is a measure of whether such a causal chain has indeed been identified. And correlation, the measure of predictive accuracy, is a measure of how much causation we can explain. ([Location 2149](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2149))
    - Tags: [[pink]] 
- We must, however, remember that while correlation does not imply causation, causation does imply correlation. Where there is a causal link, we should find a correlation. ([Location 2162](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2162))
    - Tags: [[pink]] 
- In short, wherever there is causality, there is correlation. It follows that where there is causality, we should be able to predict—and correlation, the accuracy of this prediction, is a measure of how much causality we understand. Hence the conclusion of the Princeton researchers is this: the extent to which sociologists can predict events like evictions, as measured by a correlation of .22, is an indication of how much—or how little—they understand about the life trajectories of these families. Objective ignorance sets a ceiling not only on our predictions but also on our understanding. ([Location 2165](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2165))
    - Tags: [[pink]] 
- If, as you read the first part of this chapter, you asked yourself what drives evictions and other life outcomes among fragile families, you engaged in the same sort of thinking as that of the researchers whose efforts we ([Location 2172](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2172))
    - Tags: [[pink]] 
- described. You applied statistical thinking: you were concerned with ensembles, such as the population of fragile families, and with the statistics that describe them, including averages, variances, correlations, and so on. You were not focused on individual cases. A different mode of thinking, which comes more naturally to our minds, will be called here causal thinking. Causal thinking creates stories in which specific events, people, and objects affect one another. To experience causal thinking, picture yourself as a social worker who follows the cases of many underprivileged families. You have just heard that one of these families, the Joneses, has been evicted. Your reaction to this event is informed by what you know about the Joneses. As it happens, Jessica Jones, the family’s breadwinner, was laid off a few months ago. She could not find another job, and since then, she has been unable to pay the rent in full. She made partial payments, pleaded with the building manager several times, and even asked you to intervene (you did, but he remained unmoved). Given this context, the Joneses’ eviction is sad but not surprising. It feels, in fact, like the logical end of a chain of events, the inevitable denouement of a foreordained tragedy. ([Location 2173](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2173))
    - Tags: [[pink]] 
- These alternate narratives are as unsurprising as the main one—if the end is known. Whatever the outcome (eviction or not), once it has happened, causal thinking makes it feel entirely explainable, indeed predictable. ([Location 2186](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2186))
    - Tags: [[pink]] 
- In the valley of the normal, events unfold just like the Joneses’ eviction: they appear normal in hindsight, although they were not expected, and although we could not have predicted them. This is because the process of understanding reality is backward-looking. An occurrence that was not actively anticipated (the eviction of the Jones family) triggers a search of memory for a candidate cause (the tough job market, the inflexible manager). The search stops when a good narrative is found. Given the opposite outcome, the search would have produced equally compelling causes (Jessica Jones’s tenacity, the understanding manager). ([Location 2195](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2195))
    - Tags: [[pink]] 
- When you explain an unexpected but unsurprising outcome in this way, the destination that is eventually reached always makes sense. This is what we mean by understanding a story, and this is what makes reality appear predictable—in hindsight. Because the event explains itself as it occurs, we are under the illusion that it could have been anticipated. More broadly, our sense of understanding the world depends on our extraordinary ability to construct narratives that explain the events we observe. The search for causes is almost always successful because causes can be drawn from an unlimited reservoir of facts and beliefs about the world. As anyone who listens to the evening news knows, for example, few large movements of the stock market remain unexplained. The same news flow can “explain” either a fall of the indices (nervous investors are worried about the news!) or a rise (sanguine investors remain optimistic!). When the search for an obvious cause fails, our first resort is to produce an explanation by filling a blank in our model of the world. This is how we infer a fact we had not known before (for instance, that the manager was an unusually kind person). Only when our model of the world cannot be tweaked to generate the outcome do we tag this outcome as surprising ([Location 2203](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2203))
    - Tags: [[pink]] 
- and start to search for a more elaborate account of it. Genuine surprise occurs only when routine hindsight fails. This continuous causal interpretation of reality is how we “understand” the world. Our sense of understanding life as it unfolds consists of the steady flow of hindsight in the valley of the normal. This sense is fundamentally causal: new events, once known, eliminate alternatives, and the narrative leaves little room for uncertainty. As we know from classic research on hindsight, even when subjective uncertainty does exist for a while, memories of it are largely erased when the uncertainty is resolved. ([Location 2212](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2212))
    - Tags: [[pink]] 
- Causal thinking avoids unnecessary effort while retaining the vigilance needed to detect abnormal events. In contrast, statistical thinking is effortful. It requires the attention resources that only System 2, the mode of thinking associated with slow, deliberate thought, can bring to bear. Beyond an elementary level, statistical thinking also demands specialized training. This type of thinking begins with ensembles and considers individual cases as instances of broader categories. ([Location 2223](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2223))
    - Tags: [[pink]] 
- The distinction between these two views is a recurring theme of this book. Relying on causal thinking about a single case is a source of predictable errors. Taking the statistical view, which we will also call the outside view, is a way to avoid these errors. At this point, all we need to emphasize is that the causal mode comes much more naturally to us. Even explanations that should properly be treated as statistical are easily turned into causal narratives. Consider ([Location 2228](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2228))
    - Tags: [[pink]] 
- assertions such as “they failed because they lacked experience” or “they succeeded because they had a brilliant leader.” It would be easy for you to think of counterexamples, in which inexperienced teams succeeded and brilliant leaders failed. The correlations of experience and brilliance with success are at best moderate and probably low. Yet a causal attribution is readily made. Where causality is plausible, our mind easily turns a correlation, however low, into a causal and explanatory force. Brilliant leadership is accepted as a satisfactory explanation of success, and inexperience as an explanation of failure. The reliance on flawed explanations is perhaps inevitable, if the alternative is to give up on understanding our world. However, causal thinking and the illusion of understanding the past contribute to overconfident predictions of the future. As we will see, the preference for causal thinking also contributes to the neglect of noise as a source of error, because noise is a fundamentally statistical notion. Causal thinking helps us make sense of a world that is far less predictable than we think. It also explains why we view the world as far more predictable than it really is. In the valley of the normal, there are no surprises and no inconsistencies. The future seems as predictable as the past. And noise is neither heard nor seen. ([Location 2231](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2231))
    - Tags: [[pink]] 
- Speaking of the Limits of Understanding “Correlations of about .20 (PC = 56%) are quite common in human affairs.” “Correlation does not imply causation, but causation does imply correlation.” “Most normal events are neither expected nor surprising, and they require no explanation.” “In the valley of the normal, events are neither expected nor surprising—they just explain themselves.” “We think we understand what is going on here, but could we have predicted it?” ([Location 2241](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2241))
    - Tags: [[pink]] 
- This book extends half a century of research on intuitive human judgment, the so-called heuristics and biases program. The first four decades of this research program were reviewed in Thinking, Fast and Slow, which explored the psychological mechanisms that explain both the marvels and the flaws of intuitive thinking. The central idea of the program was that people who are asked a difficult question use simplifying operations, called heuristics. In general, heuristics, which are produced by fast, intuitive thinking, also known as System 1 thinking, are quite useful and yield adequate answers. But sometimes they lead to biases, which we have described as systematic, predictable errors of judgment. The heuristics and biases program focused on what people have in common, not on how they differ. It showed that the processes that cause judgment errors are widely shared. Partly because of this ([Location 2264](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2264))
    - Tags: [[pink]] 
- history, people who are familiar with the notion of psychological bias often assume that it always produces statistical bias, a term we use in this book to mean measurements or judgments that mostly deviate from the truth in the same direction. Indeed, psychological biases create statistical bias when they are broadly shared. However, psychological biases create system noise when judges are biased in different ways, or to a different extent. Whether they cause statistical bias or noise, of course, psychological biases always create error. ([Location 2270](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2270))
    - Tags: [[pink]] 
- Judgment biases are often identified by reference to a true value. There is bias in predictive judgments if errors are mostly in one direction rather than the other. For instance, when people forecast how long it will take them to complete a project, the mean of their estimates is usually much lower than the time they will actually need. This familiar psychological bias is known as the planning fallacy. Often, though, there is no true value to which judgments can be compared. Given how much we stressed that statistical bias can be detected only when the true value is known, you may wonder how psychological biases can be studied when the truth ([Location 2275](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2275))
    - Tags: [[pink]] 
- is unknown. The answer is that researchers confirm a psychological bias either by observing that a factor that should not affect judgment does have a statistical effect on it, or that a factor that should affect judgment does not. ([Location 2280](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2280))
    - Tags: [[pink]] 
- The answers should be clearly different, but they are not, suggesting that a factor that should influence judgments is ignored. (This psychological bias is called scope insensitivity.) Systematic errors of judgment have been demonstrated in many fields, and the term bias is now used in many domains, including business, politics, policymaking, and law. As the word is commonly used, its meaning is broad. In addition to the cognitive definition we use here (referring to a psychological mechanism and to the error that this mechanism typically produces), the word is frequently used to suggest that someone is biased against a certain group (e.g., gender biases or racial biases). It can also mean that someone favors a particular conclusion, as when we read that someone is biased by a conflict of interest or by a political opinion. We include these types of bias in our discussion of the psychology of judgment errors because all psychological biases cause both statistical bias and noise. There is one usage to which we strongly object. In this usage, costly failures are attributed to unspecified “bias,” and acknowledgments of error are accompanied by promises to “work hard to eliminate biases in our decision making.” These statements mean nothing more than “mistakes were made” and “we will try hard to do better.” To be sure, some failures truly are caused by predictable errors associated with specific psychological biases, and we believe in the feasibility of interventions to reduce bias (and noise) in judgments and decisions. But blaming every undesirable outcome on biases is a worthless explanation. We recommend reserving the word bias for specific and ([Location 2298](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2298))
    - Tags: [[pink]] 
- identifiable errors and the mechanisms that produce them. ([Location 2310](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2310))
    - Tags: [[pink]] 
- You have now experienced the essential idea of the heuristics and biases program: a heuristic for answering a difficult question is to find the answer to an easier one. The substitution of one question for the other ([Location 2341](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2341))
    - Tags: [[pink]] 
- causes predictable errors, called psychological biases. ([Location 2342](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2342))
    - Tags: [[pink]] 
- This sort of bias is manifest in the Bill example. Errors are bound to occur when a judgment of similarity is substituted for a judgment of probability, because probability is constrained by a special logic. In particular, Venn diagrams apply only to probability, not to similarity. Hence the predictable logical error that many people make. ([Location 2343](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2343))
    - Tags: [[pink]] 
- Both questions are examples of taking what we have called the outside view: when you take this view, you think of the student, or of Gambardi, as a member of a class of similar cases. You think statistically about the class, instead of thinking causally about the focal case. Taking the outside view can make a large difference and prevent significant errors. A few minutes of research would reveal that estimates of CEO turnover in US companies hover around 15% annually. This statistic suggests that the average incoming CEO has a roughly 72% probability of still being around after two years. Of course, this number is only a starting point, and the specifics of Gambardi’s case will affect your final estimate. But if you focused solely on what you were told about Gambardi, you neglected a key piece of information. (Full disclosure: We wrote the Gambardi case to illustrate noisy judgment; it took us weeks before we realized that it was also a prime example of the bias we describe here, which is called base-rate neglect. Thinking of base rates is no more automatic for the authors of this book than for anyone else.) Substitution of one question for another is not restricted to similarity and probability. Another example is the replacement of a judgment of frequency by an impression of the ease with which instances come to mind. For example, the perception of the risk of airplane crashes or hurricanes rises briefly after well-publicized instances of such events. In theory, a judgment of risk should be based on a long-term average. In reality, recent incidents are given more weight because they come more easily to mind. Substituting a judgment of how easily examples come to mind for an assessment of frequency is known as the availability heuristic. ([Location 2352](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2352))
    - Tags: [[pink]] 
- Consider how we tend to answer each of the following questions by using its easier substitute: ([Location 2366](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2366))
    - Tags: [[pink]] 
- Am I satisfied with my life as a whole? What is my mood right now? ([Location 2370](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2370))
    - Tags: [[pink]] 
- Regardless of the question, substituting one question for another will lead to an answer that does not give different aspects of the evidence their appropriate weights, and incorrect weighting of the evidence inevitably results in error. For example, a full answer to a question about life satisfaction clearly requires consulting more than your current mood, but evidence suggests that mood is in fact overly weighted. In the same manner, substituting similarity for probability leads to neglect of base rates, which are quite properly irrelevant when judging similarity. And factors such as irrelevant variations in the aesthetics of the document that presents a business plan should be given little or no weight in assessing the value of a company. Any impact they have on the judgment is likely to reflect a misweighting of the evidence and will produce error. ([Location 2371](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2371))
    - Tags: [[pink]] 
- This example illustrates a different type of bias, which we call conclusion bias, or prejudgment. Like Lucas, we often start the process of judgment with an inclination to reach a particular conclusion. When we do that, we let our fast, intuitive System 1 thinking suggest a conclusion. Either we jump to that conclusion and simply bypass the process of gathering and integrating information, or we mobilize System 2 thinking—engaging in deliberate thought—to come up with arguments that support our prejudgment. In that case, the evidence will be selective and distorted: because of confirmation bias and desirability bias, we will tend to collect and interpret evidence selectively ([Location 2387](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2387))
    - Tags: [[pink]] 
- to favor a judgment that, respectively, we already believe or wish to be true. People often come up with plausible rationalizations for their judgments and will actually think that they are the cause of their beliefs. A good test of the role of prejudgment is to imagine that the arguments seemingly supporting our belief are suddenly proven invalid. ([Location 2391](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2391))
    - Tags: [[pink]] 
- Prejudgments are evident wherever we look. Like Lucas’s reaction, they often have an emotional component. The psychologist Paul Slovic terms this the affect heuristic: people determine what they think by consulting their feelings. We like most things about politicians we favor, and we dislike even the looks and the voices of politicians we dislike. That is one reason that smart companies work so hard to attach a positive affect to their brand. Professors often notice that in a year when they get high marks for teaching, students ([Location 2398](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2398))
    - Tags: [[pink]] 
- also give the course material a high rating. In a year when students don’t like the professor so much, they give a low rating to the identical assigned readings. The same mechanism is at work even when emotion is not involved: regardless of the true reasons for your belief, you will be inclined to accept any argument that appears to support it, even when the reasoning is wrong. A subtler example of a conclusion bias is the anchoring effect, which is the effect that an arbitrary number has on people who must make a quantitative judgment. In a typical demonstration, you might be presented with a number of items whose price is not easy to guess, such as an unfamiliar bottle of wine. You are asked to jot down the last two digits of your Social Security number and indicate whether you would pay that amount for the bottle. Finally, you are asked to state the maximum amount you would be willing to pay for it. The results show that anchoring on your Social Security number will affect your final buying price. In one study, people whose Social Security numbers generated a high anchor (more than eighty dollars) stated that they were willing to pay about three times more than those with a low anchor (less than twenty dollars). Clearly, your Social Security number should not have a large effect on your judgment about how much a bottle of wine is worth, but it does. Anchoring is ([Location 2402](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2402))
    - Tags: [[pink]] 
- an extremely robust effect and is often deliberately used in negotiations. Whether you’re haggling in a bazaar or sitting down for a complex business transaction, you probably have an advantage in going first, because the recipient of the anchor is involuntarily drawn to think of ways your offer could be reasonable. People always attempt to make sense of what they hear; when they encounter an… ([Location 2412](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2412))
    - Tags: [[pink]] 
- Excessive Coherence Here is another experiment that will help you experience a third type of bias. You will read a description of a candidate for an executive position. The description consists of four adjectives, each written on a card. The deck of cards has just been shuffled. The first two cards have these two descriptors: Intelligent, Persistent. It would be reasonable to suspend judgment until the information is complete, but this is not what has happened: you already have an evaluation of the candidate, and it is positive. This judgment simply happened. You had no control over the process, and suspending judgment was not an option. Next, you draw the last two cards. Here is the full description now: Intelligent, Persistent, Cunning, Unprincipled. Your evaluation is no longer favorable, but it did not change enough. For comparison, consider the following description, which another shuffling of the deck could have produced: Unprincipled, Cunning, Persistent, Intelligent. This second description consists of the same adjectives, and yet—because of the order in which they are introduced—it is clearly much less appealing than the first. The word Cunning was only mildly negative when it followed Intelligent and Persistent, because we still believed (without reason) that the executive’s intentions were good. Yet when it follows Unprincipled, the… ([Location 2415](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2415))
    - Tags: [[pink]] 
- light of little evidence. Confirmation bias—the same tendency that leads us, when we have a prejudgment, to disregard conflicting evidence altogether—made us assign less importance than we should to subsequent data. (Another term to describe this phenomenon is the halo effect, because the candidate was evaluated in the positive “halo” of the first impression… ([Location 2430](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2430))
    - Tags: [[pink]] 
- In general, we jump to conclusions, then stick to them. We think we base our opinions on evidence, but the evidence we consider and our interpretation of it are likely to be distorted, at least to some extent, to fit our initial snap judgment. As a result, we maintain the coherence of the overall story that has emerged in our mind. This process is fine, of course, if the conclusions are correct. When the initial evaluation is erroneous, however, the tendency to stick to it in the face of contradictory evidence is likely to amplify errors. And this effect is difficult to control, because information that we have heard or seen is impossible to ignore and often difficult to forget. In court, judges sometimes instruct jurors to disregard an inadmissible piece of evidence they have heard, but this is not a realistic instruction (although it may be helpful in jury deliberation, where arguments explicitly based on this evidence can be rejected). ([Location 2442](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2442))
    - Tags: [[pink]] 
- We have briefly presented three types of biases that operate in different ways: substitution biases, which lead to a misweighting of the evidence; conclusion ([Location 2449](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2449))
    - Tags: [[pink]] 
- biases, which lead us either to bypass the evidence or to consider it in a distorted way; and excessive coherence, which magnifies the effect of initial impressions and reduces the impact of contradictory information. All three types of biases can, of course, produce statistical bias. They can also produce noise. Let’s start with substitution. Most people judge the probability that Bill is an accountant by the similarity of his profile to a stereotype: the result, in this experiment, is a shared bias. If every respondent makes the same mistake, there is no noise. But substitution does not always produce such unanimity. When the question “Is there climate change?” is replaced with “Do I trust the people who say it is real?,” it is easy to see that the answer will vary from one person to the next, depending on that person’s social circles, preferred sources of information, political affiliation, and so on. The same psychological bias creates variable judgments and between-person noise. Substitution can also be a source of occasion noise. If a question on life satisfaction is answered by consulting one’s immediate mood, the answer will inevitably vary for the same… ([Location 2450](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2450))
    - Tags: [[pink]] 
- traced to psychological biases. Prejudgments also produce both bias and noise. Return to an example we mentioned in the introduction: the shocking disparities in the percentage of asylum seekers that judges admit. When one judge admits 5% of applicants and another in the same courthouse admits 88%, we can be quite certain that they are biased in different directions. From a broader perspective, individual differences in biases can cause massive system noise. Of course, the system can also be biased to the extent that most or all judges are biased similarly. Finally, excessive coherence can produce either bias or noise, depending on whether the sequence of information and the meaning assigned to it are identical for all (or most) judges. Consider, for instance, a physically attractive candidate whose good looks create an early positive impression in most recruiters. If physical appearance is irrelevant to the position for which the candidate is considered, this positive halo will result in a shared error: a bias. On the other hand, many complex decisions require compiling information that arrives in an essentially random order. Consider the claims adjusters of chapter 2. The order in which data… ([Location 2461](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2461))
    - Tags: [[pink]] 
- Speaking of Heuristics, Biases, and Noise “We know we have psychological biases, but we should resist the urge to blame every error on unspecified ‘biases.’” “When we substitute an easier question for the one we should be answering, errors are bound to occur. For instance, we will ignore the base rate when we judge probability by similarity.” “Prejudgments and other conclusion biases lead ([Location 2477](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2477))
    - Tags: [[pink]] 
- people to distort evidence in favor of their initial position.” “We form impressions quickly and hold on to them even when contradictory information comes in. This tendency is called excessive coherence.” “Psychological biases cause statistical bias if many people share the same biases. In many cases, however, people differ in their biases. In those cases, psychological biases create system noise.” ([Location 2481](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2481))
    - Tags: [[pink]] 
- Look at the sky. How likely is it to rain in two hours? You probably had no difficulty answering this question. The judgment you made—for example, that it is “very likely” to rain soon—was produced effortlessly. Somehow, your evaluation of the sky’s darkness was converted into a probability judgment. What you just performed is an elementary example of matching. We have described judgment as an operation that assigns a value on a scale to a subjective impression (or to an aspect of an impression). Matching is an essential part of that operation. When you answer the question “On a scale of 1 to 10, how good is your mood?” or “Please give one to five stars to your shopping experience this morning,” you are matching: your task is to find a value on the judgment scale that matches your mood or experience. ([Location 2487](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2487))
    - Tags: [[pink]] 
- Conflicting cues make it more difficult to achieve a sense of coherence and to find a judgment that is a satisfactory match. The presence of conflicting cues characterizes complex judgments, in which we expect to find a lot of noise. ([Location 2509](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2509))
    - Tags: [[pink]] 
- the remainder of this chapter we focus on relatively simple judgments—especially those made on intensity scales. ([Location 2511](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2511))
    - Tags: [[pink]] 
- In ordinary conversation, the range of values for a scale is a function of the context. The comment “She has been saving a lot of money” has a different meaning when you are toasting the retirement of a successful investment banker than it has when you are congratulating a teenager who has been babysitting. And the meaning of words like large and small depends entirely on a frame of reference. We can, for example, make sense of a statement like “The large mouse ran up the trunk of the small elephant.” ([Location 2528](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2528))
    - Tags: [[pink]] 
- These examples of matching predictions are more likely than not to end in disappointment. On the other hand, matching predictions that are made when things are at their worst are more likely than not to be ([Location 2579](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2579))
    - Tags: [[pink]] 
- overly negative. Intuitive predictions that match the evidence are too extreme, both when they are optimistic and when they are pessimistic. (The technical term for such prediction errors is that they are nonregressive, because they fail to take into account a statistical phenomenon called regression to the mean.) It should be noted, however, that substitution and matching do not always govern predictions. In the language of two systems, the intuitive System 1 proposes quick associative solutions to problems as they arise, but these intuitions must be endorsed by the more reflective System 2 before they become beliefs. Matching predictions are sometimes rejected in favor of more complex responses. For example, people are more reluctant to match predictions to unfavorable than to favorable evidence. We suspect that you would hesitate to make a matching prediction of inferior college performance if Julie had been a late reader. The asymmetry between favorable and unfavorable predictions disappears when more information is available. We offer the outside view as a corrective for intuitive predictions of all kinds. ([Location 2580](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2580))
    - Tags: [[pink]] 
- The outside view can be neglected only in very easy problems, when the information available supports a prediction that can be made with complete confidence. When serious judgment is… ([Location 2591](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2591))
    - Tags: [[pink]] 
- Our limited ability to distinguish categories on intensity scales constrains the accuracy of the matching operation. Words such as large or rich assign the same label to a range of values on the dimension of size or wealth. This is a potentially important source of noise. The retiring investment banker surely deserves the label rich, but how rich is she? We have many adjectives to choose from: well-off, affluent, comfortable, wealthy, super-rich, and others. If you were given detailed descriptions of the wealth of some individuals and… ([Location 2593](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2593))
    - Tags: [[pink]] 
- The number of categories that we can distinguish on an intensity scale is given in… ([Location 2598](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2598))
    - Tags: [[pink]] 
- classic article in psychology, published in 1956: “The Magical Number Seven, Plus or Minus Two.” Beyond this limit, people tend to start to make errors—for instance, to assign A to a higher category than B when they would in fact rate B higher than A in a head-to-head comparison. Imagine a set of lines of four different lengths of between 2 and 4 inches, each line the same amount longer than the next one. You are shown one line at a time and have to call out a number between 1 and 4, where 1 goes with the shortest line and 4 with the longest. The task is easy. Now suppose you are shown lines of five different lengths and have to repeat the task calling out numbers 1 through 5. Still easy. When will you start making errors? Around the magical number of seven lines. Surprisingly, this number depends very little on the range of line lengths: if the lines were spaced between 2 and 6 inches, rather than between 2 and 4, you would still start making mistakes beyond seven lines. Much the same result is obtained when you are presented with tones that vary in loudness, or with lights of different brightness. There is… ([Location 2599](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2599))
    - Tags: [[pink]] 
- values on these dimensions. The matching operation is a versatile tool of fast, System 1 thinking and the core of many intuitive judgments, but it is crude. The magical number is not an absolute constraint. People can be trained to make finer distinctions by hierarchical categorization. For example, we can certainly discriminate several categories of wealth among multimillionaires, and judges can discriminate degrees of severity in multiple categories of crimes, themselves ordered in severity. For this refinement process to work, however, the categories must exist in advance and their boundaries must be clear. When assigning labels to a set of lines, you cannot decide to separate the longer lines from the shorter ones and treat them as two separate categories. Categorization is not under voluntary control when you are in the fast-thinking mode. There is a way to overcome the limited resolution of adjective scales: instead of using labels, use comparisons. Our ability to compare cases is much better than our ability to place them on a scale. Consider what you would do if instructed to use a twenty-point scale of quality to… ([Location 2609](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2609))
    - Tags: [[pink]] 
- time-consuming. You would first rate the restaurants, or singers, using the five-point rating scale to sort them into five categories. You would then rank the cases within each category, which you will usually be able to do with only a few ties: you probably know whether you prefer Joe’s Pizza to Fred’s Burgers, or Taylor Swift to Bob Dylan, even if you assigned them to the same category. To keep things simple, you could now distinguish four levels within each of the five categories. You can probably discriminate levels of contempt even among the singers you most dislike. The psychology of this exercise is straightforward. Explicit comparisons between objects of judgment support much finer discriminations than do ratings of objects evaluated one at a time. Judgments of line length tell a similar story: your ability to compare the length of lines that are shown in immediate succession is much better than your ability to label lengths, and you will be even more accurate when comparing lines that are in view at the same time. The advantage of comparative judgments applies to many domains. If you have a rough idea of people’s wealth, you will do better comparing individuals in the same range than you would by labeling their wealth individually. If you grade essays, you will be more precise when you rank them from best to worst than you are when you read and grade essays one by one. Comparative or relative judgments are more sensitive than categorical or absolute ones. As these examples suggest, they are also more effortful and time-consuming. Rating objects individually on scales that are explicitly comparative retains some of the benefits of comparative judgment. In some contexts, notably in education, recommendations of candidates for acceptance or promotion often require the recommender to locate the candidate in the “top 5%” or “top 20%” of some designated population, such as “students that you have taught” or “programmers with the same level of experience.” These ratings rarely deserve to be taken at face value because there is no way to keep the recommenders accountable for using the scale properly. Accountability is possible in some contexts: when managers rate employees or when analysts assess investments, a person who assigns 90% of cases to… ([Location 2619](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2619))
    - Tags: [[pink]] 
- procedure that compels explicitly comparative judgments is likely to reduce noise. In the next chapter, we further explore how using the wrong scales can add to noise. Speaking of Matching “Both of us say this movie is very good, but you seem to have enjoyed it a lot less than I did. We’re using the same words, but are we using the same scale?” “We thought Season 2 of this series would be just as spectacular as Season 1. We made a matching prediction,… ([Location 2639](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2639))
    - Tags: [[pink]] 
- This chapter focuses on the role of the response scale as a pervasive source of noise. ([Location 2677](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2677))
    - Tags: [[pink]] 
- both speakers and listeners. ([Location 2683](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2683))
    - Tags: [[pink]] 
- Our goals were to ([Location 2700](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2700))
    - Tags: [[pink]] 
- test a theory about the psychology of punitive damages and to investigate the role of the monetary scale (here dollars) as a main source of noise in this legal institution. ([Location 2700](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2700))
    - Tags: [[pink]] 
- How to determine a just punishment has been debated by philosophers and legal scholars for centuries. Our hypothesis, however, was that the question that philosophers find difficult is quite easy for ordinary people, who simplify the task by substituting an easy question for the hard one. The easy question, which is answered immediately when you are asked how much General Assistance should be punished is, “How angry am I?” The intensity of the intended punishment will then be matched to the intensity of the outrage. To test this outrage hypothesis, we asked different groups of participants to answer either the punitive intent question or the outrage question. We then compared the average ratings obtained on the two questions for the twenty-eight scenarios used in the study. As expected from the substitution ([Location 2702](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2702))
    - Tags: [[pink]] 
- idea, the correlation between the mean ratings of outrage and of punitive intent was a close-to-perfect 0.98 (PC = 94%). This correlation supports the outrage hypothesis: the emotion of outrage is the primary determinant of punitive intent. ([Location 2707](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2707))
    - Tags: [[pink]] 
- The design of the study allows us to compare the amount of noise in judgments of the same cases on three scales: outrage, punitive intent, and damage awards in dollars. ([Location 2732](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2732))
    - Tags: [[pink]] 
- We ([Location 2739](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2739))
    - Tags: [[pink]] 
- can therefore break down the overall variance of judgments into three elements: Variance of Judgments = Variance of Just Punishments + (Level Noise)2 + (Pattern Noise)2 ([Location 2739](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2739))
    - Tags: [[pink]] 
- An Unfortunate Conclusion The results are consistent with the theory we have outlined: dollar awards for all cases were anchored on the arbitrary number that each juror picked for the first case they saw. The relative ranking of cases reflects attitudes with fair accuracy and is thus not very noisy, but the absolute values of the dollar awards are essentially meaningless because they depend on the arbitrary number chosen in the first case. Ironically, the case that jurors assess in real trials is the first and only one they see. American legal practice requires civil juries to set a dollar award for one case, without the benefit of any guiding anchor. The law explicitly prohibits any communication to the jury of the size of punitive awards in other cases. The assumption implicit in the law is that jurors’ sense of justice will lead them directly from a consideration of an offense to the correct punishment. This assumption is psychological nonsense—it assumes an ability that humans do not have. The institutions of justice should acknowledge the limitations of the people who administer it. The example of punitive damages is extreme; professional judgments are rarely expressed on scales that are so hopelessly ambiguous. Nonetheless, ambiguous scales are common, which means that the punitive-damages study holds two general lessons, applicable in business, education, sports, government, and elsewhere. First, the choice of a scale can make a large difference in the amount of noise in judgments, because ambiguous scales are noisy. Second, replacing absolute judgments with relative ones, when feasible, is likely to reduce noise. Speaking of Scales ([Location 2813](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2813))
    - Tags: [[pink]] 
- “There is a lot of noise in our judgments. Could this be because we understand the scale differently?” “Can we agree on an anchor case that will serve as a reference point on the scale?” “To reduce noise, maybe we should replace our judgments with a ranking?” ([Location 2825](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2825))
    - Tags: [[pink]] 
- When the evidence available paints a coherent picture, our fast, System 1 thinking has no difficulty making sense of it. Simple judgment problems like these are easily resolved, and most people agree on their solution. ([Location 2851](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2851))
    - Tags: [[pink]] 
- What makes this problem difficult is the presence of multiple, conflicting cues. There are indications of ability and motivation but also of character weaknesses and mediocre achievement. The story seems to be all over the place. It does not easily make sense, because the elements cannot be fit in a coherent interpretation. Of course, the incoherence does not make the story unrealistic or even implausible. Life is often more complex than the stories we like to tell about it. Multiple, conflicting cues create the ambiguity that defines difficult judgment problems. Ambiguity also explains why complex problems are noisier than simple ones. The rule is simple: if there is more than one way to see anything, people will vary in how they see it. People can pick different ([Location 2852](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2852))
    - Tags: [[pink]] 
- pieces of evidence to form the core of their narrative, so there are many possible conclusions. ([Location 2858](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2858))
    - Tags: [[pink]] 
- When do you feel confident in a judgment? Two conditions must be satisfied: the story you believe must be comprehensively coherent, and there must be no attractive alternatives. Comprehensive coherence is achieved when all the details of the chosen interpretation fit with the story and reinforce each other. Of course, you can also achieve coherence, albeit less elegantly, by ignoring or explaining away whatever does not fit. It is the same with alternative interpretations. The true expert who has “solved” a judgment problem knows not only why her explanatory story is correct; she is equally fluent in explaining why other stories are wrong. Here again, a person can gain confidence of equal strength but poorer quality by failing to consider alternatives or by actively suppressing them. ([Location 2860](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2860))
    - Tags: [[pink]] 
- The main implication of this view of confidence is that subjective confidence in one’s judgment by no means guarantees accuracy. Moreover, the suppression of alternative interpretations—a well-documented process in perception—could induce what we have called the illusion of agreement (see chapter 2). If people cannot imagine possible alternatives to their conclusions, they will naturally assume that other observers must reach the same conclusion, too. Of course, few of us have the good fortune of being highly confident about all our judgments, and all of us have had the experience of uncertainty, perhaps as recently as your reading about Julie 2.0. We are not all highly confident all the time, but most of the time we are more confident than we should be. ([Location 2866](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2866))
    - Tags: [[pink]] 
- Pattern errors arise from a combination of transient and permanent factors. The transient factors include those we have described as sources of occasion noise, such as a judge’s good mood at the relevant moment or some unfortunate recent occurrence that is currently on the judge’s mind. Other factors are more permanent—for example, an employer’s unusual enthusiasm for people who attended certain universities or a doctor’s unusual propensity to recommend hospitalization for people with pneumonia. We can write a simple equation that describes an error in a single judgment: Pattern Error = Stable Pattern Error + Transient (Occasion) Error ([Location 2877](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2877))
    - Tags: [[pink]] 
- Because stable pattern error and transient (occasion) error are independent and uncorrelated, we can extend the equation above to analyze their variances: (Pattern Noise)2 = (Stable Pattern Noise)2 + (Occasion Noise) ([Location 2882](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2882))
    - Tags: [[pink]] 
- Individual differences in the quality of judgments are another source of pattern noise. Imagine a single forecaster with crystal-ball powers that no one knows about (including herself). Her accuracy would make her deviate in many cases from the average forecast. In the absence of outcome data, these deviations would be regarded as pattern errors. When judgments are unverifiable, superior accuracy will look like pattern noise. ([Location 2899](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2899))
    - Tags: [[pink]] 
- As this example illustrates, there is no sharp discontinuity between stable pattern noise and the unstable variant that we call occasion noise. The main difference is whether a person’s unique sensitivity to some aspects of the case is itself permanent or transient. When the triggers of pattern noise are rooted in our personal experiences and values, we can expect the pattern to be stable, a reflection of our uniqueness. ([Location 2924](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2924))
    - Tags: [[pink]] 
- Common sense suggests that while behavior may be driven by personality, it is also strongly affected by situations. In some situations no one is aggressive, and in other situations everyone is. When consoling a bereaved friend, neither Andrew nor Brad will act aggressively; at a football game, however, both will display some aggression. In short—and unsurprisingly—behaviors are a function of personalities and of situations. What makes people unique and endlessly interesting is that this joining of personality and situation is not a mechanical, additive function. For example, the situations that trigger more or less aggression are not the same for all people. Even if Andrew and Brad are equally aggressive on average, they do not necessarily display equal aggressiveness in every context. Perhaps Andrew is aggressive toward his peers but docile with superiors, whereas Brad’s level of aggressiveness is not sensitive to hierarchical level. Perhaps Brad is particularly prone to aggression when criticized and unusually restrained when physically threatened. These signature patterns of response to situations are likely to be fairly stable over time. They constitute much of what we consider someone’s personality, although they do not lend themselves to a description by a broad trait. Andrew and Brad may share the same score on a test of aggression, but they are unique in their pattern of response to aggression triggers and contexts. Two people who share a trait level—if, for example, they are equally obstinate or equally generous—should be described by two distributions of behaviors that have the same average but not necessarily the same pattern of responses to different situations. You can now see the parallel between this discussion of personality and the model of judgment we have presented. Level differences between judges correspond to the differences among scores on personality traits, which represent an average of behaviors in multiple situations. Cases are analogous to situations. A person’s judgment of a particular problem is only moderately ([Location 2939](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2939))
    - Tags: [[pink]] 
- predictable from that person’s average level, just as specific behaviors are only moderately predictable from personality traits. The ranking of individuals by their judgment varies substantially from one case to another because people differ in their reaction to the features and combinations of features that they find in each case. The signature of an individual who makes judgments and decisions is a unique pattern of sensitivity to features and a correspondingly unique pattern in the judgment of cases. The uniqueness of personality is normally a cause for celebration, but this book is concerned with professional judgments, where variation is problematic and noise is error. The point of the analogy is that pattern noise in judgment is not random—even if we have little hope of explaining it and even if the individuals who make distinctive judgments could not explain them. ([Location 2953](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2953))
    - Tags: [[pink]] 
- Speaking of Pattern Noise “You seem confident in your conclusion, but this is not an easy problem: there are cues pointing… ([Location 2960](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2960))
    - Tags: [[pink]] 
- overlooked alternative interpretations of the evidence?” “You and I have interviewed the same candidate, and usually we are equally demanding interviewers. Yet we have completely different judgments. Where does this pattern noise come from?” “The uniqueness of people’s personalities is what makes them capable of innovation and creativity, and simply interesting and… ([Location 2961](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2961))
    - Tags: [[pink]] 
- We hope that by now, you agree that wherever there is judgment, there is noise. We also hope that for you, there is no longer more of it than you think. This mantra about noise motivated us when we started our project, but our thinking about the topic has evolved over the years of working on it. We now review the main lessons we have learned about the components of noise, about their respective importance in the general picture of noise, and about the place of noise in the study of judgment. The Components of Noise Figure 16 offers a combined… ([Location 2968](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2968))
    - Tags: [[pink]] 
- error into bias and system noise, • system noise into level noise and pattern noise, • pattern noise into stable… ([Location 2975](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=2975))
    - Tags: [[pink]] 
- We do, however, feel a need to explain abnormal outcomes: the bad ones and, occasionally, the surprisingly good ones—such as the shocking business gamble that pays off. Explanations that appeal to error or to special flair are far more popular than they deserve to be, because important gambles of the past easily become acts of genius or folly when their outcome is known. A well-documented psychological bias called the fundamental attribution error is a strong tendency to assign blame or credit to agents for actions and outcomes that are better explained by luck or by objective circumstances. Another bias, hindsight, distorts judgments so that outcomes that could not have been anticipated appear easily foreseeable in retrospect. Explanations for errors of judgment are not hard to come by; finding reasons for judgments is, if anything, easier than finding causes for events. We can always invoke the motives of the people making the judgments. If that is not sufficient, we can blame their incompetence. And another explanation for poor judgments has become common in recent decades: psychological bias. A substantial body of research in psychology and behavioral economics has documented a long list of psychological biases: the planning fallacy, overconfidence, loss aversion, the endowment effect, the status quo bias, excessive discounting of the future (“present bias”), and many others—including, of course, biases for or against various categories of people. Much is known about the conditions under which each of these biases is likely to influence judgments and decisions, and a fair amount is known that would allow an observer of decision making to recognize biased thinking in real time. A psychological bias is a legitimate causal explanation of a judgment error if the bias could have been predicted in advance or detected in real time. A psychological bias that is identified only after the fact ([Location 3076](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3076))
    - Tags: [[pink]] 
- can still provide a useful, if tentative, explanation if it also offers a prediction about the future. For example, the surprising rejection of a strong woman candidate for a position may suggest a more general hypothesis of gender bias that future appointments by the same committee will confirm or refute. Consider, in contrast, a causal explanation that applies only to one event: “In that case they failed, so they must have been overconfident.” The statement is completely vacuous, but it provides an illusion of understanding that can be quite satisfying. Business school professor Phil Rosenzweig has convincingly argued that empty explanations in terms of biases are common in discussions of business outcomes. Their popularity attests to the prevalent need for causal stories that make sense of experience. ([Location 3089](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3089))
    - Tags: [[pink]] 
- The result is a marked imbalance in how we view bias and noise as sources of error. If you have been exposed to any introductory psychology, you probably remember the illustrations in which a salient and richly detailed figure stands out from an indistinct background. Our attention is firmly fixed on the figure even when it is small against the background. The figure/ground demonstrations are an apt metaphor for our intuitions about bias and noise: bias is a compelling figure, while noise is the background to which we pay no attention. That is how we remain largely unaware of a large flaw in our judgment. ([Location 3104](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3104))
    - Tags: [[pink]] 
- Speaking of the Sources of Noise “We easily see differences in the average level of judgments, but how large is the pattern noise we do not see?” “You say this judgment was caused by biases, but would you say the same thing if the outcome had been different? And can you tell if there was noise?” “We are rightly focused on reducing biases. Let’s also worry about reducing noise.” ([Location 3108](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3108))
    - Tags: [[pink]] 
- How can an organization improve the judgments its ([Location 3115](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3115))
    - Tags: [[pink]] 
- professionals make? In particular, how can an organization reduce judgment noise? If you were in charge of answering these questions, how would you go about it? ([Location 3115](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3115))
    - Tags: [[pink]] 
- Three things matter. Judgments are both less noisy and less biased when those who make them are well trained, are more intelligent, and have the right cognitive style. In other words: good judgments depend on what you know, how well you think, and how you think. Good judges tend to be experienced and smart, but they also tend to be actively open-minded and willing to learn from new information. ([Location 3173](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3173))
    - Tags: [[pink]] 
- The confidence we have in these experts’ judgment is entirely based on the respect they enjoy from their peers. We call them respect-experts. ([Location 3186](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3186))
    - Tags: [[pink]] 
- Another characteristic of respect-experts is their ([Location 3214](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3214))
    - Tags: [[pink]] 
- ability to make and explain their judgments with confidence. We tend to put more trust in people who trust themselves than we do in those who show their doubts. The confidence heuristic points to the fact that in a group, confident people have more weight than others, even if they have no reason to be confident. Respect-experts excel at constructing coherent stories. Their experience enables them to recognize patterns, to reason by analogy with previous cases, and to form and confirm hypotheses quickly. They easily fit the facts they see into a coherent story that inspires confidence. ([Location 3214](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3214))
    - Tags: [[pink]] 
- There is good reason to believe that general intelligence is likely to be associated with better judgment. Intelligence is correlated with good performance in virtually all domains. All other things being equal, it is associated not only with higher academic achievement but also with higher job performance. ([Location 3220](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3220))
    - Tags: [[pink]] 
- Many debates and misunderstandings arise in ([Location 3223](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3223))
    - Tags: [[pink]] 
- discussions of measures of intelligence or of general mental ability (GMA, the term now used in preference to intelligence quotient, or IQ). There are lingering misconceptions about the innate nature of intelligence; in fact, tests measure developed abilities, which are partly a function of heritable traits and partly influenced by the environment, including educational opportunities. Many people also have concerns about the adverse impact of GMA-based selection on identifiable social groups and the legitimacy of using GMA tests for selection purposes. ([Location 3223](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3223))
    - Tags: [[pink]] 
- Yet for all its crudeness and limitations, GMA, as measured by standardized tests containing questions on verbal, quantitative, and spatial problems, remains by far the best single predictor of important outcomes. As the previously mentioned review adds, the predictive power of GMA is “larger than most found in psychological research.” The strength of the association between general mental ability and job success increases, quite logically, with the complexity of the job in question: intelligence matters more for rocket scientists than it does for those with simpler tasks. For jobs of high complexity, the correlations that can be observed between standardized test scores and job performance are in the .50 range (PC = 67%). As we have noted, a correlation of .50 indicates a very strong predictive value by social-science standards. ([Location 3235](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3235))
    - Tags: [[pink]] 
- This belief, although widespread, is incorrect. No doubt the range of GMAs found in a given occupation is wider at the bottom of the range of occupations than at the top: there are high-GMA individuals in lower-level occupations but almost no people with below-average GMA among lawyers, chemists, or engineers. From that perspective, therefore, high mental ability is apparently a necessary condition for gaining access to high-status professions. However, this measure fails to capture differences in achievement within these groups. Even among the top 1% of people as measured by cognitive ability (evaluated at age thirteen), exceptional outcomes are strongly correlated with GMA. Compared with those who are in the bottom quartile of this top 1%, those who are in the top quartile are two to three times more likely to earn a doctoral-level degree, publish a book, or be granted a patent. In other words, not only does the difference in GMA matter between the 99th percentile and the 80th or 50th, but it still matters—a lot!—between the 99.88th percentile and the 99.13th. ([Location 3245](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3245))
    - Tags: [[pink]] 
- But this line of reasoning has an important limitation. Since you cannot give standardized tests to everyone, you will have to guess who the higher-GMA ([Location 3262](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3262))
    - Tags: [[pink]] 
- people are. And high GMA improves performance on many fronts, including the ability to convince others that you’re right. People of high mental ability are more likely than others to make better judgments and to be true experts, but they are also more likely to impress their peers, earn others’ trust, and become respect-experts in the absence of any reality feedback. Medieval astrologers must have been among the highest-GMA people of their time. It can be sensible to place your trust in people who look and sound intelligent and who can articulate a compelling rationale for their judgments, but this strategy is insufficient and may even backfire. Are there, then, other ways to identify real experts? Do people with the best judgment have other recognizable traits? ([Location 3263](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3263))
    - Tags: [[pink]] 
- Regardless of mental ability, people differ in their cognitive style, or their approach to judgment tasks. Many instruments have been developed to capture cognitive styles. Most of these measures correlate with GMA (and with one another), but they measure different things. One such measure is the… ([Location 3269](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3269))
    - Tags: [[pink]] 
- about the ball and the bat: “A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?” Other questions that have been proposed to measure cognitive reflection include this one: “If you’re running a race and you pass the person in second place, what place are you in?” CRT questions attempt to measure how likely people are to override the first (and wrong) answer that comes to mind (“ten cents” for the ball-and-bat question, and “first” for the race example). Lower CRT scores are associated with many real-world judgments and beliefs, including belief in ghosts, astrology, and extrasensory perception. The scores predict whether people will fall for blatantly inaccurate “fake news.” They are even associated with how much people will use their smartphones. The CRT is seen by many as one instrument to measure a broader concept: the propensity to use reflective versus impulsive thought processes. Simply put, some people like to engage in careful thought, whereas others, faced with the same problem, tend to trust their first impulses. In our terminology, the… ([Location 3272](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3272))
    - Tags: [[pink]] 
- for instance, asks people how much they like to think hard about problems. To score high on the scale, you would have to agree that “I tend to set goals that can be accomplished only by expending considerable mental effort” and disagree with “Thinking is not my idea of fun.” People with a high need for cognition tend to be less susceptible to known cognitive biases. Some more bizarre associations have been reported, too: if you avoid movie reviews with a spoiler alert,… ([Location 3282](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3282))
    - Tags: [[pink]] 
- In other words, while the cognitive reflection and need for cognition scores measure the propensity to engage in slow and careful thinking, actively open-minded thinking goes beyond that. It is the humility of those who are constantly aware that their judgment is a work in progress and who yearn to be corrected. We will see in chapter 21 that this thinking style characterizes the very best forecasters, who constantly change their minds and revise their beliefs in response to new information. Interestingly, there is some evidence that actively open-minded thinking is a teachable skill. ([Location 3306](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3306))
    - Tags: [[pink]] 
- But the evidence suggests that if the goal is to reduce error, it is better for leaders (and others) to remain open to counterarguments and to know that they might be wrong. If they end up being decisive, it is at the end of a process, not at the start. ([Location 3321](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3321))
    - Tags: [[pink]] 
- Speaking of Better Judges “You are an expert. But are your judgments verifiable, or are you a respect-expert?” “We have to choose between two opinions, and we know nothing about these individuals’ expertise and track record. Let’s follow the advice of the more intelligent one.” “Intelligence is only part of the story, however. How people think is also important. Perhaps we should pick the most thoughtful, open-minded person, rather than the smartest one.” ([Location 3323](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3323))
    - Tags: [[pink]] 
- The challenge of learning to overcome a bias is to recognize that a new problem is similar to one we have seen elsewhere and that a bias that we have seen in one place is likely to ([Location 3365](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3365))
    - Tags: [[pink]] 
- materialize in other places. ([Location 3366](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3366))
    - Tags: [[pink]] 
- We suggest undertaking this search for biases neither before nor after the decision is made, but in real time. Of course, people are rarely aware of their own biases when they are being misled by them. This lack of awareness is itself a known bias, the bias blind spot. People often recognize biases more easily in others than they do in themselves. We suggest that observers can be trained to spot, in real time, the diagnostic signs that one or several familiar biases are affecting someone else’s decisions or recommendations. ([Location 3394](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3394))
    - Tags: [[pink]] 
- A decision observer is not an easy role to play, and no doubt, in some organizations it is not realistic. Detecting biases is useless if the ultimate decision makers are not committed to fighting them. Indeed, the decision makers must be the ones who initiate the process of decision observation and who support the role of the decision observer. We ([Location 3402](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3402))
    - Tags: [[pink]] 
- certainly do not recommend that you make yourself a self-appointed decision observer. You will neither win friends nor influence people. ([Location 3404](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3404))
    - Tags: [[pink]] 
- Bias is error we can often see and even explain. It is directional: that is why a nudge can limit the detrimental effects of a bias, or why an effort to boost judgment can combat specific biases. It is also often visible: that is why an observer can hope to diagnose biases in real time as a decision is being made. Noise, on the other hand, is unpredictable error that we cannot easily see or explain. That is why we so often neglect it—even when it causes grave damage. For this reason, strategies for noise reduction are to debiasing what preventive hygiene measures are to medical treatment: the goal is to prevent an unspecified range of potential errors before they occur. We call this approach to noise reduction decision hygiene. When you wash your hands, you may not know precisely which germ you are avoiding—you just know that handwashing is good prevention for a variety of germs (especially but not only during a pandemic). Similarly, following the principles of decision hygiene means that you adopt techniques that reduce noise without ever knowing which underlying errors you are helping to avoid. The analogy with handwashing is intentional. Hygiene measures can be tedious. Their benefits are not directly visible; you might never know what problem they prevented from occurring. Conversely, when problems do arise, they may not be traceable to a specific breakdown in hygiene observance. For these reasons, handwashing compliance is difficult to enforce, even among health-care professionals, who are well aware of its importance. Just like handwashing and other forms of prevention, decision hygiene is invaluable ([Location 3432](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3432))
    - Tags: [[pink]] 
- but thankless. Correcting a well-identified bias may at least give you a tangible sense of achieving something. But the procedures that reduce noise will not. They will, statistically, prevent many errors. Yet you will never know which errors. Noise is an invisible enemy, and preventing the assault of an invisible enemy can yield only an invisible victory. Given how much damage noise can cause, that invisible victory is nonetheless worth the battle. ([Location 3444](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3444))
    - Tags: [[pink]] 
- Speaking of Debiasing and Decision Hygiene “Do you know what specific bias you’re fighting and in what direction it affects the outcome? If not, there are probably several biases at work, and it is hard to predict ([Location 3449](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3449))
    - Tags: [[pink]] 
- which one will dominate.” “Before we start discussing this decision, let’s designate a decision observer.” “We have kept good decision hygiene in this decision process; chances are the decision is as good as it can be.” ([Location 3451](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3451))
    - Tags: [[pink]] 
- Mayfield was released after two weeks. Eventually, the US government apologized to him, paid him a $2 million settlement, and ordered an extensive investigation into the causes of the mistake. Its key finding: “The error was a human error and not a methodology or technology failure.” Fortunately, such human errors are rare. They are nonetheless instructive. How could the best fingerprint experts in the United States mistakenly identify a fingerprint as belonging to a man who had never come close to the crime scene? To find out, we first need to understand how fingerprint examination works and how it relates to other examples of professional judgment. We will learn that forensic fingerprinting, which we tend to think of as an exact science, is in fact subject to the psychological biases of examiners. These biases can create more noise, and thus more error, than we would imagine. And we will see how the forensic science community is taking steps to tackle this problem by implementing a ([Location 3465](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3465))
    - Tags: [[pink]] 
- decision hygiene strategy that can apply to all environments: a tight control over the flow of information used to make judgments. ([Location 3472](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3472))
    - Tags: [[pink]] 
- Fingerprints Fingermarks are the impressions left by the friction ridges of our fingers on the surfaces we touch. Although there are examples of fingerprints being used as apparent identification marks in ancient times, modern fingerprinting dates back to the late nineteenth century, when Henry Faulds, a Scottish physician, published the first scientific paper suggesting the use of fingerprints as an identification technique. In subsequent decades, fingerprints gained traction as identification marks in criminal records, gradually replacing the anthropometric measurement techniques developed by Alphonse Bertillon, a French police officer. Bertillon himself codified, in 1912, a formal system for the comparison of fingerprints. Sir Francis Galton, whom we previously encountered as the discoverer of the wisdom of crowds, had developed a similar system in England. (Still, it… ([Location 3473](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3473))
    - Tags: [[pink]] 
- prejudice, contributed decisive—and flawed—expert testimony during the 1894 and 1899 trials of Alfred Dreyfus.) Police officers soon discovered that fingerprints could do more than serve as identification marks for repeat offenders. In 1892, Juan Vucetich, a police officer in Argentina, was the first to compare a latent fingerprint left at a crime scene with a suspect’s thumb. Since then, the practice of collecting latent prints (those left by their owner at the scene of a crime) and comparing them with exemplar prints (those collected in controlled conditions from known individuals) has been the most decisive application of fingerprinting and has provided the most widely used form of forensic evidence. If you have ever come across an electronic fingerprint reader (like those used by immigration services in many countries), you probably think of fingerprint comparison as a straightforward, mechanical, and easily automated task. But comparing a latent print collected from a crime scene with an exemplar print is a much more delicate exercise than matching two clean prints. When you press your fingers… ([Location 3481](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3481))
    - Tags: [[pink]] 
- collected in a controlled and dedicated environment. Latent prints often overlap with other prints, either by the same person or by someone else, and include dirt and other artifacts present on the surface. Deciding whether they match a suspect’s exemplar prints requires expert judgment. It is the job of human fingerprint examiners. When provided with a latent print, examiners routinely follow a process called ACE-V, which stands for analysis, comparison, evaluation, and verification. First, they must analyze the latent print to determine whether it is of sufficient value for comparison. If it is, they compare it to an exemplar print. The comparison leads to an evaluation, which can produce an identification (the prints originated from the same person), an exclusion (the prints do not originate from the same person), or an inconclusive decision. An identification decision triggers the fourth step: verification by another examiner. For decades, the reliability of this procedure remained unquestioned. Although eyewitness testimonies have been shown to be dangerously unreliable and even confessions can be… ([Location 3491](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3491))
    - Tags: [[pink]] 
- offer an infallible means of personal identification.” In the very rare cases when errors did happen, they were blamed on incompetence or fraud. Fingerprint evidence remained unchallenged for so long in part because of the difficulty in proving it wrong. The true value of a set of fingerprints, that is, the ground truth of who actually committed the crime, is often unknown. For Mayfield and a handful of similar cases, the mistake was especially egregious. But in general, if a suspect disputes the examiner’s conclusions, the fingerprint evidence will, of course, be considered more reliable. We have noted that not knowing the true value is neither unusual nor an impediment to measuring noise. How much noise is there in fingerprint analysis? Or more precisely, given that fingerprint examiners, unlike sentencing judges or underwriters, do not produce a number but make a categorical judgment, how often do they disagree, and why? This question is what Itiel Dror, a… ([Location 3501](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3501))
    - Tags: [[pink]] 
- It may seem odd for a cognitive scientist—a psychologist—to challenge fingerprint examiners. After all, as you may have seen on TV shows like CSI: Crime Scene Investigation and subsequent series of the CSI franchise, these are latex-glove-wearing, microscope-wielding hard-science types. But Dror realized that examining fingerprints was clearly a matter of judgment. And as a cognitive neuroscientist, he reasoned that wherever there is judgment, there must be noise. To test this hypothesis, Dror focused first on occasion noise: the variability between the judgments of the same experts looking at the same evidence twice. As Dror puts it, “If experts are not reliable in the sense that they are not consistent with themselves, then the basis of their judgments and professionalism is in question.” Fingerprints provide a perfect test bed for an audit of occasion noise because unlike the cases that a physician or a judge encounters, pairs of prints are not easily memorable. Of course, a suitable interval of time must be allowed to pass to ensure that examiners do not remember the prints. (In Dror’s studies, some brave, open-minded experts… ([Location 3510](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3510))
    - Tags: [[pink]] 
- the examiners’ judgments change from one test to the next, we are in the… ([Location 3521](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3521))
    - Tags: [[pink]] 
- The Forensic Confirmation Bias In two of his original studies, Dror added an important twist. When seeing the prints for the second time, some of the examiners were exposed to additional biasing information about the case. For instance, fingerprint examiners who had earlier found the prints to be a match were told, this time, that “the suspect has an alibi” or that “firearms evidence suggests it’s not him.” Others, who had first concluded that a suspect was innocent or that the prints were inconclusive, were told the second time that “the detective believes the suspect is guilty,” “eyewitnesses identified him,” or “he confessed to the crime.” Dror called this experiment a test of the experts’ “biasability,” because the contextual information supplied activated a psychological bias (a confirmation bias) in a given direction. Indeed, the examiners turned out to be susceptible to bias. When the same… ([Location 3522](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3522))
    - Tags: [[pink]] 
- strong contextual information that suggested an exclusion. In the second study, six experts reviewed four pairs of prints; biasing information led to changes in four of the twenty-four decisions. To be sure, most of their decisions did not change, but for these kinds of decisions, a shift of one in six can be counted as large. These findings have since been replicated by other researchers. Predictably, the examiners were more likely to change their minds when the decision was a difficult one to start with, when the biasing information was strong, and when the change was from a conclusive to an inconclusive decision. It is, nonetheless, troubling that “expert fingerprint examiners made decisions on the basis of the context, rather than on the basis of the actual information contained in the print.” The effect of biasing information is not restricted to the examiner’s conclusion (identification, inconclusive, or exclusion). Biasing information actually changes what the examiner perceives, in addition to how that perception is interpreted. In a separate study, Dror and colleagues showed that examiners who have been placed in a biased… ([Location 3530](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3530))
    - Tags: [[pink]] 
- A later, independent study confirmed this conclusion and added that “how [it] occurs is not obvious.” Dror coined a term for the impact of biasing information: the forensic confirmation bias. This bias has since been documented with other forensic techniques, including blood pattern analysis, arson investigation, the analysis of skeletal remains, and forensic pathology. Even DNA analysis—widely regarded as the new gold standard in forensic science—can be susceptible to confirmation bias, at least when experts must assess complex DNA mixtures. The susceptibility of forensic experts to confirmation bias is not just a theoretical concern because, in reality, no systematic precautions are in place to make sure that forensic experts are not exposed to biasing information. Examiners often receive such information in the transmittal letters that accompany the evidence submitted to them. Examiners are also often in direct communication with police, prosecutors, and other examiners. Confirmation bias raises another problem. An important safeguard against errors, built into the ACE-V procedure, is the independent… ([Location 3540](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3540))
    - Tags: [[pink]] 
- step therefore does not provide the benefit normally expected from the aggregation of independent judgments, because verifications are not, in fact, independent. A cascade of confirmation biases seems to have been at work in the Mayfield case, in which not two but three FBI experts concurred on the erroneous identification. As the later investigation of the error noted, the first examiner appears to have been impressed by “the power of the correlation” from the automated system searching the databases of fingerprints for a possible match. Although he was, apparently, not exposed to Mayfield’s biographical details, the results provided by the computerized system performing the initial search, “coupled with the inherent pressure of working an extremely high-profile case,” were enough to produce the initial confirmation bias. Once the first examiner made an erroneous identification, the report continues, “the subsequent examinations were tainted.” As the first examiner was a highly respected supervisor, “it became increasingly difficult for others in the agency to disagree.” The initial error… ([Location 3550](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3550))
    - Tags: [[pink]] 
- Its central finding was that very few erroneous identifications occurred: the false-positive rate was about one in six hundred. ([Location 3588](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3588))
    - Tags: [[pink]] 
- For instance, FBI experts observe, “in most casework, an exclusion has the same operational implications as an inconclusive.” In other words, the fact that a fingerprint is found on the murder weapon is sufficient to convict, but the absence of that print is not sufficient to exonerate a suspect. ([Location 3597](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3597))
    - Tags: [[pink]] 
- Examiners are trained to consider erroneous identification as the deadly sin to be avoided at all costs. To their credit, they act in accordance with this principle. We can only hope that their level of care keeps erroneous identifications, like those in the Mayfield case and a handful of other high-profile cases, extremely rare. ([Location 3604](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3604))
    - Tags: [[pink]] 
- Listening to Noise To observe that there is noise in forensic science should not be seen as a criticism of forensic scientists. It is merely a consequence of the observation we have made repeatedly: Wherever there is judgment, there is noise, and more of it than you think. A task like the ([Location 3607](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3607))
    - Tags: [[pink]] 
- analysis of fingerprints seems objective, so much so that many of us would not spontaneously regard it as a form of judgment. Yet it leaves room for inconsistency, disagreement, and, occasionally, error. However low the error rate of fingerprint identification may be, it is not zero, and as PCAST noted, juries should be made aware of that. ([Location 3609](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3609))
    - Tags: [[pink]] 
- Even when they are aware of the risk of bias, forensic scientists are not immune to the bias blind spot: the tendency to acknowledge the presence of bias in others, but not in oneself. In a survey of four hundred professional forensic scientists in twenty-one countries, 71% agreed that “cognitive bias is a cause for concern in the forensic sciences as a whole,” but only 26% thought that their “own judgments are influenced by cognitive bias.” In other words, about half of these forensic professionals believe that their colleagues’ judgments are noisy but that their own are not. Noise can be an invisible problem, even to people whose job is to see the invisible. ([Location 3620](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3620))
    - Tags: [[pink]] 
- Sequencing Information Thanks to the persistence of Dror and his colleagues, attitudes are slowly changing and a growing number of forensic laboratories have begun taking new measures to reduce error in their analyses. For example, the PCAST report commended the FBI laboratory for redesigning its procedures to minimize the risk of confirmation bias. ([Location 3625](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3625))
    - Tags: [[pink]] 
- The necessary methodological steps are relatively simple. They illustrate a… ([Location 3628](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3628))
    - Tags: [[pink]] 
- that has applicability in many domains: sequencing information to limit the formation of premature intuitions. In any judgment, some information is relevant, and some is not. More information is not always better, especially if it has the potential to bias judgments by leading the judge to form a premature intuition. In that spirit, the new procedures deployed in forensic laboratories aim to protect the independence of the examiners’ judgments by giving the examiners only the information they need, when they need it. In other words, the laboratory keeps them as much in the dark about the case as possible and reveals information only gradually. To do that, the approach Dror and colleagues codified is called linear sequential unmasking. Dror has another recommendation that illustrates the same decision hygiene strategy: examiners should document their judgments at each step. They should document their analysis of a latent fingerprint before they look at exemplar fingerprints to decide whether they are a match. This sequence of steps helps experts avoid the risk that they see only what they are looking for. And they should record… ([Location 3629](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3629))
    - Tags: [[pink]] 
- early intuition biases the entire process. The same logic inspires a third recommendation, which is an important part of decision hygiene. When a different examiner is called on to verify the identification made by the first person, the second person should not be aware of the first judgment. The presence of noise in forensic science is, of course, of concern because of its potential life-or-death consequences. But it is also revealing. That we remained for so long entirely unaware of the possibility of error in fingerprint identification shows how our confidence in expert human judgment can sometimes be exaggerated and how a noise audit can reveal an unexpected amount of noise. The ability to mitigate these shortcomings through relatively simple process changes should be encouraging to all those who care about improving the quality of decisions. The main decision hygiene strategy this case illustrates—sequencing information—has broad applicability as a safeguard against occasion noise. As we have noted, occasion noise is driven by countless triggers, including mood and even outside temperature. You cannot hope to control all… ([Location 3639](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3639))
    - Tags: [[pink]] 
- in time, when the triggers of occasion noise are likely to be different. Less obvious is the possibility that your judgment can be altered by another trigger of occasion noise: information—even when it is accurate information. As in the example of the fingerprint examiners, as soon as you know what others think, confirmation bias can lead you to form an overall impression too early and to ignore contradictory information. The titles of two Hitchcock… ([Location 3649](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3649))
    - Tags: [[pink]] 
- Speaking of Sequencing Information “Wherever there is judgment, there is noise—and that includes reading fingerprints.” “We have more information about this case, but let’s not tell the experts everything we know before they make their judgment, so as not to bias them. In fact, let’s tell them only what they absolutely need to know.” “The second opinion is not independent if the person giving it knows what the first opinion was. And the… ([Location 3653](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3653))
    - Tags: [[pink]] 
- Analysts of forecasting—of when it goes wrong and why—make a sharp distinction between bias and noise (also called inconsistency or unreliability). Everyone agrees that in some contexts, forecasters are ([Location 3666](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3666))
    - Tags: [[pink]] 
- biased. For example, official agencies show unrealistic optimism in their budget forecasts. On average, they project unrealistically high economic growth and unrealistically low deficits. For practical purposes, it matters little whether their unrealistic optimism is a product of a cognitive bias or political considerations. In addition, forecasters tend to be overconfident: if asked to formulate their forecasts as confidence intervals rather than as point estimates, they tend to pick narrower intervals than they should. ([Location 3667](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3667))
    - Tags: [[pink]] 
- Forecasters are also noisy. A reference text, J. Scott Armstrong’s Principles of Forecasting, points out that even among experts, “unreliability is a source of error in judgmental forecasting.” In fact noise is a major source of error. Occasion noise is common; forecasters do not always agree with themselves. Between-person noise is also pervasive; forecasters disagree with one another, even if they are specialists. ([Location 3675](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3675))
    - Tags: [[pink]] 
- The research also offers suggestions for reducing noise and bias. We will not review them exhaustively here, but we will focus on two noise-reduction strategies that have broad applicability. One is an application of the principle we mentioned in chapter 18: selecting better judges produces better judgments. The other is one of the most universally applicable decision hygiene strategies: aggregating multiple independent estimates. The easiest way to aggregate several forecasts is to average them. Averaging is mathematically guaranteed to reduce noise: specifically, it divides it by the square root of the number of judgments averaged. This means that if you average one hundred judgments, you will reduce noise by 90%, and if you average four hundred judgments, you will reduce it by 95%—essentially eliminating it. This statistical law is the engine of the wisdom-of-crowds approach, discussed in chapter 7. ([Location 3682](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3682))
    - Tags: [[pink]] 
- One method to produce aggregate forecasts is to use prediction markets, in which individuals bet on likely outcomes and are thus incentivized to make the right forecasts. Much of the time, prediction markets have been found to do very well, in the sense that if the prediction market price suggests that events are, say, 70% likely to happen, they happen about 70% of the time. Many companies in various industries have used prediction markets to aggregate diverse views. Another formal process for aggregating diverse views is known as the Delphi method. In its classic form, this method involves multiple rounds during which the participants submit estimates (or votes) to a moderator and remain anonymous to one another. At each new round, the participants provide reasons for their estimates and respond to the reasons given by others, still anonymously. The process encourages estimates to converge (and sometimes forces them to do so by requiring new judgments to fall within a specific range of the distribution of previous-round judgments). The method benefits both from aggregation and social learning. The Delphi method has worked well in many situations, but it can be challenging to implement. A simpler version, mini-Delphi, can be deployed within a single meeting. Also called estimate-talk-estimate, it requires participants first to produce separate (and silent) estimates, then to explain and justify them, and finally to make a new estimate in response to the estimates and explanations of others. The consensus judgment is the average of the individual estimates obtained in that second round. ([Location 3697](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3697))
    - Tags: [[pink]] 
- To understand the central findings, we need to explain some key aspects of the method adopted by Tetlock and his team to evaluate forecasters. First, they used a large number of forecasts, not just one or a few, where luck might be responsible for success or failure. If you predict that your favorite sports team will win ([Location 3723](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3723))
    - Tags: [[pink]] 
- its next game, and it does, you are not necessarily a good forecaster. Maybe you always predict that your favorite team will win: if that’s your strategy, and if they win only half the time, your forecasting ability is not especially impressive. To reduce the role of luck, the researchers examined how participants did, on average, across numerous forecasts. Second, the researchers asked participants to make their forecasts in terms of probabilities that an event would happen, rather than a binary “it will happen” or “it will not happen.” To many people, forecasting means the latter—taking a stand one way or the other. However, given our objective ignorance of future events, it is much better to formulate probabilistic forecasts. If someone said in 2016, “Hillary Clinton is 70% likely to be elected president,” he is not necessarily a bad forecaster. Things that are correctly said to be 70% likely will not happen 30% of the time. To know whether forecasters are good, we should ask whether their probability estimates map onto reality. Suppose that a particular forecaster named Margaret says that 500 different events are 60% likely. If 300 of them actually happen, then we can conclude that Margaret’s confidence is well calibrated. Good calibration is one requirement for good forecasting. Third, as an added refinement, Tetlock and colleagues did not just ask their forecasters to make ([Location 3726](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3726))
    - Tags: [[pink]] 
- one probability estimate about whether an event would happen in, say, twelve months. They gave the participants the opportunity to revise their forecasts continuously in light of new information. Suppose that you had estimated, back in 2016, that the United Kingdom had only a 30% chance of leaving the European Union before the end of 2019. As new polls came out, suggesting that the “Leave” vote was gaining ground, you probably would have revised your forecast upward. When the result of the referendum was known, it was still uncertain whether the United Kingdom would leave the union within that time frame, but it certainly looked a lot more probable. (Brexit technically happened in 2020.) With each new piece of information, Tetlock and his colleagues allowed the forecasters to update their forecasts. For scoring purposes, each one of these updates is treated as a new forecast. That way, participants in the Good Judgment Project are incentivized to monitor the news and update their forecasts continuously. This approach mirrors what is expected of forecasters in business and government, who… ([Location 3736](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3736))
    - Tags: [[pink]] 
- What do you do?”) Fourth, to score the performance of the forecasters, the Good Judgment Project used a system developed by Glenn W. Brier in 1950. Brier scores, as they are known, measure the distance between what people forecast and what actually happens. Brier scores are a clever way to get around a pervasive problem associated with probabilistic forecasts: the incentive for forecasters to hedge their bets by never taking a bold stance. Think again of Margaret, whom we described as a well-calibrated forecaster because she rated 500 events as 60% likely, and 300 of those events did happen. This result may not be as impressive as it seems. If Margaret is a weather forecaster who always predicts a 60% chance of rain and there are 300 rainy days out of 500, Margaret’s forecasts are well calibrated but also practically useless. Margaret, in essence, is telling you that, just in case, you might want to carry an umbrella every day. Compare her with Nicholas, who predicts a 100% chance of rain on the 300 days when it will rain, and a 0% chance of rain on the 200 dry days. Nicholas has the same perfect calibration as Margaret: when either forecaster predicts that X% of the days will be rainy, rain falls precisely X% of the time. But Nicholas’s forecasts are much more valuable: instead of hedging his bets, he is willing to tell you whether you should take an umbrella. Technically, Nicholas is said to have a high resolution in addition to good calibration. Brier scores reward both good calibration and good resolution. To produce a good score, you have not only to be right on average (i.e., well calibrated) but also to be willing to take a stand and differentiate among forecasts (i.e., have high resolution). Brier scores are based on the logic of mean squared errors, and lower scores are better: a score of 0 would be perfect. So, now that we know how they were scored, how well did the Good Judgment Project volunteers do? One of the major findings was that the overwhelming majority of the volunteers did poorly, but about 2% stood out. As mentioned earlier, Tetlock calls these well-performing people… ([Location 3745](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3745))
    - Tags: [[pink]] 
- Apart from general intelligence, we could reasonably expect that superforecasters are unusually good with numbers. And they are. But their real advantage is not their talent at math; it is their ease in thinking analytically and probabilistically. Consider superforecasters’ willingness and ability to structure and disaggregate problems. Rather than form a holistic judgment about a big geopolitical question (whether a nation will leave the European Union, whether a war will break out in a particular place, whether a public official will be assassinated), they break it up into its component parts. They ask, “What would it take for the answer to be yes? What would it take for the answer to be no?” Instead of offering a gut ([Location 3768](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3768))
    - Tags: [[pink]] 
- feeling or some kind of global hunch, they ask and try to answer an assortment of subsidiary questions. Superforecasters also excel at taking the outside view, and they care a lot about base rates. As explained for the Gambardi problem in chapter 13, before you focus on the specifics of Gambardi’s profile, it helps to know the probability that the average CEO will be fired or quit in the next two years. Superforecasters systematically look for base rates. Asked whether the next year will bring an armed clash between China and Vietnam over a border dispute, superforecasters do not focus only or immediately on whether China and Vietnam are getting along right now. They might have an intuition about this, in light of the news and analysis they have read. But they know that their intuition about one event is generally not a good guide. Instead they start by looking for a base rate: they ask how often past border disputes have escalated into armed clashes. If such clashes are rare, superforecasters will begin by incorporating that fact and only then turn to the details of the China–Vietnam situation. In short, what distinguishes the superforecasters isn’t their sheer intelligence; it’s how they apply it. ([Location 3773](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3773))
    - Tags: [[pink]] 
- To characterize the thinking style of superforecasters, Tetlock uses the phrase “perpetual beta,” a term used by computer programmers for a program that is not meant to be released in a final version but that is endlessly used, analyzed, and improved. Tetlock finds that “the strongest predictor of rising into the ranks of superforecasters is perpetual beta, the degree to which one is committed to belief updating and self-improvement.” As he puts it, “What makes them so good is less what they are than what they do—the hard work of research, the careful thought and self-criticism, the gathering and synthesizing of other perspectives, the granular judgments and relentless updating.” They like a particular cycle of thinking: “try, fail, analyze, adjust, try again.” ([Location 3787](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3787))
    - Tags: [[pink]] 
- At this point, you might be tempted to think that people can be trained to be superforecasters or at least to perform more like them. And indeed, Tetlock and his collaborators have worked to do exactly that. Their efforts should be considered the second stage of understanding why superforecasters perform so well and how to make them perform better. In an important study, Tetlock and his team randomly assigned regular (nonsuper) forecasters to three groups, in which they tested the effect of different interventions on the quality of subsequent judgments. These interventions exemplify three of the strategies we have described to improve judgments: 1. Training: Several forecasters completed a tutorial designed to improve their abilities by teaching them probabilistic reasoning. In the tutorial, the forecasters learned about various biases (including base-rate neglect, overconfidence, and confirmation bias); the importance of averaging multiple predictions from diverse sources; and considering reference classes. 2. Teaming (a form of aggregation): Some forecasters were asked to work in teams in which they could see and debate one another’s predictions. Teaming could increase accuracy by encouraging forecasters to deal with opposing arguments and to be actively open-minded. 3. Selection: All forecasters were scored for accuracy, and at the end of a full year, the top 2% were designated as superforecasters and given the opportunity to work together in elite teams the following year. As it turns out, all three interventions worked, in the sense that they improved people’s Brier scores. Training made a difference, teaming made a larger one, and selection had an even larger effect. This important finding confirms the value of aggregating judgments and selecting good judges. But it is not the full story. Armed with data about the effects of each intervention, Ville Satopää, who collaborated with Tetlock and Mellers, developed a sophisticated statistical technique to tease out how, exactly, each intervention improved forecasts. In principle, he reasoned, there are three major reasons why some forecasters can perform better or worse than others: 1. They can be more skilled at finding and analyzing data in the environment that are relevant to the prediction they have to make. This explanation points ([Location 3793](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3793))
    - Tags: [[pink]] 
- to the importance of information. 2. Some forecasters may have a general tendency to err on a particular side of the true value of a forecast. If, out of hundreds of forecasts, you systematically overestimate or underestimate the probability that certain changes from the status quo will occur, you can be said to suffer from a form of bias, in favor of either change or stability. 3. Some forecasters may be less susceptible to noise (or random errors). In forecasting, as in any judgment, noise can have many triggers. Forecasters may overreact to a particular piece of news (this is an example of what we have called pattern noise), they may be subject to occasion noise, or they may be noisy in their use of the probability scale. All these errors (and many more) are unpredictable in their size and direction. Satopää, Tetlock, Mellers, and their colleague Marat Salikhov called their model the BIN (bias,… ([Location 3811](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3811))
    - Tags: [[pink]] 
- worked primarily by reducing noise. As the researchers put it, “Whenever an intervention boosted accuracy, it worked mainly by suppressing random errors in judgment. Curiously, the original intent of the training intervention was to reduce bias.” Since the training was designed to reduce biases, a less-than-super forecaster would have predicted that bias reduction would be the major effect of the training. Yet the training worked by reducing noise. The surprise is easily explained. Tetlock’s training is designed to fight psychological biases. As you now know, the effect of psychological biases is not always a statistical bias. When they affect different individuals on different judgments in different ways, psychological biases produce noise. This is clearly the case here, as the events being forecast are quite varied. The same biases can lead a forecaster to overreact or underreact, depending on the topic. We should not expect them to produce a statistical bias, defined as the general tendency of a forecaster to believe that events will happen or not happen. As a result, training… ([Location 3819](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3819))
    - Tags: [[pink]] 
- that work together are better at finding information than one is. If Alice and Brian are working together, and Alice has spotted signals that Brian has missed, their joint forecast will be better. When working in groups, the superforecasters seem capable of avoiding the dangers of group polarization and information cascades. Instead, they pool their data and insights and, in their actively open-minded way, make the most of the combined information. Satopää and his colleagues explain this advantage: “Teaming—unlike training… allows forecasters to harness the information.” Selection had the largest total effect. Some of the improvement comes from a better use of information. Superforecasters are better than others at finding relevant information—possibly because they are smarter, more motivated, and more experienced at making these kinds of forecasts than is the average participant. But the main effect of selection is, again, to reduce noise. Superforecasters are less noisy than regular players or even… ([Location 3829](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3829))
    - Tags: [[pink]] 
- Speaking of Selection and Aggregation “Let’s take the average of four independent judgments—this is guaranteed to reduce noise by half.” “We should strive to be in perpetual beta, like the superforecasters.” “Before we discuss this situation, what is the relevant base rate?” “We have a good team, but how can we ensure more diversity of opinions?” ([Location 3863](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3863))
    - Tags: [[pink]] 
- But the surprise is not the existence of noise in the medical profession. It is its sheer magnitude. Our goals in this chapter are to elaborate that claim and to describe some of the approaches to noise reduction used by the medical profession. We will ([Location 3895](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3895))
    - Tags: [[pink]] 
- focus on one decision hygiene strategy: the development of diagnostic guidelines. We are keenly aware that an entire book could easily be written about noise in medicine and the various steps that doctors, nurses, and hospitals have been taking by way of remedy. Notably, noise in medicine is hardly limited to noise in diagnostic judgments, which is our focus here. Treatments can also be noisy, and an extensive literature addresses this topic as well. If a patient has a heart problem, doctors’ judgments about the best treatment are shockingly variable, whether the question involves the right medication, the right kind of surgery, or whether to get surgery at all. The Dartmouth Atlas Project has dedicated itself, for more than twenty years, to documenting “glaring variations in how medical resources are distributed and used in the United States.” Similar conclusions hold in numerous nations. For our purposes, however, a brief exploration of noise in diagnostic judgments will be sufficient. ([Location 3897](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3897))
    - Tags: [[pink]] 
- In medicine, between-person noise, or interrater ([Location 3916](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3916))
    - Tags: [[pink]] 
- reliability, is usually measured by the kappa statistic. The higher the kappa, the less noise. A kappa value of 1 reflects perfect agreement; a value of 0 reflects exactly as much agreement as you would expect between monkeys throwing darts onto a list of possible diagnoses. In some domains of medical diagnosis, reliability as measured by this coefficient has been found to be “slight” or “poor,” which means that noise is very high. It is often found to be “fair,” which is of course better but which also indicates significant noise. On the important question of which drug-drug interactions are clinically significant, generalist physicians, reviewing one hundred randomly selected drug-drug interactions, showed “poor agreement.” To outsiders and to many doctors, diagnosis of the various stages of kidney disease might seem relatively straightforward. But nephrologists show only “slight to moderate agreement” in their judgments about the meaning of standard tests used in the evaluation of patients with kidney disease. ([Location 3916](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3916))
    - Tags: [[pink]] 
- A large study found that the range of false negatives among different radiologists varied from 0% (the radiologist was correct every time) to greater than 50% (the radiologist incorrectly identified the mammogram as normal more than half of the time). Similarly, false-positive rates ranged from less than 1% to 64% (meaning that nearly two-thirds of the time, the radiologist said the mammogram showed cancer when cancer was not present). False negatives and false positives, from different radiologists, ensure that there is noise. ([Location 3953](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3953))
    - Tags: [[pink]] 
- Less Noisy Doctors: The Value of Guidelines ([Location 3970](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3970))
    - Tags: [[pink]] 
- It would be a major contribution not only to medicine but also to human knowledge to provide a comprehensive account of the existence and magnitude of noise in the context of different medical problems. We are unaware of any such account; we hope that it will be produced in the fullness of time. But even now, existing findings provide some clues. At one extreme, diagnosis for some problems and illnesses is essentially mechanical and allows no room for judgment. In other cases, the diagnosis is not mechanical but straightforward; anyone with medical training is highly likely to reach the same conclusion. In still other cases, a degree of specialization—among, say, lung cancer specialists—will be sufficient to ensure that noise exists but is minimal. At the other extreme, some cases present a great deal of room for judgment, and the relevant criteria for diagnosis are so open-ended that noise will be substantial and difficult to reduce. As we will see, this is the case in much of psychiatry. ([Location 3971](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3971))
    - Tags: [[pink]] 
- Perhaps the most famous example of a guideline for diagnosis is the Apgar score, developed in 1952 by the obstetric anesthesiologist Virginia Apgar. Assessing whether a newborn baby is in distress used to be a matter of clinical judgment for physicians and midwives. Apgar’s score gave them a standard guideline instead. The evaluator measures the baby’s color, heart rate, reflexes, muscle tone, and respiratory effort, sometimes summarized as a “backronym” for Apgar’s name: appearance (skin color), pulse (heart rate), grimace (reflexes), activity (muscle tone), and ([Location 3987](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3987))
    - Tags: [[pink]] 
- respiration (breathing rate and effort). In the Apgar test, each of these five measures is given a score of 0, 1, or 2. The highest possible total score is 10, which is rare. A score of 7 or above is considered indicative of good health (table 3). ([Location 3991](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=3991))
    - Tags: [[pink]] 
- Note that heart rate is the only strictly numerical component of the score and that all the other items involve an element of judgment. But because the judgment is decomposed into individual elements, each of which is straightforward to assess, practitioners with even a modest degree of training are unlikely to disagree a great deal—and hence Apgar scoring produces little noise. The Apgar score exemplifies how guidelines work and why they reduce noise. Unlike rules or algorithms, guidelines do not eliminate the need for judgment: the decision is not a straightforward computation. Disagreement remains possible on each of the components and hence on the final conclusion. Yet guidelines succeed in reducing noise because they decompose a complex decision into a number of easier subjudgments on predefined dimensions. The benefits of this approach are clear when we view the problem in terms of the simple prediction models discussed in chapter 9. A clinician making a judgment about a newborn’s health is working from ([Location 4010](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4010))
    - Tags: [[pink]] 
- The Depressing Case of Psychiatry In terms of noise, psychiatry is an extreme case. When diagnosing the same patient using the same diagnostic criteria, psychiatrists frequently disagree with one another. For that reason, noise reduction has been a major priority for the psychiatric community since at least the 1940s. And as we will see, despite being constantly refined, guidelines have provided only modest help in reducing noise. A 1964 study involving 91 patients and ten experienced psychiatrists found that the likelihood of ([Location 4032](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4032))
    - Tags: [[pink]] 
- an agreement between two opinions was just 57%. Another early study, involving 426 state hospital patients diagnosed independently by two psychiatrists, found agreement merely 50% of the time in their diagnosis of the kind of mental illness that was present. Yet another early study, involving 153 outpatients, found 54% agreement. In these studies, the source of the noise was not specified. Interestingly, however, some psychiatrists were found to be inclined to assign patients to specific diagnostic categories. For example, some psychiatrists were especially likely to diagnose patients with depression, and others with anxiety. As we shall soon see, levels of noise continue to be high in psychiatry. Why is this? Specialists lack a single, clear answer (which means that the explanations for noise are themselves noisy). The large set of diagnostic categories is undoubtedly one factor. But in a preliminary effort to answer that question, researchers asked one psychiatrist to interview a patient first, and then had a second psychiatrist conduct another interview after a short resting period. The two psychiatrists met afterward and, if they disagreed, discussed why they did so. One frequent reason was “inconstancy of the physician”: different schools of thought, different training, different clinical experiences, different interview styles. While a “clinician with developmental training ([Location 4036](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4036))
    - Tags: [[pink]] 
- might explain the hallucinatory experience as part of posttraumatic experience of past abuse,” a different clinician “with a biomedical orientation might explain the same hallucinations as part of a schizophrenic process.” Such differences are examples of pattern noise. Beyond physician differences, however, the main reason for noise was “inadequacy of the nomenclature.” Such observations and widespread professional dissatisfaction with psychiatric nomenclature helped motivate the 1980 revision (the third edition) of the Diagnostic and Statistical Manual of Mental Disorders (DSM-III). The manual included, for the first time, explicit and detailed criteria for diagnosing mental disorders, a first step in the direction of introducing diagnostic guidelines. DSM-III led to a dramatic increase in the research on whether diagnoses were noisy. It also proved helpful in reducing noise. But the manual was far from a complete success. Even after a significant 2000 revision of the fourth edition, DSM-IV (originally published in 1994), research showed that the level of noise remained high. On the one… ([Location 4046](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4046))
    - Tags: [[pink]] 
- reveal multiple diagnoses for the same patient.” Another version of the manual, DSM-5, was released in 2013. The American Psychiatric Association had hoped that DSM-5 would reduce noise because the new edition relied on more objective, clearly scaled criteria. But psychiatrists continue to show significant noise. For example, Samuel Lieblich and his colleagues find that “psychiatrists have a hard time agreeing on who does and does not have major depressive disorder.” Field trials for DSM-5 found “minimal agreement,” which “means that highly trained specialist psychiatrists under study conditions were only able to agree that a patient has depression between 4 and 15% of the time.” According to some field trials, DSM-5 actually made things worse, showing increased noise “in all major domains, with some diagnoses, such as mixed anxiety-depressive disorder… so unreliable as to appear useless in clinical practice.” The major reason for the limited success of guidelines seems to be that, in psychiatry, “the diagnostic criteria of some disorders are still vague and difficult to operationalize.” Some guidelines reduce noise by decomposing judgment… ([Location 4056](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4056))
    - Tags: [[pink]] 
- from vague standards; (2) producing “reference definitions” of symptoms and their level of severity, on the theory that when “clinicians agree on the presence or absence of symptoms, they are more likely to agree on the diagnosis”; and (3) using structured interviews of patients in addition to open conversation. One proposed interview guide includes twenty-four screening questions that allow for more reliable diagnosis of, for example, anxiety, depression, and eating disorders. These steps sound promising, but it is an open question to what extent they would succeed in reducing noise. In the words of one observer, “the reliance on the patient’s subjective symptoms, the clinician’s interpretation of the symptoms, and the absence of objective measure (such as a blood test) implant the seeds of diagnostic unreliability of psychiatric disorders.” In this sense, psychiatry may prove especially resistant to attempts at noise reduction. On that particular question, it is too soon to make a confident prediction. But… ([Location 4067](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4067))
    - Tags: [[pink]] 
- Speaking of Guidelines in… ([Location 4076](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4076))
    - Tags: [[pink]] 
- “Among doctors, the level of noise is far higher than we might have suspected. In diagnosing cancer and heart disease—even in reading X-rays—specialists sometimes disagree. That means that the treatment a patient gets might be a product of a lottery.” “Doctors like to think that they make the same decision whether it’s Monday or Friday or early in the morning or late in the afternoon. But it turns out that what doctors say and do might well depend on how tired they are.” “Medical guidelines can make doctors less likely… ([Location 4077](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4077))
    - Tags: [[pink]] 
- Different studies come to different conclusions on the breakdown of system noise into these three components (level, pattern, and occasion), and we can certainly imagine reasons why it should vary from one organization to the next. But all forms of noise are undesirable. The basic message that emerges from this research is a simple one: most ratings of performance have much less to do with the performance of the person being rated than we would wish. As one review summarizes it, “the relationship between job performance and ratings of job performance is likely to be weak or at best uncertain.” ([Location 4124](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4124))
    - Tags: [[pink]] 
- What’s Next? In light of all the efforts that organizations have made to improve performance measurement, it is an understatement to say that the results have been disappointing. As a result of those efforts, the cost of performance evaluations skyrocketed. In 2015, Deloitte calculated that it was spending 2 million hours each year evaluating its sixty-five thousand people. Performance reviews continue to be one of the most dreaded rituals of organizations, hated almost as much by those who have to perform them as by those who receive them. One study found that a staggering 90% of managers, employees, and HR heads believe that their performance management processes fail to deliver the results they expected. Research has confirmed what most managers have experienced. Although performance feedback, when associated with a development plan for the employee, can bring about improvements, performance ratings as they are most ([Location 4215](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4215))
    - Tags: [[pink]] 
- often practiced demotivate as often as they motivate. As one review article summarized, “No matter what has been tried over decades to improve [performance management] processes, they continue to generate inaccurate information and do virtually nothing to drive performance.” ([Location 4222](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4222))
    - Tags: [[pink]] 
- Frame-of-reference training has been known for decades and provides demonstrably less noisy and more accurate ratings. Yet it has gained little ground. It is easy to guess why. Frame-of-reference training, case scales, and other tools that pursue the same goals are complex and time-consuming. To be valuable, they usually need to be customized for the company and even for the unit conducting the evaluations, and they must be frequently updated as job requirements evolve. These tools require a company ([Location 4243](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4243))
    - Tags: [[pink]] 
- to add to its already-large investment in its performance management systems. Current fashion goes in the opposite direction. (In part 6, we shall have more to say about the costs of reducing noise.) ([Location 4246](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4246))
    - Tags: [[pink]] 
- Speaking of Defining the Scale “We spend a lot of time on our performance ratings, and yet the results are one-quarter performance and three-quarters system noise.” “We tried 360-degree feedback and forced ranking to address this problem, but we may have made things worse.” “If there is so much level noise, it is because different raters have completely different ideas of what ‘good’ or ‘great’ means. They will only agree if we give them concrete cases as anchors on the rating scale.” ([Location 4263](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4263))
    - Tags: [[pink]] 
- One study that tracked the behavior of interviewers who had formed a positive or negative initial impression from résumés and test scores found that initial impressions have a deep effect on the way the interview proceeds. Interviewers with positive first impressions, for instance, ask fewer questions and tend to “sell” the company to the candidate. ([Location 4338](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4338))
    - Tags: [[pink]] 
- The story illustrates that however much we would like to believe that our judgment about a candidate is based on facts, our interpretation of facts is colored by prior attitudes. ([Location 4356](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4356))
    - Tags: [[pink]] 
- A final point: when interviews are not the only source of information about candidates—for instance, when there are also tests, references, or other inputs—these various inputs must be combined into an ([Location 4366](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4366))
    - Tags: [[pink]] 
- overall judgment. The question this raises is one you now recognize: should the inputs be combined using judgment (a clinical aggregation) or a formula (a mechanical aggregation)? As we saw in chapter 9, the mechanical approach is superior both in general and in the specific case of work performance prediction. Unfortunately, surveys suggest that the overwhelming majority of HR professionals favor clinical aggregation. This practice adds yet another source of noise to an already-noisy process. ([Location 4367](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4367))
    - Tags: [[pink]] 
- One of these strategies should be familiar by now: aggregation. Its use in this context is not a surprise. Almost all companies aggregate the judgments of multiple interviewers on the same candidate. Not to be outdone, Google sometimes had candidates suffer through twenty-five interviews! One of the conclusions of Bock’s review was to reduce that number to four, as he found that additional interviews added almost no predictive validity to what was achieved by the first four. To ensure this level of validity, however, Google stringently enforces a rule that not all companies observe: the company makes sure that the interviewers rate the candidate separately, before they communicate with one another. Once more: aggregation works—but only if the judgments are independent. Google also adopted a decision hygiene strategy we haven’t yet described in detail: structuring complex judgments. The term structure can mean many things. As we use the term here, a structured complex judgment is defined by three principles: decomposition, independence, and delayed holistic judgment. The first principle, decomposition, breaks down the decision into components, or mediating assessments. This step serves the same purpose as the identification of the subjudgments in a guideline: it focuses the judges on the important cues. Decomposition acts as a road map to specify what data is needed. And it filters out irrelevant information. In Google’s case, there are four mediating assessments in the decomposition: general cognitive ability, leadership, cultural fit (called “googleyness”), and role-related knowledge. (Some of these assessments are then broken down into smaller components.) Note that a candidate’s good looks, smooth talk, exciting hobbies, and any other aspects, positive or negative, that a recruiter might notice in an unstructured interview are not on the list. ([Location 4378](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4378))
    - Tags: [[pink]] 
- The second principle of structured judgment, independence, requires that information on each assessment be collected independently. Just listing the components of the job description is not enough: most recruiters conducting traditional interviews also know the four or five things they look for in a candidate. The problem is that, in the conduct of the interview, they do not evaluate these elements separately. Each assessment influences the others, which makes each assessment very noisy. To overcome this problem, Google orchestrated ways to make assessments in a fact-based manner and independently of one another. Perhaps its most visible move was to introduce structured behavioral interviews. The interviewers’ task in such interviews is not to decide whether they like a candidate overall; it is to collect data about each assessment in the evaluation structure and to assign a score to the candidate on each assessment. To do so, interviewers are required to ask predefined questions about the candidate’s behaviors in past situations. They must also record the answers and score them against a predetermined rating scale, using a unified rubric. The rubric gives examples of what average, good, or great answers look like for each question. This shared scale (an example of the behaviorally anchored rating scales we introduced in the preceding chapter) helps reduce noise in judgments. ([Location 4399](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4399))
    - Tags: [[pink]] 
- Google uses other data as inputs on some of the dimensions it cares about. To test job-related knowledge, it relies in part on work sample tests, such as asking a candidate for a programming job to write some code. Research has shown that work sample tests are among the best predictors of on-the-job performance. Google also uses “backdoor references,” supplied not by someone the candidate has nominated but by Google employees with whom the candidate has crossed paths. The third principle of structured judgment, delayed holistic judgment, can be summarized in a simple prescription: do not exclude intuition, but delay it. At Google, the final hiring recommendation is made collegially by a hiring committee, which reviews a complete file of all the ratings the candidates have obtained on each assessment in each interview and other relevant information in support of these assessments. On the basis of that information, the committee then decides ([Location 4415](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4415))
    - Tags: [[pink]] 
- whether to extend an offer. Despite the famously data-driven culture of this company, and despite all the evidence that a mechanical combination of data outperforms a clinical one, the final hiring decision is not mechanical. It remains a judgment, in which the committee takes all the evidence into account and weighs it holistically, engaging in a discussion of the question “Will this person be successful at Google?” The decision is not merely computed. ([Location 4422](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4422))
    - Tags: [[pink]] 
- The three principles—once more, decomposition, independent assessment on each dimension, and delayed holistic judgment—do not necessarily provide a template for all organizations trying to improve their selection processes. But the principles are broadly consistent with the recommendations that organizational psychologists have formulated over the years. In fact, the principles bear some resemblance to the selection method that one of us (Kahneman) implemented in ([Location 4429](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4429))
    - Tags: [[pink]] 
- the Israeli army as early as 1956 and described in Thinking, Fast and Slow. That process, like the one Google put in place, formalized an evaluation structure (the list of personality and competence dimensions that had to be evaluated). It required interviewers to elicit objective evidence relevant to each dimension in turn and to score that dimension before moving on to the next. And it allowed recruiters to use judgment and intuition to reach a final decision—but only after the structured evaluation had taken place. ([Location 4433](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4433))
    - Tags: [[pink]] 
- Nevertheless, most executives remain convinced of the irreplaceable value of informal, interview-based methods. Remarkably, so do many candidates who believe that only a face-to-face interview will enable them to show a prospective employer their true mettle. Researchers have called this “the persistence of an illusion.” One thing is clear: recruiters and candidates severely underestimate the noise in hiring judgments. Speaking of Structure in Hiring ([Location 4440](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4440))
    - Tags: [[pink]] 
- “In traditional, informal interviews, we often have an irresistible, intuitive feeling of understanding the candidate and knowing whether the person fits the bill. We must learn to distrust that feeling.” “Traditional interviews are dangerous not only because of biases but also because of noise.” “We must add structure to our interviews and, more broadly, to our selection processes. Let’s start by defining much more clearly and specifically what we are looking for in candidates, and let’s make sure we evaluate the candidates independently on each of these dimensions.” ([Location 4444](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4444))
    - Tags: [[pink]] 
- Some time ago, two of us (Kahneman and Sibony), together with our friend Dan Lovallo, described a method of decision making in organizations. We called the method, which was designed with noise mitigation as a primary objective, the mediating assessments protocol. It incorporates most of the decision hygiene strategies that we have introduced in the preceding chapters. The protocol can be applied broadly and whenever the evaluation of a plan or an option requires considering and weighting multiple dimensions. It can be used, and adapted in various ways, by organizations of all kinds, including diverse companies, hospitals, universities, and government agencies. ([Location 4452](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4452))
    - Tags: [[pink]] 
- The committee members agreed to try out the approach. But, they asked, what were the mediating assessments? Was there a predefined checklist that Joan had in mind? “No,” she replied. “That might be the case if we applied the protocol to a routine decision, but in this case, we need to define the mediating assessments ourselves. This is critically important: deciding on the major aspects of the acquisition that should be assessed is up to us.” The strategy committee agreed to meet again the next day to do that. ([Location 4492](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4492))
    - Tags: [[pink]] 
- The deal team’s mission, as Joan saw it, was not to tell the board what it thought of the deal as a whole—at least, not yet. It was to provide an objective, independent evaluation on each of the mediating assessments. Ultimately, Joan explained, each chapter in the deal team’s report should end with a rating that answers a simple question: “Leaving aside the weight we should give this topic in the final decision, how strongly does the evidence on this assessment argue for or against the deal?” ([Location 4508](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4508))
    - Tags: [[pink]] 
- First, he explained, the team’s analysts should try to make their analyses as objective as possible. The evaluations should be based on facts—nothing new about that—but they should also use an outside view whenever possible. Since the team members were unsure of what he meant by “outside view,” Jeff gave them two examples, using two of the mediating assessments Joan had identified. To evaluate the probability that the deal would receive regulatory approval, he said, they would need to start by finding out the base rate, the percentage of comparable transactions that are approved. This task would, in turn, require them to define a relevant reference class, a group of deals considered comparable enough. ([Location 4514](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4514))
    - Tags: [[pink]] 
- Your job is not to sell your recommendation. It is to represent the truth. If it is complicated, so be it—it often is.” ([Location 4543](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4543))
    - Tags: [[pink]] 
- As she read the team’s report to prepare for the decision meeting, Joan immediately noticed something important: while most of the assessments supported doing the deal, they did not paint a simple, rosy, all-systems-go picture. Some of the ratings were strong; others were not. These differences, she knew, were a predictable result of keeping the assessments independent of one another. When excessive coherence is kept in check, reality is not as coherent as most board presentations make it seem. “Good,” Joan thought. “These discrepancies between assessments will raise questions and trigger discussions. That’s just what we need to have a good debate in the board. The diverse results will not make the decision easier, for sure—but they will make it better.” Joan convened a meeting of the board to review the report and come to a decision. She explained the approach that the deal team followed, and she invited the board members to apply the same principle. “Jeff and his team have worked hard to keep the assessments independent of each other,” she said, “and our task now is to review them independently, too. This means we will consider each assessment separately, before we start discussing the final decision. We are going to treat each assessment as a distinct agenda item.” The board members knew that following this structured approach would ([Location 4548](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4548))
    - Tags: [[pink]] 
- be difficult. Joan was asking them not to form a holistic view of the deal before all assessments were discussed, but many of them were industry insiders. They had a view on Roadco. Not discussing it felt a bit artificial. Nevertheless, because they understood what Joan was trying to achieve, they agreed to play by her rules and refrain temporarily from discussing their overall views. To their surprise, the board members found that this practice was highly valuable. During the meeting, some of them even changed their mind about the deal (although no one would ever know, since they had kept their views to themselves). The way Joan ran the meeting played a large part: she used the estimate-talk-estimate method, which combines the advantages of deliberation and those of averaging independent opinions. Here is how she proceeded. On each assessment, Jeff, on behalf of the deal team, briefly summarized the key facts (which the board members had read in detail beforehand). Then Joan asked the board members to use a voting app on their phones to give their own rating on the assessment—either the same as the deal team’s proposed rating or a different one. The distribution of ratings was projected immediately on the screen, without identifying the raters. “This is not a vote,” Joan explained. “We are just taking the temperature of the room on each topic.” By getting an immediate read on each board member’s independent opinion before starting a discussion, Joan reduced the danger of social influence and information cascades. ([Location 4558](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4558))
    - Tags: [[pink]] 
- On some assessments, there was immediate consensus, but on others, the process revealed opposing views. Naturally, Joan managed the discussion to spend more time on the latter. She made sure that board members on each side of the divide spoke up, encouraging them to express their viewpoints with facts and arguments but also with nuance and humility. Once, when a board member who felt strongly about the deal got carried away, she reminded him that “we are all reasonable people and we disagree, so this must be a subject on which reasonable people can disagree.” When the discussion of an assessment drew to a close, Joan asked the board members to vote again on a rating. Most of the time, there was more convergence than in the initial round. The same sequence—a first estimate, a discussion, and a second estimate—was repeated for each assessment. Finally, it was time to reach a conclusion about the deal. To facilitate the discussion, Jeff showed the list of assessments on the whiteboard, with, for each assessment, the average of the ratings that the board had assigned to it. The board members were looking at the profile of the deal. How should they decide? One board member had a simple suggestion: use a… ([Location 4569](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4569))
    - Tags: [[pink]] 
- person disagreed, suggesting a different hierarchy of the assessments. Joan interrupted the discussion. “This is not just about computing a simple combination of the assessment ratings,” she said. “We have delayed intuition, but now is the time to use it. What we need now is your judgment.” Joan did not explain her logic, but she had learned this lesson the hard way. She knew that, particularly with important decisions, people reject schemes that tie their hands and do not let them use their judgment. She had seen how decision makers game the system when they know that a formula will be used. They change the ratings to arrive at the desired conclusion—which defeats the purpose of the entire exercise. Furthermore, although this was not the case here, she remained alert to the possibility that decisive considerations could emerge that were not anticipated in the definition of assessments (the broken-leg factors discussed in chapter 10). If such unanticipated deal breakers (or, conversely, deal clinchers) appeared, a purely mechanical decision process based on the average of the assessments might lead to a serious mistake. Joan also knew that letting the board members use their intuition at this stage was very different from having them use it earlier in the process. Now that the assessments were available and known to all, the final… ([Location 4580](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4580))
    - Tags: [[pink]] 
- The Mediating Assessments Protocol in Recurring Decisions We have described the mediating assessments protocol in the context of a one-off, singular decision. But the procedure applies to recurring decisions, too. Imagine that Mapco is not making a single acquisition but is a venture capital fund that makes repeated investments in start-ups. The protocol would be just as applicable and the story would be much the same, with just two twists that, if anything, make it simpler. First, the initial step—defining the list of mediating assessments—needs to be done only once. The fund has investment criteria, which it applies to all its prospective investments: these are the assessments. There is no need to reinvent them each time. Second, if the fund makes many decisions of the same type, it can use its experience to calibrate its judgments. Consider, for instance, an assessment that every fund will want to make: evaluating the quality of the management team. We suggested that… ([Location 4592](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4592))
    - Tags: [[pink]] 
- much easier in the context of a recurring decision. If you have evaluated the management teams of dozens, even hundreds of companies, you can use this shared experience as a reference class. A practical way to do this is to create a case scale defined by anchor cases. You might say, for instance, that the target management team is “as good as the management team of ABC Company when we acquired it” but not quite “as good as the management team of DEF Company.” The anchor cases must, of course, be known to all the participants (and periodically updated). Defining them requires an up-front investment of time. But the value of this approach is… ([Location 4602](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4602))
    - Tags: [[pink]] 
- What the Protocol Changes For ease of reference, we summarize the main changes that the mediating assessments protocol entails in table 4. Table 4: Main steps of the mediating assessments protocol 1. At the beginning of the process, structure the decision into mediating assessments. (For recurring judgments, this is done only once.) 2. Ensure that whenever possible, mediating assessments… ([Location 4607](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4607))
    - Tags: [[pink]] 
- 3. In the analytical phase, keep the assessments as independent of one another as possible. 4. In the decision meeting, review each assessment separately. 5. On each assessment, ensure that participants make their judgments individually; then use the estimate-talk-estimate… ([Location 4614](https://readwise.io/to_kindle?action=open&asin=B08KQ2FKBX&location=4614))
    - Tags: [[pink]]

