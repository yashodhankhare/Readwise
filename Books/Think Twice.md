---
tags:
  - readwise
---

# Think Twice

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/31KuXwy4b3L._SL200_.jpg)

## Metadata
- Author: [[Michael J. Mauboussin]]
- Full Title: Think Twice
- Category: #books

## Highlights
- A Ponzi scheme is a fraudulent operation in which a manager uses funds from new investors to pay off old investors. Since there is no legitimate investment activity, it collapses when the operator can’t find enough additional investors. ([Location 95](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=95))
    - Tags: [[pink]] 
- Mental flexibility, introspection, and the ability to properly calibrate evidence are at the core of rational thinking and are largely absent on IQ tests. ([Location 124](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=124))
    - Tags: [[pink]] 
- To make good decisions, you frequently must think twice—and that’s something our minds would rather not do. ([Location 131](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=131))
    - Tags: [[pink]] 
- Three factors determine the outcomes of your decisions: how you think about the problem, your actions, and luck. ([Location 196](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=196))
    - Tags: [[pink]] 
- In a probabilistic environment, you are better served by focusing on the process by which you make a decision than on the outcome. ([Location 207](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=207))
    - Tags: [[pink]] 
- These contrasting points of view reveal our first mistake, a tendency to favor the inside view over the outside view.6 An inside view considers a problem by focusing on the specific task and by using information that is close at hand, and makes predictions based on that narrow and unique set of inputs. ([Location 298](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=298))
    - Tags: [[pink]] 
- The outside view asks if there are similar situations that can provide a statistical basis for making a decision. Rather than seeing a problem as unique, the outside view wants to know if others have faced comparable problems and, if so, what happened. The outside view is an unnatural way to think, precisely because it forces people to set aside all the cherished information they have gathered. ([Location 334](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=334))
    - Tags: [[pink]] 
- Why do people tend to embrace the inside view? Most of us are unduly optimistic a good deal of the time. Social psychologists distinguish three illusions that lead people to the inside view.7 ([Location 339](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=339))
    - Tags: [[pink]] 
- This shows the illusion of superiority, which suggests people have an unrealistically positive view of themselves. ([Location 344](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=344))
    - Tags: [[pink]] 
- The second is the illusion of optimism. Most people see their future as brighter than that of others. ([Location 359](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=359))
    - Tags: [[pink]] 
- Finally, there is the illusion of control. People behave as if chance events are subject to their control. ([Location 362](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=362))
    - Tags: [[pink]] 
- A vast range of professionals commonly lean on the inside view to make important decisions with predictably poor results. This is not to say these decision makers are negligent, naïve, or malicious. Encouraged by the three illusions, most believe they are making the right decision and have faith that the outcomes will be satisfactory. Now that you are aware of the distinction between the inside and outside view, you can measure your decisions and the decisions of others more carefully. ([Location 376](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=376))
    - Tags: [[pink]] 
- Basic math explains why most companies don’t add value when they acquire another firm. The change in value for the buyer equals the difference between the increase in cash flow from combining the two companies (synergies) and the amount over the market value that the acquirer pays (premium). Companies want to get more than they pay for. So if synergies exceed the premium, the price of the buyer’s stock will rise. If not, it will fall. ([Location 392](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=392))
    - Tags: [[pink]] 
- This work has an interesting twist. While people are notoriously poor at guessing when they’ll finish their own projects, they’re pretty good at guessing about other people. In fact, the planning fallacy embodies a broader principle. When people are forced to look at similar situations and see the frequency of success, they tend to predict more accurately. If you want to know how something is going to turn out for you, look at how it turned out for others in the same situation. Daniel Gilbert, a psychologist at Harvard University, ponders why people don’t rely more on the outside view, “Given the impressive power of this simple technique, we should expect people to go out of their way to use it. But they don’t.” The reason is most people think of themselves as different, and better, than those around them.19 ([Location 462](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=462))
    - Tags: [[pink]] 
- How to Incorporate the Outside View into Your Decisions ([Location 492](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=492))
    - Tags: [[pink]] 
- Kahneman and Amos Tversky, a psychologist who had a long collaboration with Kahneman, published a multistep process to help you use the outside view.21 I have distilled their five steps into four and have added some thoughts. Here are the four steps: Select a reference class. Find a group of situations, or a reference class, that is broad enough to be statistically significant but narrow enough to be useful in analyzing the decision that you face. The task is generally as much art as science, and is certainly trickier for problems that few people have dealt with before. But for decisions that are common—even if they are not common for you—identifying a reference class is straightforward. Mind the details. Take the example of mergers and acquisitions. We know that the shareholders of acquiring companies lose money in most mergers and acquisitions. But a closer look at the data reveals that the market responds more favorably to cash deals and those done at small premiums than to deals financed with stock at large premiums. So companies can improve their chances of making money from an acquisition by knowing what deals tend to succeed. Assess the distribution of outcomes. Once you have a reference class, take a close look at the rate of success and failure. For example, fewer than one of six horses in Big Brown’s position won the Triple Crown. Study the distribution and note the average outcome, the most common outcome, and extreme successes or failures. In his book Full House, Stephen Jay Gould, who was a paleontologist at Harvard University, showed the importance of knowing the distribution of outcomes after his doctor diagnosed him with mesothelioma. His doctor explained that half of the people diagnosed with the rare cancer lived only eight months (more technically, the median mortality was eight months), seemingly a death sentence. But Gould soon realized that while half the patients died within eight months, the other half went on to live much longer. Because of his relatively young age at diagnosis, there was a good chance he would be one of the fortunate ones. Gould wrote, “I had asked the right question and found the answers. I had obtained, in all probability, the most precious of all possible gifts in the circumstances—substantial time.” Gould lived another twenty years.22 ([Location 493](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=493))
    - Tags: [[pink]] 
- Two other issues are worth mentioning. The statistical rate of success and failure must be reasonably stable over time for a reference class to be valid. If the properties of the system change, drawing inference from past data can be misleading. This is an important issue in personal finance, where advisers make asset allocation recommendations for their clients based on historical statistics. Because the statistical properties of markets shift over time, an investor can end up with the wrong mix of assets. Also keep an eye out for systems where small perturbations can lead to large-scale change. Since cause and effect are difficult to pin down in these systems, drawing on past experiences is more difficult. Businesses driven by hit products, like movies or books, are good examples. Producers and publishers have a notoriously difficult time anticipating results, because success and failure is based largely on social influence, an inherently unpredictable phenomenon. Make a prediction. With the data from your reference class in hand, including an awareness of the distribution of outcomes, you are in a position to make a forecast. The idea is to estimate your chances of success and failure. For all the reasons that I’ve discussed, the chances are good that your prediction will be too optimistic. Sometimes when you find the right reference class, you see the success rate is not very high. So to improve your chance of success, you have to do something different than everyone else. One example is the play calling of National Football League coaches in critical game situations including fourth downs, kickoffs, and two-point conversion attempts. As in many other sports, conventional ways to decide about these situations are handed down from one generation of coaches to the next. But this stale decision-making process means scoring fewer points and winning fewer games. Chuck Bower, an astrophysicist at Indiana University, and Frank Frigo, a former world backgammon champion, created a computer program called Zeus to assess the play-calling decisions of pro football coaches. Zeus uses the same modeling techniques that have succeeded in backgammon and chess programs, and the creators loaded it with statistics and the behavioral traits of coaches. Bower and Frigo found that only four teams in the thirty-two-team league made crucial decisions that agreed with… ([Location 511](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=511))
    - Tags: [[pink]] 
- But the point that Kahneman emphasized was that even if you explain anchoring to a group, it does not sink in. You can run an experiment right after a discussion of the concept and still see the bias in action. The main reason, psychologists believe, is that anchoring is predominantly subconscious. ([Location 562](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=562))
    - Tags: [[pink]] 
- Anchoring is symptomatic of this chapter’s broader decision mistake: an insufficient consideration of alternatives. To be blunter, you can call it tunnel vision. Failure to entertain options or possibilities can lead to dire consequences, from a missed medical diagnosis to unwarranted confidence in a financial model. So what’s going on in our heads that causes us to focus too narrowly? One of my favorite explanations comes from Phillip Johnson-Laird, a psychologist known for his theory of mental models. Johnson-Laird argues that when we reason, “We use perception, the meanings of words and sentences, the significance of the propositions that they express, and our knowledge. Indeed, we use everything we’ve got to think of possibilities, and we represent each possibility in a mental model of the world.”3 ([Location 565](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=565))
    - Tags: [[pink]] 
- Our minds are just trying to get an answer—the proper diagnosis for a sick patient, the right price for an acquisition, what will happen next in a novel—and have routines to get the answer quickly and often efficiently. But getting the right solution expeditiously means homing in on what seems to us to be the most likely outcomes and leaving out a lot of what could be. For most of our evolutionary past, this worked well. But the causal patterns that worked in a natural environment tens of thousands of years ago often do not hold in today’s technological world. So when the stakes are sufficiently high, we must slow down and swing the light over the full range of possible outcomes. ([Location 587](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=587))
    - Tags: [[pink]] 
- You can also see the consequence of anchoring and adjustment in negotiation. Gregory Northcraft and Margaret Neale, psychologists who study negotiation tactics, presented a group of real estate agents identical background material on a specific house—its size, amenities, and recent comparable-house transactions. To measure the anchoring effect, the researchers gave some agents different listing prices for the same house. Sure enough, the agents who saw a high listing price appraised the house for substantially more than those who saw a low price (see figure 2–1). Notable, too, is that less than 20 percent of the agents reported using the listing price data in their appraisal, insisting instead their assessment was independent. This bias is pernicious in large part because we are so unaware of it.8 ([Location 603](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=603))
    - Tags: [[pink]] 
- In his book How Doctors Think, Dr. Jerome Groopman describes a trim and fit forest ranger who found himself in a hospital emergency room with chest pains. The doctor on duty listened carefully to the ranger’s symptoms, reviewed a checklist for heart disease, and ordered some standard tests. All came out fine. The results, along with the man’s healthy look, prompted the doctor to assure the patient there was an “about zero” chance his heart was the source of the problem. The next day, the forest ranger came back in with a heart attack. Fortunately, he survived. But the doctor who had seen him the previous day was beside himself. On reflection, the doctor realized he had fallen prey to a bias that arises from the representativeness heuristic. This bias, the second of our decision mistakes, says we often rush to conclusions based on representative categories in our mind, neglecting possible alternatives. The well-worn aphorism “don’t judge a book by its cover” speaks to this bias, encouraging us to remain open to options even as our mind seeks to shut them down. In this case, the doctor’s error was to rule out a heart attack because the patient appeared to be a model of health and fitness. “You have to be prepared in your mind for the atypical and not so quickly reassure yourself, and the patient, that everything is okay,” the doctor later mused.10 ([Location 619](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=619))
    - Tags: [[pink]] 
- The availability heuristic, judging the frequency or probability of an event based on what is readily available in memory, poses a related challenge. We tend to give too much weight to the probability of something if we have seen it recently or if it is vivid in our mind. Groopman tells of a woman who came to the hospital suffering from a low-grade fever and a high respiratory rate. Her community had recently experienced a wave of viral pneumonia, creating mental availability for the physician. He diagnosed her as having a subclinical case, suggesting she had the pneumonia but that the symptoms had yet to surface. Instead, it turned out she had a case of aspirin toxicity. She had taken too many aspirin in an attempt to treat a cold, and her fever and respiratory rate were classic symptoms. But the doctor overlooked them because of the vividness of the viral pneumonia. Like representativeness, availability encourages us to ignore alternatives.11 Think carefully about how the representativeness and availability heuristics may impose on your decisions. Have you ever judged someone solely based on how he or she looks? Have you ever feared flying more after hearing of a plane crash? If the answer is yes, you are a normal human. But you also risk misunderstanding, or missing altogether, plausible outcomes. ([Location 629](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=629))
    - Tags: [[pink]] 
- Cognitive dissonance is one facet of our next mistake, the rigidity that comes with the innate human desire to be internally and externally consistent.14 Cognitive dissonance, a theory developed in the 1950s by Leon Festinger, a social psychologist, arises when “a person holds two cognitions—ideas, attitudes, beliefs, opinions—that are psychologically inconsistent.”15 The dissonance causes mental discomfort that our minds seek to reduce. ([Location 661](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=661))
    - Tags: [[pink]] 
- While cognitive dissonance is about internal consistency, the confirmation bias is about external consistency. The confirmation bias occurs when an individual seeks information that confirms a prior belief or view and disregards, or disconfirms, evidence that counters it.19 Robert Cialdini, a social psychologist at Arizona State University, notes that consistency offers two benefits. First, it permits us to stop thinking about an issue, giving us a mental break. Second, consistency frees us from the consequence of reason—namely, changing our behavior. The first allows us to avoid thinking; the second to avoid acting.20 ([Location 698](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=698))
    - Tags: [[pink]] 
- The study of political partisans shows the large role that attention plays in tunnel vision. Paying a lot of attention to one thing means you are not paying a lot of attention to others, often creating a form of blindness. Every year, I show a video to my class that demonstrates this phenomenon. Daniel Simons and Christopher Chabris, psychologists who study perception, created the now famous thirty-second video that shows two teams, one wearing white shirts and the other black, in a nondescript lobby. Each team passes a basketball back and forth. I ask the students to count the number of passes the white team makes, which is somewhat challenging because the players move around. Of course, the students know there’s some trick, so they concentrate their attention on the task. There is a trick. Roughly halfway through the video, a woman wearing a gorilla suit walks into the middle of the scene, thumps her chest, and walks off. Less than 60 percent of students concentrating on the challenging visual task notice the gorilla (see figure 2–4). I then rerun the video and ask the students to watch it unencumbered by the task. There are always nervous chuckles when the gorilla makes her appearance. My results are very consistent with what other experimenters report. Let’s face it: we all have finite attention bandwidths. If you dedicate all that bandwidth to one task, none is left over for anything else. So people should be alert to striking a balance between nitty-gritty problem solving and a broader context.25 There’s something else that contributes to tunnel vision, and it’s something we can all relate to in varying degrees—stress. Like a lot of things in life, a little bit of stress (or a lot for a very short time) is a good thing. But too much ([Location 728](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=728))
    - Tags: [[pink]] 
- stress can muddle our thinking by clipping our ability to think long term. Stress is often very helpful. The classic stress response mobilizes energy to your muscles by increasing your heart rate, blood pressure, and breathing. High stress also helps your sensory system. For example, policemen report that during shootouts their visual acuity and focus improves, they sense a slowdown in time, and they fail to hear sounds. For a short burst, the mind can focus intently on the task at hand. This reaction is valuable in extraordinary circumstances.26 Stress is bad, however, if it is constant. Animals have a stress response when they are faced with physical threats—imagine a lion is chasing a zebra—but calm down once the threat passes. While humans are periodically threatened physically, most of our stress comes from the emotional strains of job deadlines, financial worries, and relationship issues. Crucially, the stress response is the same whether it comes from physical or psychological provocation. And, unlike most of the animal kingdom, we can experience chronic psychological stress. Events turn on our stress response system and we can’t turn it off. While mobilizing your body to respond to a short-term threat is an amazing feat, the same response is deeply detrimental to your health if it is always on. ([Location 741](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=741))
    - Tags: [[pink]] 
- Robert Sapolsky, a neurobiologist at Stanford University and an expert on stress, notes that an important feature of the stress response is that it turns off long-term systems. You need not worry about your digestion, growth, disease prevention, or reproduction if you are about to be a lion’s lunch. The stress response is, in Sapolsky’s words, “penny-wise and dollar foolish.” And this plays into tunnel vision. Stressed people struggle to think about the long term. The manager about to lose her job tomorrow has little interest in making a decision that will make her better off in three years. Psychological stress creates a sense of immediacy that inhibits consideration of options with distant payoffs. The stress response, so effective for dealing with here-and-now risks, co-opts the decision-making apparatus and compels poor decisions.27 ([Location 757](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=757))
    - Tags: [[pink]] 
- How do you avoid the tunnel vision trap? Here’s a five-point checklist: Explicitly consider alternatives. As Johnson-Laird’s model of reasoning suggests, decision makers often fail to consider a sufficient number of alternatives. You should examine a full range of alternatives, using base rates or market-derived guidelines when appropriate to mitigate the influence of the representativeness or availability biases. ([Location 804](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=804))
    - Tags: [[pink]] 
- To this end, negotiation teachers suggest entering talks knowing your best alternative to a negotiated agreement, your walkaway price, and the same two sums for the party across the table. These figures allow you to improve the odds of an advantageous deal and to avoid being surprised. In other settings, too, enumerating your alternatives clearly and completely is very helpful.32 Seek dissent. Much easier said than done, the idea is to prove your views wrong. There are a couple of techniques. The first is to ask questions that could elicit answers that might contradict your own views. Then listen carefully to the answers. Do the same when canvassing data: look for reliable sources that offer conclusions different than yours. This helps avoid a foolish inconsistency.33 When possible, surround yourself with people who have dissenting views. This is emotionally and intellectually very difficult, but is highly effective in exposing alternatives. It also reduces the risk of group think, when group members try to reach consensus with minimal conflict by avoiding testing alternative ideas. Abraham Lincoln embodied this approach. After his unlikely ascent to the White House, Lincoln appointed a number of his eminent foes to cabinet positions. He ended up winning the respect of his former adversaries, as his team of rivals navigated the United States through the Civil War.34 ([Location 807](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=807))
    - Tags: [[pink]] 
- Keep track of previous decisions. We humans have an odd tendency: once an event has passed, we believe we knew more about the outcome beforehand than we really did. This is known as hindsight bias. The research shows people are unreliable in recalling how an uncertain situation appeared to them before finding out the results. My family was driving to the airport to catch a flight for a vacation. We could have gone either on Interstate 95 or on the Merritt Parkway, two roughly equivalent routes. I listened to the traffic report, heard both were clear, and picked Interstate 95. A few minutes later, we ran into traffic caused by an accident. After clearing the traffic, we dashed to the airport, only to narrowly miss our flight. My wife turned to me and in an exasperated tone said, “I knew we should have taken the Merritt.” As Søren Kierkegaard, the Danish philosopher said, “Life must be understood backwards …But it must be lived—forwards.”35 So we generally fail to consider enough alternatives looking forward and think we knew what was… ([Location 819](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=819))
    - Tags: [[pink]] 
- Avoid making decisions while at emotional extremes. Making decisions under ideal conditions is tough enough, but you can be sure your decision-making skills will rapidly erode if you are emotionally charged. Stress, anger, fear, anxiety, greed, and euphoria are all mental states antithetical to quality decisions. But just as it’s hard to make good decisions during emotional upheaval, it’s also hard to make good decisions in the absence of emotion. Antonio Damasio, a neuroscientist, suggests that “our reason can operate most efficiently” when we have some emotional poise. Whenever possible, try to postpone important decisions if you feel at an emotional extreme.36 Understand incentives. Consider carefully what incentives exist, and what behaviors the incentives might motivate. Financial incentives are generally easy to spot, but nonfinancial incentives, like reputation or fairness, are less obvious yet still important in driving decisions. While few of us believe that incentives distort our decisions, the… ([Location 829](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=829))
    - Tags: [[pink]] 
- many cases, the most obvious choice is the right choice. But in a world that presents more alternatives than it used to, tunnel vision can lead to substantial but entirely avoidable mistakes. Here again, you need not labor over every decision. Rather, when the stakes are sufficiently high, ask whether you are susceptible to tunnel vision. If so, scrutinize your… ([Location 839](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=839))
    - Tags: [[pink]] 
- The night-and-day contrast between the quality of advice from Netflix’s algorithms and the local video-store clerk illustrates this chapter’s first decision mistake: using experts instead of mathematical models. This mistake, I admit, is hard to swallow and is a direct affront to experts of all stripes. But it is also among the best documented findings in the social sciences. In 1954, Paul Meehl, a psychologist at the University of Minnesota, published a book that reviewed studies comparing the clinical judgment of experts (psychologists and psychiatrists) with linear statistical models. He made sure the analysis was done carefully so he could be confident that the comparisons were fair. In study after study, the statistical methods exceeded or matched the expert performance.16 More recently, Philip Tetlock, a psychologist at the University of California, Berkeley, completed an exhaustive study of expert predictions, including twenty-eight thousand forecasts made by three hundred experts hailing from sixty countries over fifteen years. Tetlock asked the experts to predict political and economic outcomes, probabilistic fields with wide ranges of outcomes. Summarizing his results, Tetlock stated flatly, “It is impossible to find any domain in which humans clearly outperformed crude extrapolation algorithms, less still sophisticated statistical ones.”17 Despite this decades-old and well-substantiated evidence, the practice of relying on experts in a wide range of domains has changed very little. The fact is most people have difficulty assimilating broad statistical evidence into the judgment at hand. When you face a decision, ask yourself whether you would rather get your next recommendation from Cinematch or the guy behind the videostore counter. You now know where you are most likely to get the most viewing pleasure. ([Location 981](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=981))
    - Tags: [[pink]] 
- The Best Buy example, where a collection of partially informed nonexperts did better than experts, shows our second decision mistake: relying on experts instead of the wisdom of crowds. Understanding why collectives are often wise—and sometimes very unwise—requires us to look under the hood at how the wisdom of crowds works. But before proceeding, give the question some thought. How is it that a group of nonexperts can predict better than the resident expert? Scott Page, a social scientist who has studied problem solving by groups, offers a very useful approach for understanding collective decision making. He calls it the diversity prediction theorem, which states:18 Collective error = average individual error − prediction diversity The theorem uses squared errors as an accuracy measure, which researchers in the social sciences and statistics commonly employ because it assures that negative and positive errors do not cancel out.19 The average individual error captures the accuracy of the individual guesses. You can think of it as a measure of ability. Prediction diversity reflects the dispersion of guesses, or how different they are. The collective error, of course, is simply the difference between the correct answer and the average guess. Page discusses the diversity prediction theorem in depth in his book The Difference, and provides numerous examples of the theorem in action. I illustrate the diversity prediction theorem by asking students to guess the number of jellybeans in a jar and showing them the collective error, average individual error, and the prediction diversity. For example, one year the average guess of the students was 1,151 jellybeans when the actual number was 1,116, an error of approximately 3 percent. The average individual was off by about 700 beans (and the guesses did not fall along a bell-shaped distribution). But the diversity was high enough to offset most of the individual errors, leaving a small collective error. The diversity prediction theorem tells us that a diverse crowd will always predict more accurately than the average person in the crowd. Not sometimes. Always. This suggests that modesty is in order, but most people do not think of themselves as average—and certainly not as below average. Yet in reality, half of all people must be below average, and so you should sort out when you are likely to be one of them. Also important is that collective accuracy is equal parts ability and diversity. You can reduce the collective error either by increasing ability or by increasing diversity. Both ability and diversity are essential. This implication is relevant for gauging the health of markets or building a successful team.20 ([Location 996](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=996))
    - Tags: [[pink]] 
- Finally, while not a formal implication of the theorem, the collective is often better than even the best individual. So a diverse collective always beats the average person and frequently beats everyone. In the jellybean experiment, just two of the seventy-three students did better than the consensus. This is not good news for experts and deeply humbling for all decision makers. With the diversity prediction theorem in hand, we can flesh out when crowds predict well. Three conditions must be in place: diversity, aggregation, and incentives. Each condition clicks into the equation. Diversity reduces the collective error. Aggregation assures that the market considers everyone’s information. Incentives help reduce individual errors by encouraging people to participate only when they think they have an insight. Clearly, collectives cannot solve all problems. If your plumbing is in need of repair, you are better off… ([Location 1018](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1018))
    - Tags: [[pink]] 
- Intuition therefore works well in stable environments, where conditions remain largely unchanged (e.g., the chess board and pieces), where feedback is clear, and where cause-and-effect relationships are linear. ([Location 1045](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1045))
    - Tags: [[pink]] 
- TONY, A MIDDLE-AGED MAN with his glasses perched on the end of his nose, was the last to answer. He had a furrowed brow and appeared nervous. “Same,” he replied without conviction. With that incorrect response, Tony added evidence to one of the most famous social psychology experiments—Solomon Asch’s study of conformity under group pressure. Asch first ran these experiments in the 1940s. He assembled a group of eight people. Unbeknownst to the true subject, seven of the participants were accomplices. Asch asked them to complete the trivial task of matching the length of a given line with one of three unequal lines. The procedure was simple, and the answers were virtually errorfree in the control rounds. Asch then launched the experiment, cueing the confederates to give the wrong answer to see how the subject, who answered last, would respond. While some did remain independent, about one-third of the subjects conformed to the group’s incorrect judgment.1 The experiment showed that group decisions, even obviously poor ones, influence our individual decisions. References to Asch’s experiment are common, and most people who discuss it are satisfied to point out the degree of conformity. But the real question is: what’s going on in the heads of people who conform? Asch wondered this, too. Based on close observation, he suggested three descriptive categories to explain the conforming behavior: Distortion of judgment. These subjects conclude that their perceptions are wrong and that the group is right. Distortion of action. These individuals suppress their own knowledge in order to go with the majority. Distortion of perception. This group is not aware that the majority opinion distorts their estimates. Asch recognized that figuring out why people conform is as important as the observation that they do conform. But given the available tools, he had no concrete method for figuring out the mental processes behind conformity. ([Location 1120](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1120))
    - Tags: [[pink]] 
- The heart of this chapter’s message is that our situation influences our decisions enormously. The mistakes that follow are particularly difficult to avoid because these influences are largely subconscious. Making good decisions in the face of subconscious pressure requires a very high degree of background knowledge and self-awareness. ([Location 1166](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1166))
- People around us also influence our decisions, often with good reason. Social influence arises for a couple of reasons. The first is asymmetric information, a fancy phrase meaning someone knows something you don’t. In those cases, imitation makes sense because the information upgrade allows you to make better decisions. Peer pressure, or the desire to be part of the in-group, is a second source of social influence. For good evolutionary reasons, humans like to be part of a group—a collection of interdependent individuals—and naturally spend a good deal of time assessing who is “in” and who is “out.”7 Experiments in social psychology have repeatedly confirmed this. Researchers have done the Asch experiment over a hundred times in nearly twenty countries and have found similar conformity levels across geographies. Of course, conformity is also at the core of the diversity breakdowns that lead to unhealthy crowd behavior. ([Location 1172](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1172))
    - Tags: [[pink]] 
- Lee Ross, a social psychologist at Stanford University, coined the term “fundamental attribution error” to describe the tendency to explain behavior based on an individual’s disposition versus the situation. We naturally associate bad behavior with poor character, except when we assess our own behavior. We more readily explain our own poor behavior as a reflection of the social circumstances.8 ([Location 1179](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1179))
    - Tags: [[pink]] 
- This experiment is an example of priming, which psychologists formally define as “the incidental activation of knowledge structures by the current situational context”12 In other words, what comes in through our senses influences how we make decisions, even when it seems completely irrelevant in a logical sense. Priming is by no means limited to music. Researchers have manipulated behavior through exposure to words, smells, and visual backgrounds. ([Location 1214](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1214))
    - Tags: [[pink]] 
- For priming to work, the association must be sufficiently strong and the individual must be in a situation where the association sparks behavior. ([Location 1231](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1231))
    - Tags: [[pink]] 
- They convincingly argue that we can easily nudge people toward a particular decision based solely on how we arrange the choices for them. ([Location 1243](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1243))
    - Tags: [[pink]] 
- The central idea is called affect, or how the positive or negative emotional impression of a stimulus influences decisions. The basic concept is that how we feel about something influences how we decide about it. Affective responses occur quickly and automatically, are difficult to manage, and remain beyond our awareness. As Robert Zajonc, a social psychologist, said, “In many decisions affect plays a more important role than we are willing to admit. We sometimes delude ourselves that we proceed in a rational manner and weigh all the pros and cons of the various alternatives. But this is probably seldom the case. Quite often ‘I decided in favor of X’ is no more than ‘I liked X.’ ”19 Affect is situational ([Location 1265](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1265))
    - Tags: [[pink]] 
- Affect research reveals two core principles related to probabilities and outcomes. First, when the outcomes of an opportunity are without potent affective meaning, people tend to overweight probabilities. As a case in point, Paul Slovic, a psychology professor at the University of Oregon, asked one group to rate a system to save 150 lives and a separate group to rate a system expected to save 98 percent of 150 lives. Even though saving 150 lives is clearly better, the 98 percent option received a much higher rating. The reason is that the first group found little affective value in the 150 sum. On the other hand, 98 percent, close to the ideal of 100 percent, was affectively stronger. Therefore, the probability took center stage in the rating.21 In contrast, when outcomes are vivid, people pay too little attention to the probabilities and too much to the outcomes. For example, lottery players have the same feeling whether the probability of winning is one in ten million or one in ten thousand because the payoff is so large and carries so much affective meaning. This probability insensitivity is why individuals simultaneously play the lottery and buy insurance: the valence of the lottery gains or property losses swamps the associated probabilities of winning or losing. ([Location 1272](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1272))
    - Tags: [[pink]] 
- Zimbardo explains the factors that make the situation so forceful. First, situational power is most likely in novel settings, where there are no previous behavioral guidelines. Second, rules—which may emerge through interaction or be predetermined—can create a means to dominate and suppress others because people justify their behavior as only conforming to the rules. Third, when people are asked to play a certain role for a prolonged period, they risk becoming actors who can’t break from character. Roles shut people off from their normal lives and accommodate behaviors they would generally avoid. Finally, in situations that lead to negative behavior, there is often an enemy—an outside group. This is especially pronounced when both the in-group and out-group stop focusing on individuals.25 Zimbardo ends The Lucifer Effect, his book on situational power, on an encouraging note, offering tips for resisting the pull of unwelcome social influence. At their core, most of the recommendations have the same message: be mindful of what is going on around you. ([Location 1305](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1305))
    - Tags: [[pink]] 
- Inertia, or resistance to change, also shows how the situation shapes real-world decisions. A common answer to “Why do we do it this way?” is “We’ve always done it this way.” Individuals and organizations perpetuate poor practices even when their original usefulness has disappeared or better methods have surfaced. The situation keeps people from taking a fresh look at old problems. ([Location 1314](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1314))
    - Tags: [[pink]] 
- Here are some ideas to help you cope with the power of the situation: ([Location 1355](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1355))
    - Tags: [[pink]] 
- Be aware of your situation. You can think of this in two parts. There is the conscious element, where you can create a positive environment for decision making in your own surroundings by focusing on process, keeping stress to an acceptable level, being a thoughtful choice architect, and making sure to diffuse the forces that encourage negative behaviors. Then there is coping with the subconscious influences. Control over these influences requires awareness of the influence, motivation to deal with it, and the willingness to devote attention to address possible poor decisions. In the real world, satisfying all three control conditions is extremely difficult, but the path starts with awareness.29 Consider the situation first and the individual second. This concept, called attributional charity, insists that you evaluate the decisions of others by starting with the situation and then turning to the individuals, not the other way around. While easier for Easterners than Westerners, most of us consistently underestimate the role of the situation in assessing the decisions we see others make. Try not to make the fundamental attribution error.30 Watch out for the institutional imperative. Warren Buffett, the celebrated investor and chairman of Berkshire Hathaway, coined the term institutional imperative to explain the tendency of organizations to ([Location 1356](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1356))
    - Tags: [[pink]] 
- “mindlessly” imitate what peers are doing. There are typically two underlying drivers of the imperative. First, companies want to be part of the in-group, much as individuals do. So if some companies in an industry are doing mergers, chasing growth, or expanding geographically, others will be tempted to follow. Second are incentives. Executives often reap financial rewards by following the group. When decision makers make money from being part of the crowd, the draw is nearly inescapable.31 One example comes from a Financial Times interview with the former chief executive officer of Citigroup Chuck Prince in 2007, before the brunt of the financial crisis. “When the music stops, things will be complicated,” offered Prince, demonstrating that he had some sense of what was to come. “But as long as the music is playing, you’ve got to get up and dance.”32 The institutional imperative is rarely a good dance partner. Avoid inertia. Periodically revisit your processes and ask whether they are serving their purpose. Organizations sometimes adopt routines and structures that become crystallized, impeding positive change. Efforts to reform education in the United States, for example, have been met with resistance from teachers and administrators who prefer the status quo. ([Location 1367](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1367))
    - Tags: [[pink]] 
- Let’s define a complex adaptive system and explain why it flummoxes observers. You can think of a complex adaptive system in three parts (see figure 5-1).5 First, there is a group of heterogeneous agents. These agents can be neurons in your brain, bees in a hive, investors in a market, or people in a city. Heterogeneity means each agent has different and evolving decision rules that both reflect the environment and attempt to anticipate change in it. Second, these agents interact with one another, and their interactions create structure—scientists often call this emergence. Finally, the structure that emerges behaves like a higher-level system and has properties and characteristics that are distinct from those of the underlying agents themselves. ([Location 1420](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1420))
    - Tags: [[pink]] 
- The inability to understand the system based on its components prompted Philip Anderson, a physicist and Nobel Prize winner, to draft the essay, “More Is Different.” Anderson wrote, “The behavior of large and complex aggregates of elementary particles, it turns out, is not to be understood in terms of the simple extrapolation of the properties of a few particles. Instead, at each level of complexity entirely new properties appear.”6 If you want to understand an ant colony, don’t ask an ant. It doesn’t know what’s going on. Study the colony. The problem goes beyond the inscrutable nature of complex adaptive systems. Humans have a deep desire to understand cause and effect, as such links probably conferred humans with evolutionary advantage.7 In complex ([Location 1430](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1430))
    - Tags: [[pink]] 
- adaptive systems, there is no simple method for understanding the whole by studying the parts, so searching for simple agent-level causes of system-level effects is useless. Yet our minds are not beyond making up a cause to relieve the itch of an unexplained effect.8 When a mind seeking links between cause and effect meets a system that conceals them, accidents will happen. ([Location 1436](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1436))
    - Tags: [[pink]] 
- Just as watching one bee won’t help you understand the hive’s behavior, listening to individual investors will give you scant insight into the market.10 ([Location 1447](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1447))
    - Tags: [[pink]] 
- Regrettably, this mistake also shows up in behavioral finance, a field that considers the role of psychology in economic decision making. Behavioral finance enthusiasts believe that since individuals are irrational—counter to classical economic theory—and markets are made up of individuals, then markets must be irrational. This is like saying, “We have studied ants and can show that they are bumbling and inept. Therefore, we can reason that ant colonies are bumbling and inept.” But that conclusion doesn’t hold if more is different—and it is. Market irrationality does not follow from individual irrationality. You and I both might be irrationally overconfident, for example, but if you are an overconfident buyer and I am an overconfident seller, our biases may cancel out. In dealing with systems, the collective behavior matters more. You must carefully consider the unit of analysis to make a proper decision. ([Location 1455](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1455))
    - Tags: [[pink]] 
- When you are dealing with a system that has lots of interconnected parts, tweaking one part can have unforeseen consequences for the whole. ([Location 1463](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1463))
    - Tags: [[pink]] 
- First, our modern world has more interconnected systems than before. So we encounter these systems with greater frequency and, most likely, with greater consequence. Second, we still attempt to cure problems in complex systems with a naïve understanding of cause and effect. ([Location 1485](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1485))
    - Tags: [[pink]] 
- What should you do when you find yourself dealing with a complex adaptive system? Here are some thoughts that may help your decision making: ([Location 1517](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1517))
    - Tags: [[pink]] 
- Consider the system at the correct level. Remember the phrase “more is different.” The most prevalent trap is extrapolating the behavior of individual agents to gain a sense of system behavior. If you want to understand the stock market, study it at the market level. Consider what you see and read from individuals as entertainment, not as education. Similarly, be aware that the function of an individual agent outside the system may be very different from that function within the system. For instance, mammalian cells have the same metabolic rates in vitro, whether they are from shrews or elephants. But the metabolic rate of cells in small mammals is much higher than the rate of those in large mammals. The same structural cells work at different rates, depending on the animals they find themselves in.21 Watch for tightly coupled systems. A system is tightly coupled when there is no slack between items, allowing a process to go from one stage to the next without any opportunity to intervene. Aircraft, space missions, and nuclear power plants are classic examples of complex, tightly coupled systems. Engineers try to build in buffers or redundancies to avoid failure, but frequently don’t anticipate all possible contingencies.22 Most complex adaptive systems are loosely coupled, where removing or incapacitating one or a few agents has little impact on the system’s performance. For example, if you randomly remove some investors, the stock market will continue to function fine. But when the agents lose diversity and behave in a coordinated fashion, a complex adaptive system can behave in a tightly coupled fashion. Booms and crashes in financial markets are an illustration. ([Location 1519](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1519))
    - Tags: [[pink]] 
- Use simulations to create virtual worlds. Dealing with complex systems is inherently tricky because the feedback is equivocal, information is limited, and there is no clear link between cause and effect. Simulation is a tool that can help our learning process. Simulations are low cost, provide feedback, and have proved their value in other domains like military planning and pilot training.23 ([Location 1532](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1532))
    - Tags: [[pink]] 
- Complex adaptive systems often perform well at the system level, despite dumb agents (a point that both scientists and nonscientists often fail to grasp).26 Conversely, unintended consequences can lead to failure when well-meaning individuals attempt to manage the system to achieve a particular goal. So if you deal with a complex adaptive system, make sure you carefully set your system-level goal and proceed with caution in implementing agent-level changes for achieving your objective. ([Location 1551](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1551))
    - Tags: [[pink]] 
- Birth order effects do exist within a family and they do shape behavior. Older children alternate between dominating and nurturing their younger siblings, acting like proxies for parents. Younger children get relatively more parental attention and affection. So how can we at once accept that birth-order effects are real, while doubting Sulloway’s claims? The answer lies in considering context. While children assume birth-order roles within the family, they do not extend the roles outside the family. For instance, an oldest child who is domineering at home may show no such behavior on the playground at school. When parents or siblings complete self-report tests or assess a family member, birth-order effects show up clearly. But when outsiders like teachers or researchers observe behaviors, the birth-order effects melt away. Children—indeed people of all ages—do not behave the same under all conditions. They adjust their behavior to reflect their social circumstances. Just a couple of months after our youngest child started preschool, my wife and I got a potentially disturbing call from his teachers. They were worried about his verbal development because he barely uttered a word at school. The good news was that he followed his ([Location 1577](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1577))
    - Tags: [[pink]] 
- lessons and activities fine; the bad news was that he did not make a peep. My wife and I were less concerned than baffled. He is our fifth child and was from an early age the most verbal of the bunch—no doubt partly reflecting his personality and partly from coping with four older siblings. At home he was anything but quiet, but once he stepped into the classroom he turned off the verbal spigot. Fortunately, one of the teachers who had seen him at home assured the others that yes, the kid can talk, and talk plenty. Where Sulloway overreached was in arguing that behaviors at home shape behaviors everywhere. The facts simply do not stand behind this assertion. More specifically, studies consistently show that birth order has little or no effect on personality. Cécile Ernst and Jules Angst, Swiss psychologists, did the most comprehensive study of birth order and personality and concluded flatly that birth order and family size do not have a strong impact on personality. In a more recent paper, “Rebel Without a Cause or Effect: Birth Order and Social Attitudes,” a trio of sociologists found little or no support for Sulloway’s claims.5 The lesson from this debate is an example of this chapter’s theme: the importance of understanding context. Frequently, people try to cram the lessons or experiences from one situation into a different situation. But that strategy often crashes because the decisions that work in one context often fail miserably in another. The right answer to most ([Location 1587](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1587))
    - Tags: [[pink]] 
- questions that professionals face is, “It depends.” ([Location 1598](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1598))
    - Tags: [[pink]] 
- In the 1700s, Daniel Bernoulli’s study of fluid dynamics led to the airfoil, a shape that creates lift by creating decreased air pressure over the top of the wing relative to the air pressure under the wing. Rather than being correlated ([Location 1618](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1618))
    - Tags: [[pink]] 
- with flight, Bernoulli’s Principle shows what causes flight (improved classification and definition stages). The airfoil led to a new approach to flying. Once the Wright brothers combined this new theory with the physical materials and capabilities of stability, steering, and propulsion, the era of flight was born. Many management theories today look a lot more like feathers glued to wings than airfoils. Consultants, researchers, and practitioners often observe some successes, seek common attributes among them, and proclaim that those attributes can lead others to succeed. This simply does not work. You should be highly skeptical any time you see “the keys to success” or “formulas for winning.” ([Location 1620](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1620))
    - Tags: [[pink]] 
- Numerous scholars from varied disciplines have studied causation, and most agree that three conditions must hold to make a claim that X causes Y.16 The first is that X must occur before Y. The second is a functional relationship between X and Y, including the requirement that cause and effect take on two or more values. For example, the statement “smoking causes lung cancer” says that smoking increases the chances of lung cancer versus not smoking. So a scientist must consider all the relationships between the variables: does the person smoke (yes or no) and does the person have cancer (yes or no). Here, too, you must consider whether the relationship is merely happenstance. The final condition is that for X to cause Y, there cannot be a factor Z that causes both X and Y. For instance, watching too much television may correlate with obesity. But low socioeconomic status may explain both the television viewing and the weight problem.17 You must be very alert to the correlation-causality mistake. The fact that we like to make explicit cause-and-effect connections only adds to the challenge. When you hear of a causal connection, step carefully through the three conditions to see if the claim holds up. You will most likely be surprised at how ([Location 1740](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1740))
    - Tags: [[pink]] 
- rarely you can firmly establish causation. ([Location 1750](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1750))
    - Tags: [[pink]] 
- Changing the decision-making process as circumstances dictate is a fundamental challenge and can be psychologically taxing. Here are some thoughts on how you can make sure you are correctly considering circumstances in your decision making: ([Location 1770](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1770))
    - Tags: [[pink]] 
- Ask whether the theory behind your decision making accounts for circumstances. People frequently attempt to extrapolate successful choices from prior experiences to new situations, with predictably poor results. Flawed research that draws common attributes from organizations that have done well and offers those attributes as a general prescription for winning is also popular. Neither mistake properly considers decisions in context. One positive example is an exercise that Thomas Thurston, a former Intel employee, completed in 2006. Steeped in the theory of disruptive innovation, which is based on circumstances, Thurston reviewed almost fifty business plans that Intel’s new business initiatives group had funded. Applying the theory that specifies when innovations succeed, he was able to predict, without knowledge of the outcomes, a statistically significant 85 percent of successes and failures.19 Further, he was able to identify where some of the failed businesses had gone wrong. Thurston then teamed up with Clayton Christensen to teach the theory to business school students. Their first pass at sorting the winners and losers was close to random, but by the end of the semester the students sorted with over 80 percent accuracy. The progress shows the theory’s value and that the students can learn the lessons and improve performance. Watch for the correlation-and-causality trap. People have an innate desire to link cause and effect and are not beyond making up a cause for the effects they see. This creates the risk of observing a correlation—often the result of chance—and assuming causation. When you hear of a correlation, be sure to consider the three conditions: time precedence, relationship, and that no additional factor is causing the other two to correlate. Balance simple rules with changing conditions. Evolution provides a powerful argument for circumstance-based thinking. In evolution, the ability of an individual to survive and reproduce does not simply reflect specific attributes like size, color, or strength. Rather, the inherited characteristics that lead to survival and reproduction are inherently circumstantial. One approach to decision making—especially for rapidly changing environments—balances a handful of simple but definite rules with the prevailing conditions. For example, priority rules help managers rank the opportunities they identify, or exit rules tell them when to leave a business. The rules make sure that managers uphold certain core ideals while recognizing changing conditions, allowing for the requisite flexibility to decide properly.20 Remember there is no “best” practice in domains with multiple dimensions. While many people, especially Westerners, are keen to determine which organization is best, crowning a winner in a high-dimensionality realm makes no sense. One of the Colonel Blotto game’s main lessons is that under most circumstances, winning strategies are nontransitive: all players have strengths and weaknesses,… ([Location 1772](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1772))
    - Tags: [[pink]] 
- Most of us look forward to leveraging our favorable experiences by applying the same approach to the next situation. We also have a thirst for success formulas—key steps to enrich ourselves. Sometimes our experience and nostrums work, but more often they fail us.… ([Location 1807](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1807))
    - Tags: [[pink]] 
- guiding our decisions are based on attributes, not circumstances. Attribute-based theories come very naturally to us and often appear compelling, as we saw with the birth-order discussion. However, once you realize the answer to most questions is, “It depends,”… ([Location 1809](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1809))
    - Tags: [[pink]] 
- However, once you realize the answer to most questions is, “It depends,” you are ready to embark on the quest to… ([Location 1810](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1810))
    - Tags: [[pink]] 
- Feedback can be negative or positive, and within many systems you see a healthy balance of the two. Negative feedback is a stabilizing factor, while positive feedback promotes change. But too much of either type of feedback can leave a system out of balance. The classic illustration of negative feedback in markets is arbitrage. For instance, if the price of gold in London drifts a little above the price in New York, arbitrageurs will buy New York gold and sell London gold until they close the aberrant price gap. A more mundane example is your thermostat, which detects deviations from the temperature you set and sends instructions to return the temperature back to your desired level. Negative feedback resists change by pushing in the opposite direction. Positive feedback reinforces an initial change in the same direction. Imagine a school of fish or a flock of birds eluding a predator. They move in unison to avoid the threat. We also see positive feedback at work in fads and fashions, where people imitate one another. Positive feedback can explain bouts with Pet Rocks, the Macarena, and Pokémon cards. The focus of this chapter is phase transitions, where small incremental changes in causes lead to large-scale effects. Philip Ball, a physicist and writer, calls it the grand ah-whoom.4 Put a tray of water into your freezer and the temperature drops to the threshold of freezing. The water ([Location 1839](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1839))
    - Tags: [[pink]] 
- remains a liquid until—ah-whoom—it becomes ice. Just a small incremental change in temperature leads to a change from liquid to solid. The grand ah-whoom occurs in many complex systems where collective behavior emerges from the interaction of its constituent parts. You can find lots of these systems in the physical world, including water molecules and iron atoms. But the ideas also apply to the social world, even though the laws aren’t defined as clearly as they are in physics. Examples include everything from the behavior of stock exchanges to the popularity of hit songs. To be clear, in all these systems cause and effect are proportionate most of the time. But they also have critical points, or thresholds, where phase transitions occur. You can think of these points as occurring when one form of feedback overwhelms the other. When you don’t see it coming, the grand ah-whoom will surprise you.5 Let’s use the idea of a phase transition to answer the question that was scrawled on the sign at the Millennium Bridge. When you walk, your mass exerts a small amount of sideways force. These individual forces normally cancel out when a group crosses a stiff bridge, an example of negative feedback. However, the Millennium Bridge initially had insufficient lateral dampeners, allowing a little swaying when enough people were on the bridge. That swaying forced people to change their gait by widening their steps. The wider steps lead to greater sideways force and more swaying. The positive feedback caused the wobbling and synchronized crowd behavior to emerge simultaneously.6 ([Location 1850](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1850))
    - Tags: [[pink]] 
- The vital insight is the existence of a critical point. In December 2000, Arup engineers enlisted volunteers to walk on the bridge in order to determine the level at which the unsafe swaying would occur. Their test showed that 156 people could walk on the bridge with little impact (see figure 7-2). But adding just 10 more pedestrians caused the amplitude to change dramatically, as the positive feedback kicked in (see figure 7-2 right axis). For the first 156 people who crossed the bridge, there was little sway and no sense of any potential hazard, even though the bridge was on the cusp of a phase transition. This shows why critical points are so important for proper counterfactual thinking: considering what might have been.7 For every phase transition you do see, how many close calls were there? You can imagine testing the bridge with 50, 100, or even 150 people. The harmful… ([Location 1863](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1863))
    - Tags: [[pink]] 
- With lots of phenomena, including human heights and athletic results, the outcomes don’t stray too far from average. Take heights as an example. The tallest human on record grew to a height of 272 centimeters (8'11"), while the shortest was 57 centimeters (1'10"), a roughly five-to-one differential. Approximately 95 percent of people vary no more than 15 centimeters (about 6 inches) from the average height. Heights have a narrow and predictable range of outcomes. But there are systems with heavily skewed distributions, where the idea of average holds little or no meaning. These distributions are better described by a power law, ([Location 1876](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1876))
    - Tags: [[pink]] 
- which implies that a few of the outcomes are really large (or have a large impact) and most observations are small. Look at city sizes. New York City, with about 8 million inhabitants, is the largest city in the United States. The smallest town has about 50 people. So the ratio of the largest to the smallest is more than 150,000 to 1. Other social phenomena, like book or movie sales, show such extreme differences as well. City sizes have a much wider range of outcomes than human heights do.8 Nassim Taleb, an author and former derivatives trader, calls the extreme outcomes within power law distributions black swans. He defines a black swan as an outlier event that has a consequential impact and that humans seek to explain after the fact.9 In large part owing to Taleb’s efforts, more people are aware of black swans and distributions that deviate from the bell curve. What most people still don’t appreciate is the mechanism that propagates black swans. Here’s where critical points and phase transitions come in. Positive feedback leads to outcomes that are outliers. And critical points help explain our perpetual surprise at black swan events because we have a hard time understanding how such small incremental perturbations can lead to such large outcomes. We simply don’t see them coming because they are beyond what our minds expect. What is behind these critical points in social systems? One answer comes from studying the wisdom of crowds.10 Crowds tend to make accurate predictions when three conditions prevail—diversity, aggregation, and incentives. ([Location 1881](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1881))
    - Tags: [[pink]] 
- Diversity is about people having different ideas and different views of things. Aggregation means you can bring the group’s information together. Incentives are rewards for being right and penalties for being wrong that are often, but not necessarily, monetary. For a host of psychological and sociological reasons, diversity is the most likely condition to fail when humans are involved. But what’s essential is that the crowd doesn’t go from smart to dumb gradually. As you slowly remove diversity, nothing happens initially. Additional reductions may also have no effect. But at a certain critical point, a small incremental reduction causes the system to change qualitatively. Blake LeBaron, an economist at Brandeis University, has demonstrated this point for the stock market using an agent-based model. Instead of using real investors, LeBaron’s model created a thousand investors within the computer and gave them money, guidelines on allocating their portfolios, and diverse trading rules. Then he let them loose. His model was able to replicate many of the empirical features we see in the real world, including cycles of booms and crashes. But perhaps his most important finding is that a stock price can continue to rise… ([Location 1893](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1893))
    - Tags: [[pink]] 
- reinforced. This makes the population very brittle, in that a small reduction in the demand for shares could have a strong… ([Location 1905](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1905))
    - Tags: [[pink]] 
- The presence of phase transitions invites a few common decision-making mistakes. The first is the problem of induction, or how you should logically go from specific observations to general conclusions. Although philosophers, from Sextus Empiricus to David Hume, have for centuries warned against extrapolating from what we see, refraining from doing so is very difficult. To state the obvious, induction fails—sometimes spectacularly so—in systems with phase transitions. To illustrate the problem, Taleb retells Bertrand Russell’s story of a turkey that is fed a thousand days in a row. (Russell actually spoke of a chicken. Taleb changed it to a turkey for the American audience.)12 The feedings reinforce the turkey’s sense of security and well-being, until the day before Thanksgiving an unexpected event occurs. All the turkey’s experience and feedback is positive until fortune takes a turn for the… ([Location 1908](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1908))
    - Tags: [[pink]] 
- from 2007 to 2008 that were in excess of one-third of the profits it had earned cumulatively in its thirty-six years as a public company.13 Dealing with a system governed by a power law is like the farmer feeding us while he holds the axe behind his back. If you stick around long enough, the axe will fall. The question is not if, but when. The term black swan reflects the criticism of induction by the philosopher Karl Popper. Popper argued that seeing lots of white swans doesn’t prove the theory that all swans are white, but seeing one black swan does disprove it. So Popper’s point is that to understand a phenomenon, we’re better off focusing on falsification than on verification. But we’re not naturally inclined to falsify something. Karl Duncker, a psychologist, observed that when people use or think about something in a particular way they have great difficulty thinking about it in new ways. In a classic experiment, Duncker gave subjects a candle, a box of tacks, and a pack of matches. He then asked them to attach the candle to a wall so that it wouldn’t drip on the table below. The trick was to use the tack box as a platform, something few participants thought to do. Duncker argued that people fixate on an object’s normal function and could not conceptualize it differently. People… ([Location 1916](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1916))
    - Tags: [[pink]] 
- fact that phase transitions come with sudden change only adds to the confusion. Another mistake that we make when dealing with complex systems is what psychologists call reductive bias, “a tendency for people to treat and interpret complex circumstances and topics as simpler than they really are, leading to misconception.”14 When asked to decide about a system that’s complex and nonlinear, a person will often revert to thinking about a system that is simple and linear. Our minds naturally offer an answer to a related but easier question, often with costly consequences. Finance offers a great example of this bias. While empirical research from as early as the 1920s showed that changes in the price of assets do not follow a normal, bell-shaped distribution, economic theory still rests on that assumption. If you have ever heard a financial expert refer to the stock market using terms like alpha, beta, or standard deviation, you have witnessed reductive bias in action. Most economists characterize markets using simpler, but wrong, price-change distributions. A number of high-profile financial blowups, including Long-Term Capital Management, show the danger of this bias.15 Benoit Mandelbrot, a French mathematician and the father of fractal geometry,… ([Location 1928](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1928))
    - Tags: [[pink]] 
- Cootner, an economist at MIT and the editor of the volume, was unconvinced of Mandelbrot’s case. “If [Mandelbrot] is right,” he wrote, “almost all of our statistical tools are obsolete. Almost without exception, past econometric work is meaningless.”17 But Cootner could rest easy, because Mandelbrot’s ideas never penetrated mainstream economics. Philip Mirowski, a historian and philosopher of economic thought at Notre Dame, notes, “The simple historical fact is that [Mandelbrot’s economic ideas] have been by and large ignored, with some few exceptions… which seem to have been subsequently abandoned by their authors.”18 A few years ago, I went to a dinner in New York City that included Mandelbrot. I showed up late and saw just two seats free. Mandelbrot arrived shortly after me and explained that his tardiness was due to an incompetent driver, whom he fired. Mandelbrot then leaned over and asked, “Would you mind giving me a ride home?” I fretted for the rest the dinner, wondering what I could possibly say to this remarkable man forty years my senior during an hour-long drive to the suburbs. As he slipped into the passenger seat, I decided to ask him about the history of reductive bias in finance. He was very gracious, albeit frustrated that the… ([Location 1941](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1941))
    - Tags: [[pink]] 
- the future, he was sure that the simple models of the economists would not anticipate it. Well, it didn’t take long. The financial crisis of 2007–2009 had a lot of moving parts but near the center was a little-known formula developed by David Li, a statistician and mathematician. The equation deals with the tricky challenge of measuring the correlation of default between assets. (The formula is known as a Gaussian copula function.) Correlation is crucial in diversifying a portfolio and, hence, in managing risk. For example, consider two potential investments: Umbrella Corp. and Picnic Basket Inc. If the weather is inclement, Umbrella Corp.’s stock goes up and Picnic Basket Inc.’s stock goes down. Of course, nice weather leads to the opposite market reaction. Because the performance of the stocks is not correlated, you’ll be diversified if you own both no matter the weather. But if the stocks become correlated—they both go up or down at the same time for whatever reason—you’ll be exposed to more risk than you thought. The promise of Li’s equation was that it could, with a single number, measure the likelihood that two or more assets within a portfolio would default at the same time. This opened the floodgates for new products… ([Location 1953](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1953))
    - Tags: [[pink]] 
- about the details of how each corporate bond within the pool would behave. While market participants described the formula as “beautiful, simple, and tractable,” it had a fatal flaw because correlations change. Consistent with reductive bias, the equation was based on an uncomplicated, stable world but was applied in a complex, dynamic world. As is often the case, default correlations rise when the economy turns south. The failure of Long-Term Capital Management illustrates how changing correlations can wreak havoc. LTCM observed that the correlation between its diverse investments was less than 10 percent over the prior five years. To stress test its portfolio, LTCM assumed that correlations could rise to 30 percent, well in excess of anything the historical data showed. But when the financial crisis hit in 1998, the correlations soared to 70 percent. Diversification went out the window, and the fund suffered mortal losses. “Anything that relies on correlation is charlatanism,” scoffed Taleb. Or, as I’ve heard traders say, “The only thing that goes up in a bear market is correlation.”19 The final mistake in dealing with phase transitions is the belief in prediction. Ours is the only world we know. But it is… ([Location 1965](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=1965))
    - Tags: [[pink]] 
- Here are some tips on how to cope with systems that have phase transitions: Study the distribution of outcomes for the system you are dealing with. Thanks to Taleb’s prodding, many people now associate extreme events with black swans. But Taleb makes a careful, if overlooked, distinction: if we understand what the broader distribution looks like, the outcomes—however extreme—are correctly labeled as gray swans, not black swans. He calls them “modelable extreme events.” In fact, scientists have done a lot of work classifying the distributions of various systems, including the stock market, terrorist acts, and power-grid failures.25 So if you have the background and tools to understand these systems, you can get a general view of how the system behaves, ([Location 2033](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2033))
    - Tags: [[pink]] 
- even if you have no reliable means of predicting any specific event. The key is to properly prepare for whatever the system metes out, extreme or not. For the most part, people are scorched not by black swans, the unknown unknowns, but rather by their failure to prepare for gray swans. Look for ah-whoom moments. As the discussion about the Millennium Bridge and the wisdom of crowds revealed, big changes in collective systems often occur when the system actors coordinate their behavior. Think of the dot-com boom of the late 1990s or the economic mess of 2007–2009. While a reduction in diversity does not guarantee a system change (although it does invoke invisible vulnerability), it substantially raises the probability. Coordinated behavior is at the core of many asymmetric outcomes, including favorable (best-selling books, venture capital) and unfavorable (national security, lending) outcomes. Be mindful of the level of diversity and recognize that state changes often come suddenly. Beware of forecasters. Humans have a large appetite for forecasts and predictions across a broad spectrum of domains. People must recognize that the accuracy of forecasts in systems with phase transitions is dismal, even by so-called experts. Watts says, “We think there is something we can call quality… and the results we see in the world reflect this quality.” But, he added, “I am comfortable with the idea that the outcomes we ([Location 2039](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2039))
    - Tags: [[pink]] 
- get are often largely arbitrary.”26 The best course is to recognize the nature of the distribution and to prepare for all contingencies. Mitigate the downside, capture the upside. One common and conspicuous error in dealing with complex systems is betting too much on a particular outcome. In the 1950s, John Kelly, a physicist at Bell Labs, developed a formula for optimal betting strategy based on information theory. The Kelly formula tells you how much to bet, given your edge. One of the Kelly formula’s central lessons is that betting too much in a system with extreme outcomes leads to ruin. Betting too much explains the demise of many large financial institutions, including American International Group (AIG), which implicitly failed to consider extreme outcomes. For example, AIG, a large and profitable insurance company, moved aggressively into the derivatives business in order to improve profits. A sizable percentage of the business included selling insurance against defaults on assets tied to corporate debt and mortgage securities. When the market plunged in 2008, AIG was unable to meet its financial commitments and had to be bailed out by the U.S. government. And… ([Location 2050](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2050))
    - Tags: [[pink]] 
- the financial instruments that we see in the market that are tied to extreme events are often mispriced.28 In the end, the admonishment of investment legend Peter Bernstein should carry the day: “Consequences are more important than probabilities.” This does not mean you should focus on outcomes instead of… ([Location 2061](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2061))
    - Tags: [[pink]] 
- This chapter will offer you a fresh perspective for interpreting your own team’s winning streaks and slumps—or, for that matter, the performance of employees, business units, stockbrokers, and other professionals as individuals and groups. ([Location 2081](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2081))
    - Tags: [[pink]] 
- Francis Galton, cousin of Charles Darwin, was a Victorian polymath who liked to count things. Curious about a broad range of topics including evolution, psychology, and meteorology, he brought an empiricist’s discipline to testing his ideas. During his life, he gathered and analyzed a huge amount of data. Through a process of inquiry and investigation, Galton discovered the phenomenon of reversion to the mean, a towering achievement in statistics. ([Location 2084](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2084))
    - Tags: [[pink]] 
- The idea is that for many types of systems, an outcome that is not average will be followed by an outcome that has an expected value closer to the average. While most people recognize the idea of reversion to the mean, they often ignore or misunderstand the concept, leading to a slew of mistakes in their analysis.2 Galton’s interest in this topic started with the idea that genius was inherited. He noticed that geniuses—musicians, artists, scientists—were way above the average, and that while their children were above the average, they were closer to it. Genius, however, was hard to measure. So Galton turned to something he could measure: sweet peas. He separated sweet pea seeds by size and showed that while the offspring tended to resemble the parent seed, their average size was closer to the mean of the full population.3 While normal, or bell-shaped, distributions were well known at that time, thinkers of the day generally assumed that the distributions were the result of a large number of small errors around an average. For instance, numerous scientists might make an estimate of a planet’s position. Each estimate captures the position with some error, reflecting imperfect instruments or calculation. If those errors are as likely to be in one direction as another, they will cancel out, and the average of the estimates will be the planet’s true position. But the theory of errors could not explain Galton’s findings. He recognized there had to be a different mechanism at work. Heredity clearly played an important role in determining the size of the peas; it wasn’t simply that errors were distributed around some sort of universal average. So Galton rolled up his sleeves and embarked on a detailed study of stature. Galton gathered the heights of four hundred parents and more than nine hundred of their grown children. He combined the heights of the mothers and fathers into… ([Location 2087](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2087))
    - Tags: [[pink]] 
- Galton’s significant insight was that, even as reversion to the mean occurs from one generation to the next, the overall distribution of heights remains stable over time. This combination sets a trap for people because reversion to the mean suggests things become more average over time, while a stable distribution implies things don’t change much. Fully grasping how change and stability go together is the key to understanding reversion to the mean.5 ([Location 2110](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2110))
    - Tags: [[pink]] 
- In many human endeavors, the outcomes are a combination of skill and luck. ([Location 2115](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2115))
    - Tags: [[pink]] 
- Naturally, the amount of influence that skill and luck will have depends on the activity. ([Location 2116](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2116))
    - Tags: [[pink]] 
- Yet even when a player’s skill doesn’t change, his luck will come and go. ([Location 2118](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2118))
    - Tags: [[pink]] 
- Any system that combines skill and luck will revert to the mean over time. Daniel Kahneman neatly captured this idea when he was asked to offer a formula for the twenty-first century. He actually provided two. Here’s what he submitted:7 Success = Some talent + luck Great success = Some talent + a lot of luck ([Location 2122](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2122))
    - Tags: [[pink]] 
- When you ignore the concept of reversion to the mean, you make three types of mistakes. The first mistake is thinking you’re special. I once met with a company’s senior management team and discussed my interpretation of reversion to the mean in corporate performance. The executives all nodded knowingly. Then the CEO chimed in, “Yes, we understand the idea of mean reversion well. But it doesn’t apply to us because we’ve figured out a better way to run our business.” If it were only so. ([Location 2130](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2130))
    - Tags: [[pink]] 
- In my research, I found that analysts on Wall Street ignore the effects of reversion to the mean when they build their models of a company’s future financial results. Analysts regularly neglect the evidence for reversion to the mean in considering essential drivers like company sales growth rates and levels of economic profitability.10 ([Location 2150](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2150))
    - Tags: [[pink]] 
- “Mediocrity tends to prevail in the conduct of competitive business,” wrote Horace Secrist, an economist at Northwestern University, in his 1933 book, The Triumph of Mediocrity in Business. With that stroke of the pen, Secrist became a lasting example of the second mistake associated with reversion to the mean—a misinterpretation of what the data says.11 Secrist’s book is truly impressive. Its four hundred-plus pages show mean-reversion in series after series in an apparent affirmation of the tendency toward mediocrity. My research gives an example of Secrist’s idea. Figure 8-3 shows how the spread between return on invested capital (ROIC) and cost of capital reverts to the mean for a sample of more than a thousand companies, broken into quintiles, over a decade (the figure tracks the median ROIC for each quintile). While contemporary, this picture would have fit comfortably inside Secrist’s text.12 Secrist’s book was warmly received for the most part, with the notable exception of a scathing review by Harold Hotelling, an economist and statistician at Columbia University. The problem, Hotelling pointed out, is “these diagrams really prove nothing more than the ratios in question have a tendency to wander about.”13 The best visual for understanding Hotelling’s criticism is figure 8-4. At the top is the distribution of ROICs for the sample in 1997. In the middle is the reversion to the mean from figure 8-3, and on the bottom is the distribution of ROICs for 2007. ([Location 2154](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2154))
    - Tags: [[pink]] 
- Note that the distribution on the top and bottom look very similar. ([Location 2165](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2165))
    - Tags: [[pink]] 
- In contrast to Secrist’s suggestion, there is no tendency for all companies to migrate toward the average or for the variance to shrink. Indeed, a different but equally valid presentation of the data shows a “movement away from mediocrity and [toward] increasing variation.”14 A more accurate view of the data is that over time, luck reshuffles the same companies and places them in different spots on the distribution. Naturally, companies that had enjoyed extreme good or bad luck will likely revert to the mean, but the overall system looks very similar through time. What if you ran the analysis of reversion to the mean from the present to the past instead of from the past to the present? Are the parents of tall children more or less likely to be taller than their children? A counterintuitive implication of mean reversion is that you get the same result whether you run the data forward or backward. So the parents of tall children tend to be tall, but not as tall as their children. Companies with high returns today had high returns in the past, but not as high as the present. Figure 8-5 illustrates this point by reversing the arrow of time. The quintiles are based on 2007 ROICs—and are therefore different from the quintiles in figure 8-3—and go back to 1997. The similarity to figure 8-3 is clear. FIGURE 8-5 ([Location 2172](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2172))
    - Tags: [[pink]] 
- Here’s how to think about it. Say results are part persistent skill and part transitory luck. Extreme results in any given period, reflecting really good or bad luck, will tend to be less extreme either before or after that period as the contribution of luck is less significant. ([Location 2186](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2186))
    - Tags: [[pink]] 
- More than forty years ago, Daniel Kahneman was asked to help flight instructors in the Israeli air force sharpen their training skills. After watching the instructors hurl obscenities at the trainees, Kahneman told the instructors about research with pigeons that demonstrated how positive feedback can motivate better… ([Location 2189](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2189))
    - Tags: [[pink]] 
- saying is for the birds.” The agitated instructor went on to explain that pilots almost always did worse on their next flight after praise and consistently did better after a tongue lashing. Initially taken aback, Kahneman soon realized that the instructor was committing our third mistake. The instructor believed that his insults caused the pilots to fly better. In reality, their performance was simply reverting to the mean. If a pilot had an unusually great flight, the instructor would be more likely to pay him a compliment. Then, as the pilot’s next flight reverted to the mean, the instructor would see a more normal performance and… ([Location 2191](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2191))
    - Tags: [[pink]] 
- The halo effect, first described in the 1920s by Edward Thorndike, a psychologist at Columbia University, is closely related to reversion to the mean and illustrates a fatal flaw in… ([Location 2201](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2201))
    - Tags: [[pink]] 
- halo effect is the human proclivity to make specific inferences based on… ([Location 2203](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2203))
    - Tags: [[pink]] 
- In The Halo Effect, Phil Rosenzweig showed that this mistake pervades the business world. Rosenzweig pointed out that we tend to observe financially successful companies, attach attributes (e.g., great leadership, visionary strategy, tight financial controls) to that success, and recommend that others embrace the attributes to achieve their own success. Researchers who study management often follow this formula and rarely recognize the role of luck in business performance. And the substantial data the researchers use to support their claims is all for nothing if they fall into the trap of the halo effect.17 For example, Rosenzweig suggests that the press will praise a company that is doing well for having “a sound strategy, a visionary leader, motivated employees, an excellent customer orientation, a vibrant culture, and so on.”18 But if the company’s performance subsequently reverts to the mean, onlookers will conclude all of… ([Location 2207](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2207))
    - Tags: [[pink]] 
- Rosenzweig shows in devastating fashion that most of the thinking from best-selling business books falls prey to the halo effect. These books are commercially successful, he suggests, because they tell managers a story they want to hear: any company can be successful by taking these steps. In fact, no simple formula ensures success in a rapidly changing business environment. ([Location 2237](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2237))
    - Tags: [[halo-effect]] 
- How do you avoid mistakes associated with reversion to the mean? Here’s a checklist that may help you identify important issues: Evaluate the mix of skill and luck in the system that you are analyzing. Discerning the contributions of skill and luck is rarely an easy task, even if analytical tools are available. 22 To make the thought more concrete, consider the continuum of games in table 8-1. On the left are complete-information games, where each player knows the positions, payoffs, and strategies available to his opponent. In these games, the outcomes are largely settled through skill. On the right are games based on luck, where skill plays no role. The middle games combine skill and luck. Here’s a simple test of whether an activity involves skill: ask if you can lose on purpose.23 Think about casino games like roulette or slots. Winning or losing is purely a matter of luck. It doesn’t matter what you do. But if you can lose on purpose, then skill is involved. This simple test reveals the role of luck in investing. While most people recognize that it is hard to construct a portfolio that beats the S&P 500, most people don’t know how hard it is to build a portfolio that will do a lot worse than the benchmark. ([Location 2251](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2251))
    - Tags: [[pink]] 
- You should therefore be careful when you draw conclusions about outcomes in activities that involve luck—especially conclusions about short-term results. We’re not very good at deciding how much weight to give to skill and to luck in any given situation. When something good happens, we tend to think it’s because of skill. When something bad happens, we write it off to chance. So forget about the outcome and concentrate instead on the process. Recognize, too, there is no lack of commentary about systems that are strongly influenced by chance. As the story of George Steinbrenner made us aware, luck plays an important role in baseball, especially in the short term. Yet baseball announcers analyze the games play-by-play with little awareness that luck explains most of what’s going on. This same principle applies in business and markets. Carefully consider the sample size. Daniel Kahneman and Amos Tversky established that people extrapolate unfounded conclusions from small sample sizes.24 But thinking clearly about sample size is essential for a few reasons. ([Location 2274](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2274))
    - Tags: [[pink]] 
- The more that luck contributes to the outcomes you observe, the larger the sample you will need to distinguish between skill and luck. Baseball is a good example. Over a 162-game season, chances are good the best teams will rise to the surface. In the short term, however, almost anything can happen. In Moneyball, Michael Lewis, an author who frequently provides fresh views on issues, points out, “In a five-game series, the worst team in baseball will beat the best about 15 percent of the time.”25 You do not see this in chess or tennis matches, games in which the best player almost always beats the worst, regardless of time frame. In addition, when a large number of people participate in an activity that is influenced by chance, some of them will succeed by sheer luck. So you have to scrutinize even long, successful track records in fields with lots of participants. Investment track records are a good example. Fans often misunderstand hot hands and streaks in games and sports. The term hot hand refers to the belief that success breeds success. We tend to believe that if a basketball player has made one shot, he is more likely to make the next one. Michael Bar-Eli, a professor of business at Ben-Gurion University, studies the psychological determinants of human performance, especially as they relate to sports. With some colleagues, Bar-Eli did a detailed review of hot-hand studies, concluding tepidly ([Location 2282](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2282))
    - Tags: [[pink]] 
- that “the empirical evidence for the existence of the hot hand is considerably limited.”26 This is not to say that players don’t have streaks of made or missed shots. Naturally, they do. The point is that these strings of successes and failures are consistent with the skill level of the player. For instance, a basketball player who makes 60 percent of her shots has about a 7.8 percent chance (0.6)5 of making five in a row. A player who makes 40 percent of his shots has only a 1 percent chance (0.4)5 of hitting five in a row. The best players have more streaks than the worst players, just as you would expect, given the statistics. Streaks, continuous success in a particular activity, require large doses of skill and luck. In fact, a streak is one of the best indicators of skill in a field. Luck alone can’t carry a streak. My analysis of various sports streaks in basketball and baseball clearly suggests streak holders are among the most skilled in their fields. Jerker Denrell, a professor of organizational behavior at Stanford Business School, has shown the link between the sample size and learning. In his paper, “Why Most People Disapprove of Me: Experience… ([Location 2293](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2293))
    - Tags: [[pink]] 
- Imagine trying a new restaurant with two possible outcomes. In the first case, the restaurant is at its best. You have a wonderful meal with attentive service at a reasonable price. Would you go back? In the second case, the restaurant has an off day. You have a so-so dinner with indifferent service at the high end of what you had hoped to pay. Would you go back? Most people would go back in the first case but not in the second. Given reversion to the mean, what’s likely to happen the second time you go to the restaurant? Chances are the meal won’t be quite as good, or the service will slip a bit. But in this case you have gathered a more accurate view of the restaurant, even if it’s less flattering. On the other hand, if you never return to the restaurant because of a bad experience, you are assured you will gather no additional information, even if that information—as reversion to the mean suggests—would be more favorable. So people tend to have a better picture of people and things they like than what they don’t like because they have a fuller sample. Watch for change within the system or of the system. Not all systems remain stable over time, so it’s important to consider how and… ([Location 2305](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2305))
    - Tags: [[pink]] 
- time as a consequence of diminished skill. Loss of skill naturally applies to other pursuits as well, including business and medicine. Further, the system itself may change. Stephen Jay Gould analyzed why baseball has not seen a player sustain a .400 batting average for a complete season since Ted Williams in 1941. After entertaining some possible explanations—none persuasive—Gould showed that while the mean batting average in the major leagues has been fairly stable over the years, the standard deviation has shrunk from roughly 32 percent in 1941 to about 27 percent today. The bell of the bell-shaped distribution has a narrower width than it used to. That the right side of the distribution is closer to average may explain the lack of.400 hitters. Gould attributed the reduction in standard deviation to a greater and more consistent overall skill level in the major leagues.28 Watch out for the halo effect. A whole cottage industry, including business school professors and consultants, is working hard to offer businesspeople tidy solutions for their problems. Here’s how you grow sales. Here’s how you innovate. Here’s how you manage your people. But any time… ([Location 2316](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2316))
    - Tags: [[pink]] 
- If you’re like me and want to find a cause for every effect, you should spend some time disentangling skill from luck. An appreciation of the relative contributions of skill and luck will allow you to think clearly about reversion to the mean. To me, the greatest lesson and opportunity from understanding reversion to the mean is to keep your cool. When outcomes are really good because of a dose of good luck, prepare for the times when they will be… ([Location 2327](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2327))
    - Tags: [[pink]] 
- IONCE ATTENDED a lecture series with a handful of colleagues.The topics, while fascinating, had a distinctly academic and abstract flavor. After the final talk, one of my coworkers sighed, “That was great, but what should I do differently tomorrow?” I’m not sure there was much to do differently the next day. But if the lessons of Think Twice have value, they suggest some very concrete actions. Before I enumerate those actions, let’s start with what you need not do. You needn’t think twice before every decision. Since most decisions will be straightforward, with clear-cut repercussions, the mistakes in this book will not be relevant. We all make lots of decisions every day, and the stakes are generally low. Even when they are not low, the best course is often obvious enough. Think Twice’s value comes in situations where the stakes are sufficiently high and where your natural decision-making process leads you to a suboptimal choice. So you must learn about the potential mistakes (prepare), identify them in context (recognize), and sharpen your ultimate decisions when the time comes (apply). Here are some thoughts on what you should do differently tomorrow. Raise your Awareness. In the introduction, I said the mistakes had to be common, identifiable, and preventable. If my message succeeded, you will see mistakes everywhere. The first action is working to identify these mistakes in your daily stream of information. My bet is you won’t lack for material. This action is in part inspired by mathematician John Allen Paulos’s books, including A Mathematician Reads the… ([Location 2335](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2335))
    - Tags: [[pink]] 
- If you are serious about improving your decisions and are open to feedback, there is a simple, inexpensive technique of great value—a decision-making journal. Whenever you make an important decision, take a moment to write down what you decided, how you came to that decision, and what you expect to happen. If you have the time and the inclination, you can also note how you feel physically and mentally. A well-kept journal offers a pair of benefits. The journal allows you to audit your decisions. Too often, after we have made a decision and observed the outcome (and this is especially true for good outcomes), our minds change the story of how we decided. Having the decision-making process written in your own hand makes it much more difficult to conjure new explanations after the fact. This process of auditing is particularly useful when decisions made with a poor process lead to good outcomes. Another benefit is the potential to find patterns. When you review your journal, you may start to see relationships between how you felt and how the decision worked out. For instance, you might note that when you are in a good mood, you are more likely to be overconfident in your assessments. Josh Waitzkin, who has achieved world-class prominence in chess and the martial arts, describes the practice of Tigran Petrosian, a former World Chess Champion. When playing matches lasting days or weeks, Petrosian would wake up and sit quietly in his room, carefully assessing his own mood. He then built his game plan for the day based on that mood, with great success. A journal can provide a structured tool for similar introspection.6 ([Location 2393](https://readwise.io/to_kindle?action=open&asin=B004OC07AI&location=2393))
    - Tags: [[pink]]

