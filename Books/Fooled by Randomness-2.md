---
tags:
  - readwise
---

# Fooled by Randomness

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/412MBJ9ojxL._SL200_.jpg)

## Metadata
- Author: [[Nassim Nicholas Taleb]]
- Full Title: Fooled by Randomness
- Category: #books

## Highlights
- RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND On the difficulty of thinking of your vacation as a linear combination of Paris and the Bahamas. Nero Tulip may never ski in the Alps again. Do not ask bureaucrats too many questions. A Brain Made in Brooklyn. We need Napoleon. Scientists bowing to the King of Sweden. A little more on journalistic pollution. Why you may be dead by now. PARIS OR THE BAHAMAS? You have two options for your next brief vacation in March. The first is to fly to Paris; the second is to go to the Caribbean. You expressed indifference between the two options; your spouse will tip the decision one way or the other. Two distinct and separate images come to you when you think of the possibilities. In the first one, you see yourself standing at the Musee d’Orsay in front of some Pissaro painting depicting a cloudy sky—the gray Parisian wintry sky. You are carrying an umbrella under your arm. In the second image, you are lying on a towel with a stack of books by your favorite authors next to you (Tom Clancy and Ammianus Marcellinus), and an obsequious waiter serving you a banana daiquiri. You know that the two states are mutually exclusive (you can only be in one place at one time), but exhaustive (there is a 100% probability that you will be in one of them). They are equiprobable, with, in your opinion, 50% probability assigned to each. ([Location 2994](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=2994))
    - Tags: [[pink]] 
- Eleven RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND On the difficulty of thinking of your vacation as a linear combination of Paris and the Bahamas. Nero Tulip may never ski in the Alps again. Do not ask bureaucrats too many questions. A Brain Made in Brooklyn. We need Napoleon. Scientists bowing to the King of Sweden. A little more on journalistic pollution. Why you may be dead by now. PARIS OR THE BAHAMAS? You have two options for your next brief vacation in March. The first is to fly to Paris; the second is to go to the Caribbean. You expressed indifference between the two options; your spouse will tip the decision one way or the other. Two distinct and separate images come to you when you think of the possibilities. In the first one, you see yourself standing at the Musee d’Orsay in front of some Pissaro painting depicting a cloudy sky—the gray Parisian wintry sky. You are carrying an umbrella under your arm. In the second image, you are lying on a towel with a stack of books by your favorite authors next to you (Tom Clancy and Ammianus Marcellinus), and an obsequious waiter serving you a banana daiquiri. You know that the two states are mutually exclusive (you can only be in one place at one time), but exhaustive (there is a 100% probability that you will be in one of them). They are equiprobable, with, in your opinion, 50% probability assigned to each. You derive great pleasure thinking about your vacation; it motivates you and makes your daily commute more bearable. But the adequate way to visualize yourself, according to rational behavior under uncertainty, is 50% in one of the vacation spots and 50% in the other—what is mathematically called a linear combination of the two states. Can your brain handle that? How desirable would it be to have your feet in the Caribbean waters and your head exposed to the Parisian rain? Our brain can properly handle one and only one state at once—unless you have personality troubles of a deeply pathological nature. Now try to imagine an 85%/15% combination. Any luck? Consider a bet you make with a colleague for the amount of $1,000, which, in your opinion, is exactly fair. Tomorrow night you will have zero or $2,000 in your pocket, each with a 50% probability. In purely mathematical terms, the fair value of a bet is the linear combination of the states, here called the mathematical expectation, i.e., the… ([Location 2994](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=2994))
    - Tags: [[pink]] 
- You derive great pleasure thinking about your vacation; it motivates you and makes your daily commute more bearable. But the adequate way to visualize yourself, according to rational behavior under uncertainty, is 50% in one of the vacation spots and 50% in the other—what is mathematically called a linear combination of the two states. Can your brain handle that? How desirable would it be to have your feet in the Caribbean waters and your head exposed to the Parisian rain? Our brain can properly handle one and only one state at once—unless you have personality troubles of a deeply pathological nature. Now try to imagine an 85%/15% combination. Any luck? Consider a bet you make with a colleague for the amount of $1,000, which, in your opinion, is exactly fair. Tomorrow night you will have zero or $2,000 in your pocket, each with a 50% probability. In purely mathematical terms, the fair value of a bet is the linear combination of the states, here called the mathematical expectation, i.e., the probabilities of each payoff multiplied by the dollar values at stake (50% multiplied by 0 and 50% multiplied by $2,000 = $1,000). Can you imagine (that is visualize, not compute mathematically) the value being $1,000? We can conjure up one and only one state at a given time, i.e., either 0 or $2,000. Left to our own devices, we are likely to bet in an irrational way, as one of the states would dominate the picture—the fear of ending with nothing or the excitement of an extra $1,000. SOME ARCHITECTURAL CONSIDERATIONS Time to reveal Nero’s secret. It was a black swan. He was then thirty-five. Although prewar buildings in New York can have a pleasant front, their architecture seen from the back offers a stark contrast by being completely ([Location 3006](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3006))
    - Tags: [[pink]] 
- bland. The doctor’s examination room had a window overlooking the backyard of one such Upper East Side street, and Nero will always remember how bland that backyard was in comparison with the front, even if he were to live another half century. He will always remember the view of the ugly pink backyard from the leaden window panes, and the medical diploma on the wall that he read a dozen times as he was waiting for the doctor to come into the room (half an eternity, for Nero suspected that something was wrong). The news was then delivered (grave voice), “I have some… I got the pathology report… It’s… It is not as bad as it sounds… It’s… It’s cancer.” The declaration caused his body to be hit by an electric discharge, running through his back down to his knees. Nero tried to yell “What?” but no sound came out of his mouth. What scared him was not so much the news as the sight of the doctor. Somehow the news reached his body before his mind. There was too much fear in the doctor’s eyes and Nero immediately suspected that the news was even worse than what he was being told (it was). The night of the diagnosis, at the medical library where he sat, drenched wet from walking for hours in the rain without noticing it and making a puddle of water around him (he was yelled at by an attendant but could not concentrate on what she was saying so she shrugged her shoulders and walked away);… ([Location 3019](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3019))
    - Tags: [[pink]] 
- Now the reader might wonder about the mathematical difference between a 28% chance of death and a 72% chance of survival over the next five years. Clearly, there is none, but we are not made for mathematics. In Nero’s mind a 28% chance of death meant the image of himself dead, and thoughts of the cumbersome details of his funeral. A 72% chance of survival put him in a cheerful mood; his mind was planning the result of a cured Nero skiing in the Alps. At no point during his ordeal did Nero think of himself as 72% alive and 28% dead. Just as Nero cannot “think” in complicated shades, consumers consider a 75% fat-free hamburger to be different from a 25% fat one. Likewise with statistical… ([Location 3032](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3032))
    - Tags: [[pink]] 
- his portfolio. Why? Because as we will see, rule-determined behavior does not require nuances. Either you kill your neighbor or you don’t. Intermediate sentiments (leading, say, to only half his killing) are either useless or downright dangerous when you do things. The emotional apparatus that jolts us into action does not understand such nuances—it is not efficient to understand things. The rest of this chapter will rapidly illustrate some manifestations of such blindness, with a cursory exposition of the research in that area (only what connects to the topics in this book). BEWARE THE PHILOSOPHER BUREAUCRAT For a long time we had the wrong product specifications when we thought of ourselves. We humans have been under the belief that we were endowed with a beautiful machine for thinking and understanding things. However, among the factory specifications for us is the lack of awareness of the true factory specifications (why complicate things?). The problem with thinking is that it causes you to develop illusions. And thinking may be such a waste of energy! Who needs it! Consider that you are standing in front of a government clerk in a heavily socialist country where being a bureaucrat is held to be what respectable people do for a living. You are there to get your papers stamped by him so you can export some of their lovely chocolate candies to the New Jersey area,… ([Location 3038](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3038))
    - Tags: [[pink]] 
- General considerations of economic growth or balance of trade are none of his interests. In fact you are lucky that he doesn’t spend any time meditating about these things: Consider how long the procedure would take if he had to solve balance of trade equations. He just has a rulebook and, over a career spanning forty to forty-five years, he will just stamp documents, be mildly rude, and go home to drink nonpasteurized beer and watch soccer games. If you gave him Paul Krugman’s book on international economics he would either sell it in the black market or give it to his nephew. Accordingly, rules have their value. We just follow them not because they are the best but because they are useful and they save… ([Location 3050](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3050))
    - Tags: [[pink]] 
- ended up being eaten by it. Others who just ran away at the smallest presumption and were not slowed down by the smallest amount of thinking ended up either outchasing the tiger or outchasing their cousin who ended up being eaten by it. Satisficing It is a fact that our brains would not be able to operate without such shortcuts. The first thinker who figured it out was Herbert Simon, an interesting fellow in intellectual history. He started out as a political scientist (but he was a formal thinker, not the literary variety of political scientists who write about Afghanistan in Foreign Affairs); he was an artificial-intelligence pioneer, taught computer… ([Location 3057](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3057))
    - Tags: [[pink]] 
- His idea is that if we were to optimize at every step in life, then it would cost us an infinite amount of time and energy. Accordingly, there has to be in us an approximation process that stops somewhere. Clearly he got his intuitions from computer science—he spent his entire career at Carnegie-Mellon University in Pittsburgh, which has a reputation as a computer science center. “Satisficing” was his idea (the melding together of satisfy and suffice): You stop when you get a near-satisfactory solution. Otherwise it may take you an eternity to reach the smallest conclusion or perform the smallest act. We are therefore rational, but in a limited way: “boundedly rational.” He believed that our brains were a large optimizing machine that had built-in rules to stop somewhere. Not quite so, perhaps. It may not be just a rough approximation. For two (initially) Israeli researchers on human nature, how we behave seemed to be a completely different process from the optimizing machine presented by Simon. The two sat down introspecting in Jerusalem looking at aspects of their own thinking, compared it to rational models, and noticed qualitative differences. Whenever they both seemed to make the same mistake of reasoning they ran empirical tests on subjects, mostly students, and discovered very surprising results on the relation… ([Location 3063](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3063))
    - Tags: [[pink]] 
- noneconomists: Daniel Kahneman and Amos Tversky, the two Israeli introspectors, and their specialty was to uncover areas where human beings are not endowed with rational probabilistic thinking and optimal behavior under uncertainty. Strangely, economists studied uncertainty for a long time and did not figure out much—if anything, they thought they knew something and were fooled by it. Aside from some penetrating minds like Keynes, Knight, and Shackle, economists did not even figure out that they had no clue about uncertainty—the discussions on risk by their idols show that they did not know how much they did not know. Psychologists, on the other hand, looked at the problem and came out with solid results. Note that, unlike economists, they conducted experiments, true controlled experiments of a repeatable nature, that can be done in Ulan Bator, Mongolia, tomorrow if necessary. Conventional economists do not have this luxury as they observe the past and make lengthy and mathematical comments, then bicker with each other about them. Kahneman and Tversky went in a completely different direction than Simon and started figuring out rules in humans that did not make them rational—but things went beyond the shortcut. For them, these rules, which are called heuristics, were not merely a simplification of rational models, but were different in methodology and category. They called them “quick and dirty” heuristics. There is a dirty part: These shortcuts came with side effects, these effects being the biases, most of which I discussed previously throughout the text (such as the inability to accept anything abstract as risk). This started an empirical research tradition called the “heuristics and biases” tradition that attempted to catalogue them—it is impressive because of its empiricism and the experimental aspect of the methods used. Since the Kahneman and Tversky results, an entire discipline called behavioral finance and economics has flourished. It is in open contradiction with the orthodox so-called neoclassical economics taught in business schools and economics… ([Location 3076](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3076))
    - Tags: [[pink]] 
- thing for them to do (it is mathematically “optimal”). The opposite is a positive science, which is based on how people actually are observed to behave. In spite of economists’ envy of physicists, physics is an inherently positive science while economics, particularly microeconomics and financial economics, is predominantly a normative one. Normative economics is like religion without the aesthetics. Note that the experimental aspect of the research implies that Daniel Kahneman and the experimental ponytailed economist Vernon Smith were the first true scientists ever to bow in front of the Swedish king for the economics prize, something that should give credibility to the Nobel academy, particularly if, like many, one takes Daniel Kahneman far more seriously than a collection of serious-looking (and very human, hence fallible) Swedes. There is another hint of the scientific firmness of this research: It is extremely readable for someone outside of psychology, unlike papers in conventional economics and finance that even people in the field have difficulty reading (as the discussions are jargon-laden and heavily mathematical to give the illusion of science). A motivated reader can get concentrated in four volumes the collection of the major heuristics and biases papers. Economists were not at the time very interested in hearing these stories of irrationality: Homo economicus as we said is a… ([Location 3095](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3095))
    - Tags: [[pink]] 
- incentives, which means that they are not necessarily cost saving. They were a different form of reasoning, and one where the probabilistic reasoning was weak. WHERE IS NAPOLEON WHEN WE NEED HIM? If your mind operates by series of different disconnected rules, these may not be necessarily consistent with each other, and if they may still do the job locally, they will not necessarily do so globally. Consider them stored as a rulebook of sorts. Your reaction will depend on which page of the book you open to at any point in time. I will illustrate it with another socialist example. After the collapse of the Soviet Union, Western businesspeople involved in what became… ([Location 3108](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3108))
    - Tags: [[pink]] 
- know whether the Russians wanted it as a prank (after all, they lived long, humorless years of oppression) but the confusion led to situations where someone had to violate a law to comply with another. I have to say that lawyers are quite dull people to talk to; talking to a dull lawyer who speaks broken English with a strong accent and vodka breath can be quite straining—so you give up. This spaghetti legal system came from the piecewise development of the rules: You add a law here and there and the situation is too complicated as there is no central system that is consulted every time to ensure compatibility of all the parts together. Napoleon faced a similar situation in France and remedied it by setting up a top-down code of law that aimed to dictate a full logical consistency. The problem with us humans is not so much that no Napoleon has showed up so far to dynamite the old structure then reengineer our minds like a big central program; it is that our minds are far more complicated than just a system of laws, and the requirement for efficiency is far greater. Consider that your brain reacts differently to the same situation depending on which chapter you open to. The absence of a central processing system makes us engage in decisions that can be in conflict with each other. You may prefer apples to oranges, oranges to pears, but pears to apples—it depends on how the choices are presented to you. The fact that your mind cannot retain and use everything you know at once is the cause of such biases. One central aspect of a heuristic is that it is blind to reasoning. “I’m As Good As My Last Trade” and Other Heuristics There exist plenty of different catalogues of these heuristics in the literature (many of them overlapping); the object of this discussion is to provide the intuition behind their formation rather than list them. For a long time we traders were totally ignorant of the behavioral research and saw situations where there was with strange regularity a wedge between the simple probabilistic reasoning and people’s perception of… ([Location 3114](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3114))
    - Tags: [[pink]] 
- I start with the “I’m as good as my last trade” heuristic (or the “loss of perspective” bias)—the fact that the counter is reset at zero and you start a new day or month from scratch, whether it is your accountant who does it or your own mind. This is the most significant distortion and the one that carries the most consequences. In order to be able to put things in general context, you do not have everything you know in your mind at all times, so you retrieve the knowledge that you require at any given time in a piecemeal fashion, which puts these retrieved knowledge chunks in their local context. This means that you have an arbitrary reference point and react to differences from that… ([Location 3134](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3134))
    - Tags: [[pink]] 
- Trader Name Learned Name Description “I’m as good as my last trade.” Prospect theory Looking at differences, not absolutes, and resetting to a specific reference point “Sound-bite effect” or “Fade the fears” Affect heuristic, risk as-feeling theory People react to concrete and visible risks, not abstract ones “It was so obvious” or “Monday morning quarterback” Hindsight bias Things appear to be more predictable after the fact “You were wrong” Belief in the law of small numbers Inductive fallacies; jumping to general conclusions too quickly Brooklyn smarts/MIT intelligence Two systems of reasoning The working brain is not quite the reasoning one “It will never go there” Overconfidence Risk-taking out of an underestimation of the odds   There is the well-known trader maxim “life is incremental.” Consider that as an… ([Location 3142](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3142))
    - Tags: [[pink]] 
- and a bad day. Which period should dominate? When you take a gamble, do you say: “My net worth will end up at $99,000 or $101,500 after the gamble” or do you say “I lose $1,000 or make $1,500?” Your attitude toward the risks and rewards of the gamble will vary according to whether you look at your net worth or changes in it. But in fact in real life you will be put in situations where you will only look at your changes. The fact that the losses hurt more than the gains, and differently, makes your accumulated performance, that is, your total wealth, less relevant than the last change in it. This dependence on the local rather than the global status (coupled with the effect of the… ([Location 3159](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3159))
    - Tags: [[pink]] 
- to a given wealth (unless of course you are very poor) so the following loss would hurt you emotionally, something that would not have taken place if you received the net amount of $700,000 in one block, or, better, two sums of $350,000 each. In addition, it is easier for your brain to detect differences rather than absolutes, hence rich or poor will be (above the minimum level) in relation to something else (remember Marc and Janet). Now, when something is in relation to something else, that something else can be manipulated. Psychologists call this effect of comparing to a given reference anchoring. If we take it to its logical limit we would realize that, because of this resetting, wealth itself does not really make one happy (above, of course, some subsistence level); but positive changes in wealth may, especially if they come as “steady” increases. More on that later with my discussion of option blindness. Other aspects of anchoring. Given that you may use two different anchors in the same situation, the way you act depends on so little. When people are asked to estimate a number, they will position it with respect to a number they have in mind or one they just heard, so “big” or “small” will be comparative. Kahneman and Tversky asked subjects to estimate the proportion of African countries in the United Nations after making them consciously pull a random number between 0 and 100 (they knew it was a random number). People… ([Location 3165](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3165))
    - Tags: [[pink]] 
- journey was 20 minutes. “No, about 25,” she answered. I timed the trip: 31 minutes. This anchoring to a number is the reason people do not react to their total accumulated wealth, but to differences of wealth from whatever number they are currently anchored to. This is the major conflict with economic theory, as according to economists, someone with $1 million in the bank would be more satisfied than if he had half a million. But we saw John reaching $1 million having had a total of $10 million; he was happier when he only had half a million (starting at nothing) than where we left him in Chapter 1. Also recall the dentist whose emotions depended on how frequently he checked his portfolio. Degree in a Fortune Cookie I used to attend a health club in the middle of the day and chat with an interesting Eastern European fellow with two Ph.D. degrees, one in physics (statistical no less), the other in finance. He worked for a trading house and was obsessed with the anecdotal aspects of the markets. He once asked me doggedly what I thought the stock market would do that day. Clearly I gave him a social answer of the kind “I don’t know, perhaps lower”—quite possibly the opposite answer to what I would have given him had he asked me an hour earlier. The next day he showed great alarm upon seeing me. He went on and on discussing my credibility and… ([Location 3178](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3178))
    - Tags: [[pink]] 
- and I have an interrresting prrroblem,” then presented the issue as a statistical puzzle, he would laugh at me. “Doktorr Talevski, did you get your degree in a fortune cookie?” Why is it so? Clearly there are two problems. First, the quant did not use his statistical brain when making the inference, but a different one. Second, he made the mistake of overstating the importance of small samples (in this case just one single observation, the worst possible inferential mistake a person can make). Mathematicians tend to make egregious mathematical mistakes outside of their theoretical habitat. When Tversky and Kahneman sampled mathematical psychologists, some of whom were authors of statistical textbooks, they were puzzled by their errors. “Respondents put too much confidence in the result of small samples and their statistical judgment showed little sensitivity to sample size.” The puzzling aspect is that not only should they have known better, “they did know better.” And yet… I will next list a few more heuristics. (1) The availability heuristic, which we saw in Chapter 3 with the earthquake in California deemed more likely than catastrophe in the entire country, or death from terrorism being more “likely” than death from all possible sources (including terrorism). It corresponds to the practice of estimating the frequency of an event according to the ease with which instances of the event can be recalled. (2) The representativeness heuristic:… ([Location 3191](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3191))
    - Tags: [[pink]] 
- caused plenty of academic ink to flow (some of the people engaged in the “rationality debate” believe that Kahneman and Tversky are putting highly normative demands on us humans). (3) The simulation heuristic: the ease of mentally undoing an event—playing the alternative scenario. It corresponds to counterfactual thinking: Imagine what might have happened had you not missed your train (or how rich you’d be today had you liquidated your portfolio at the height of the NASDAQ bubble). (4) We discussed in Chapter 3 the affect heuristic: What emotions are elicited by events determine their probability in your mind. Two Systems of Reasoning Later research refines the problem as follows: There are two possible ways for us to reason, the heuristics being part of one—rationality being part of the other. Recall the colleague who used a different brain in the classroom than the one in real life in Chapter 2. Didn’t you wonder why the person you think knows physics so well cannot apply the basic laws of physics by driving well? Researchers divide the activities of our mind into the following two polarized parts, called System 1 and System 2. System 1 is effortless, automatic, associative, rapid, parallel process, opaque (i.e., we are not aware of using it), emotional, concrete, specific, social, and personalized. System 2 is effortful, controlled,… ([Location 3205](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3205))
    - Tags: [[pink]] 
- a confirmation of that as researchers in the heuristics and biases tradition believe that System 1 can be impacted by experience and integrate elements from System 2. For instance, when you learn to play chess, you use System 2. After a while things become intuitive and you are able to gauge the relative strength of an opponent by glancing at the board. Next I introduce the evolutionary psychology point of view. WHY WE DON’T MARRY THE FIRST DATE Another branch of research, called evolutionary psychology, developed a completely different approach to the same problem. It operates in parallel, creating some bitter but not too worrisome academic debates. These evolutionary psychologists agree with the Kahneman-Tversky school that people have difficulties with standard probabilistic reasoning. However, they believe that the reason lies in the way things are presented to us in the current environment. To them, we are optimized for a set of probabilistic reasoning, but in a different environment than the one prevailing today. The statement “Our brains are made for fitness not for truth” by the scientific intellectual Steven Pinker, the public spokesmen of that school, summarizes it all. They agree that our brains are not made for understanding things but think that they are not biased, or only biased because we do not use them in their real habitat. Strangely, the Kahneman-Tversky… ([Location 3219](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3219))
    - Tags: [[pink]] 
- lies in their belief in using evolutionary theory as a backbone for our understanding of human nature. While this caused a fierce scientific dispute, I will have to say that they agree on the significant part as far as this book is concerned: (1) We do not think when making choices but use heuristics; (2) We make serious probabilistic mistakes in today’s world—whatever the true reason. Note that the split even covers the new economics: Just as we have a scientific branch of economics coming out of the Kahneman and Tversky tradition (behavioral economics), there is another scientific branch of economics coming out of evolutionary… ([Location 3232](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3232))
    - Tags: [[pink]] 
- Our Natural Habitat I will not delve too deeply into amateur evolutionary theory to probe at the reasons (besides, in spite of having spent some time in libraries I feel that I am truly an amateur in the subject matter). Clearly, the environment for which we have built our endowment is not the one that prevails today. I have not told too many of my colleagues that their decision making contains some lingering habits of cavemen—but when markets experience an abrupt move, I experience the same rush of adrenaline as if a leopard were seen prowling near my trading desk. Some of my colleagues who break telephone handles upon losing money might be even closer in their psychological makeup to our common origin. This might be a platitude to those who frequent the Greek and Latin classics, but we never fail to be surprised when noticing that people a couple of dozen centuries removed from us can exhibit similar sensibility and feelings. What used to strike me as a child upon visiting museums is that ancient Greek statues exhibit men with traits indistinguishable from ours (only more harmonious and aristocratic). I was so wrong to believe that 2,200 years was a long time. Proust wrote frequently about the surprise people have when coming across emotions in Homeric heroes that are similar to those we experience today. By genetic standards… ([Location 3238](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3238))
    - Tags: [[pink]] 
- southeastern Syria to southwestern Mesopotamia. What is our natural habitat? By natural habitat, I mean the environment in which we reproduced the most, the one in which we spent the highest number of generations. The consensus among anthropologists is that we have been around as a separate species for 130,000 years, most of which were spent in the African savannah. But we do not have to go back that far in history to get the point. Imagine life in an early urban settlement, in Middle-Town, Fertile Crescent, only about 3,000 years ago—surely modern times from a genetic standpoint. Information is limited by the physical means of its transmission; one cannot travel fast, hence information will come from faraway places in concise batches. Traveling is a nuisance fraught with all manner of physical danger; you will settle within a narrow radius of where you were born unless famine or some invading uncivilized tribe dislodges you and your relatives from your happy settlement. The number of people you would get to know in a lifetime will be small. Should a crime be committed, it will be easy to gauge the evidence of guilt within the small number of possible suspects. If you are unjustly convicted of a crime, you will argue in simple terms, propounding simple evidence like “I was not there as I was praying in the temple of Baal and was seen at dusk by the high priest” and add that… ([Location 3250](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3250))
    - Tags: [[pink]] 
- This also explains why we had to wait until the emergence of the gambling literature to see the growth of the mathematics of probability. Popular belief holds that the religious backdrop of the first and second millennia blocked the growth of tools that hint at absence of determinism, and caused the delays in probability research. The idea is extremely dubious; we simply did not compute probabilities because we did not dare to? Surely the reason is rather because we did not need to. Much of our problem comes from the fact that we have evolved out of such a habitat faster, much faster, than our genes. Even worse, our genes have not changed at all. Fast and Frugal Evolutionary theorists agree that brainwork depends on how the subject is presented and the frame offered—and they can be contradictory in their results. We detect cheaters with a different part of our brain than the one we draw on to solve logical problems. People can make incoherent choices because the brain works in the form of small partial jobs. Those heuristics that we said were “quick and dirty” to the psychologists are “fast and frugal” to the evolutionary psychologists. Not only that, but some thinkers, like the cognitive scientist Gerd Gigerenzer, seem to have obsessively taken the other side of the trade from Kahneman and Tversky; his work and that of his associates at the ABC Group (Adaptive… ([Location 3262](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3262))
    - Tags: [[pink]] 
- or choosing a meal, but we are also so wired for stock selection and that we do it appropriately if the stocks are presented to us in the correct manner. In fact, Gigerenzer agrees that we do not understand probability (too abstract), but we react rather well to frequencies (less abstract): According to him, some problems that normally would cause us to make a mistake disappear when phrased in terms of percentages. According to these researchers, while we may like to think of our brain as a central processing system, with top-down features, an analogy to the Swiss Army knife (with its small specific tools) seems to be in order. How? The psychologists’ framework is built around the distinction between the domain-specific and domain-general adaptations. A domain-specific adaptation is something that is meant to solve a very precise task (as opposed to domain-general ones that are meant to solve global ones). While these are easy to understand and accept for physiological adaptations (i.e., a giraffe’s neck helps in reaching food or an animal’s colors in providing camouflage), people have had difficulties accepting why these apply to our mind in the same manner. Our brain functions by “modules.” An interesting aspect of modularity is that we may use different modules for different instances of the same problem, depending on the framework in which it is presented—as discussed in… ([Location 3275](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3275))
    - Tags: [[pink]] 
- is given. Now, the same quiz expressed in a manner that aims at uncovering a cheater, almost everyone gets it. Neurobiologists Too Neurobiologists also have their side of the story. They believe (roughly) that we have three brains: The very old one, the reptilian brain that dictates heartbeat and that we share with all animals; the limbic brain center of emotions that we share with mammals; and the neocortex, or cognitive brain, that distinguishes primates and humans (note that even institutional investors seem to have a neocortex). While that theory of the Triune brain shows some oversimplification (particularly when handled by journalists), it seems to provide a framework for the analysis of brain functions. Although it is very difficult to figure out which part of the brain does what exactly, neuroscientists have been doing some environment mapping in the brain by, say, taking a patient whose brain is damaged in one single spot (say, by a tumor or an injury deemed to be local) and deducing by elimination the function performed by such part of the anatomy. Other methods include brain imaging and electric simulations to specific areas. Many researchers outside of neurobiology, like the philosopher and cognitive scientist Jerry Fodor (who pioneered the notion of modularity) remain skeptical about the quality of the knowledge that we can uncover by examining the physical properties of the brain, be it only on account of the complicated interactions of the single parts (with corresponding nonlinearities). The mathematician and cognitive scientist David Marr, who pioneered the field of object recognition, made the apt remark that one does not learn how birds fly by studying feathers but rather by studying aerodynamics. I will present the theses of two watershed works presented in readable books, Damasio’s Descartes’ Error and LeDoux’s Emotional Brain. Descartes’ Error presents a very simple thesis: You perform a surgical ablation on a piece of someone’s brain (say, to remove a tumor and tissue around it) with the sole resulting effect of an inability to register… ([Location 3288](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3288))
    - Tags: [[pink]] 
- expected: One cannot make a decision without emotion. Now, mathematics gives the same answer: If one were to perform an optimizing operation across a large collection of variables, even with a brain as large as ours, it would take a very long time to decide on the simplest of tasks. So we need a shortcut; emotions are there to prevent us from temporizing. Does it remind you of Herbert Simon’s idea? It seems that the emotions are the ones doing the job. Psychologists call them “lubricants of reason.” Joseph LeDoux’s theory about the role of emotions in behavior is even more potent: Emotions affect one’s thinking. He figured out that much of the connections from the emotional systems to the cognitive systems are stronger than connections from the cognitive systems to the emotional systems. The implication is that we feel emotions (limbic brain) then find an explanation (neocortex). As we saw with Claparede’s discovery, much of the opinions and assessments that we have concerning risks may be the simple result of emotions. Kafka in a Courtroom The O. J. Simpson trial provides an example of how our modern society is ruled by probability (because of the explosion in information), while important decisions are made without the smallest regard for its basic laws. We are capable of sending a spacecraft to Mars, but we are incapable of having… ([Location 3307](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3307))
    - Tags: [[pink]] 
- quantitative knowledge in the field. How could such a leap in knowledge elude lawyers and jurors only a few miles away? People who are as close to being criminal as probability laws can allow us to infer (that is, with a confidence that exceeds the shadow of a doubt) are walking free because of our misunderstanding of basic concepts of the odds. Equally, you could be convicted for a crime you never committed, again owing to a poor reading of probability—for we still cannot have a court of law properly compute the joint probability of events (the probability of two events taking place at the same time). I was in a dealing room with a TV set turned on when I saw one of the lawyers arguing that there… ([Location 3320](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3320))
    - Tags: [[pink]] 
- then switched off the television set in disgust, causing an uproar among the traders. I was under the impression until then that sophistry had been eliminated from legal cases thanks to the high standards of republican Rome. Worse, one Harvard lawyer used the specious argument that only 10% of men who brutalize their wives go on to murder them, which is a probability unconditional on the murder (whether the statement was made out of a warped notion of advocacy, pure malice, or ignorance is immaterial). Isn’t the law devoted to the truth? The correct way to look at it is to determine the percentage of murder cases where women were killed by their husbands and had previously been battered by them (that is, 50%)—for we are dealing with what is called conditional probabilities; the probability that OJ. killed his wife conditional on the information of her having been killed, rather than the unconditional probability of O.J. killing his wife. How can we expect the untrained person to understand randomness when a Harvard professor who deals and teaches the concept of probabilistic evidence can make such an incorrect statement? More particularly, where jurors (and lawyers) tend to make mistakes, along with the rest of us, is in the notion of joint probability. They do not realize that evidence compounds. The probability of my being diagnosed with respiratory tract cancer and being run over by a pink Cadillac in the same year, assuming each one of them is 1/100,000, becomes 1/10,000,000,000—by multiplying the two (obviously independent) events. Arguing that O. J. Simpson had 1/500,000 chance of not being the killer from the blood standpoint (remember the lawyers used the sophistry that there were four people with such blood types walking around Los Angeles) and adding to it the fact that he was the husband of the person and that there was additional evidence, then (owing to the compounding effect) the odds against him rise to several trillion trillion. “Sophisticated” people make worse mistakes. I can surprise people by saying that the probability of the… ([Location 3326](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3326))
    - Tags: [[pink]] 
- of the “scientific” totalitarian regimes. It projected a scary future of mankind wrapped in absurd self-feeding bureaucracies, with spontaneously emerging rules subjected to the internal logic of the bureaucracy. It spawned an entire “literature of the absurd”; the world may be too incongruous for us. I am terrified of certain lawyers. After listening to statements during the OJ. trial (and their effect) I was scared, truly scared, of the possible outcome—my being arrested for some reason that made no sense probabilistically, and having to fight some glib lawyer in front of a randomness illiterate jury. We said that mere judgment would probably suffice in a primitive society. It is easy for a society to live without mathematics— or traders to trade without quantitative methods—when the space of possible outcomes is one-dimensional. One-dimensional means that we are looking at one sole variable, not a collection of separate events. The price of one security is one-dimensional, whereas the collection of the prices of several securities is multidimensional and requires mathematical modeling—we cannot easily see the collection of possible outcomes of the portfolio with a naked eye, and cannot even represent it on a graph as our physical world has been limited to visual representation in three dimensions only. We will argue later why we run the risk of having bad models (admittedly, we have) or making the error… ([Location 3345](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3345))
    - Tags: [[pink]] 
- theories of some economist who takes his science too seriously. The beauty of science is that it makes an allowance for both error types. Luckily, there is a middle road—but sadly, it is rarely traveled. Examples of Biases in Understanding Probability I found in the behavioral literature at least forty damning examples of such acute biases, systematic departures from rational behavior widespread across professions and fields. Below is the account of a well-known test, and an embarrassing one for the medical profession. The following famous quiz was given to medical doctors (which I borrowed from the excellent Deborah Bennett’s… ([Location 3358](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3358))
    - Tags: [[pink]] 
- they are suspected of having the disease. A patient’s test is positive. What is the probability of the patient being stricken with the disease? Most doctors answered 95%, simply taking into account the fact that the test has a 95% accuracy rate. The answer is the conditional probability that the patient is sick and the test shows it—close to 2%. Less than one in five professionals got it right. I will simplify the answer (using the frequency approach). Assume no false negatives. Consider that out of 1,000 patients who are administered the test, one will be expected to be afflicted with the disease. Out of a population of the remaining 999 healthy patients, the test will identify about 50 with the disease (it is 95% accurate). The correct answer should be that the probability of being afflicted with the disease for someone selected at random who presented a positive test is the following ratio: here 1 in 51. Think of the number of times you will be given a medication that carries damaging side effects for a given disease you were told you had, when you may only have a 2% probability of being afflicted with it! We Are Option Blind As an option trader, I have noticed that people tend to undervalue options… ([Location 3365](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3365))
    - Tags: [[pink]] 
- deemed to decay, by losing their premium between two dates. I will clarify next with a simplified (but sufficient) explanation of what an option means. Say a stock trades at $100 and that someone gives me the right (but not the obligation) to buy it at $110 one month ahead of today. This is dubbed a call option. It makes sense for me to exercise it, by asking the seller of the option to deliver me the stock at $ 110, only if it trades at a higher price than $110 in one month’s time. If the stock goes to $120, my option will be worth $10, for I will be able to buy the stock at $110 from the option writer and sell it to the market at $120, pocketing the difference. But this does not have a very high probability. It is called out-of-the-money, for I have no gain from exercising it right away. Consider that I buy the option for $1. What do I expect the value of the option to be one month from now? Most people think 0. That is not true. The option has a high probability, say 90%, of being worth 0 at expiration, but perhaps 10% probability to be worth an average of $10. Thus, selling the option to me for $1 does not provide the seller with free money. If the seller had instead bought the stock himself at $100 and waited the month, he could have sold it for $120. Making $1 now was hardly, therefore, free money. Likewise, buying it is not a wasting asset. Even professionals can be fooled. How? They confuse the expected value and the most likely… ([Location 3379](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3379))
    - Tags: [[pink]] 
- steady return and the steady feeling of reward— what psychologists call flow. It is very pleasant to go to work in the morning with the expectation of being up some small money. It requires some strength of character to accept the expectation of bleeding a little, losing pennies on a steady basis even if the strategy  is bound to be profitable over longer periods. I noticed that very few option traders can maintain what I call a “long volatility” position, namely a position that will most likely lose a small quantity of money at expiration, but is expected to make money in the long run because of occasional spurts. I discovered very few people who accepted losing $1 for most expirations and making $10 once in a while, even if the game were fair (i.e., they made the $10 more than 9.1% of the time). I divide the community of option traders into two categories: premium sellers and premium buyers. Premium sellers (also called option sellers) sell options, and generally make steady money, like John in Chapters 1 and 5. Premium buyers do the reverse. Option sellers, it is said, eat like chickens and go to the bathroom like elephants. Alas, most option traders I encountered in my career are premium sellers—when they blow up it is generally other people’s money. How could professionals seemingly aware of the (simple) mathematics be put in such a position? As previously discussed, our actions are not quite guided by the parts… ([Location 3392](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3392))
    - Tags: [[pink]] 
- generally finance academics, who, instead of fitting their actions to their brains, fit their brains to their actions. These people go back and unwittingly cheat with the statistics to justify their actions. In my business, they fool themselves with statistical arguments to justify their option selling. What is less unpleasant: to lose 100 times $1 or lose once $100? Clearly the second: Our sensitivity to losses decreases. So a trading policy that makes $1 a day for a long time then loses them all is actually pleasant from a hedonic standpoint, although it does not make sense economically. So there is an incentive to invent a story about the likelihood of the events and carry on such strategy. In addition, there is the risk ignorance factor. Scientists have subjected people to tests—what I mentioned in the prologue as risk taking out of underestimating the risks rather than courage. The subjects were asked to predict a range for security prices in the future, an upper bound and a lower bound, in such a way that they would be comfortable with 98% of the security ending inside such range. Of course violations to such bound were very large, up to 30%. Such violations arise from a far more severe problem: People overvalue their knowledge and underestimate the probability of their being wrong. One example to… ([Location 3405](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3405))
    - Tags: [[pink]] 
- PROBABILITIES AND THE MEDIA (MORE JOURNALISTS) A journalist is trained in methods to express himself rather than to plumb the depth of things—the selection process favors the most communicative, not necessarily the most knowledgeable. My medical doctor friends claim that many medical journalists do not understand anything about medicine and biology, often making mistakes of a very basic nature. I cannot confirm such statements, being myself a mere amateur (though at times a voracious reader) in medical research, but I have noticed that they almost always misunderstand the probabilities used in medical research announcements. The most common one concerns the interpretation  of evidence. They most commonly get mixed up between absence of evidence and evidence of absence, a similar problem to the one we saw in Chapter 9. How? Say I test some chemotherapy, for instance Fluorouracil, for upper respiratory tract cancer, and find that it is better than a placebo, but only marginally so; that (in addition to other modalities) it improves survival from 21 per 100 to 24 per 100. Given my sample size, I may not be confident that the additional 3% survival points come from the medicine; it could be merely attributable to randomness. I would write a paper outlining my results and saying that there is no evidence of improved survival (as yet) from such medicine, and that… ([Location 3417](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3417))
    - Tags: [[pink]] 
- block against the medication, even when some researcher finally finds fresh evidence that such medicine confers a clear survival advantage. CNBC at Lunchtime The advent of the financial television channel CNBC presented plenty of benefits to the financial community but it also allowed a collection of extrovert practitioners long on theories to voice them in a few minutes of television time. One often sees respectable people making ludicrous (but smart-sounding) statements about properties of the stock market. Among these are statements that blatantly violate the laws of probability. One summer during which I was assiduous at the health club, I often heard statements such as “the real market is only 10% off the highs while the average stock is close to 40% off its highs,” which is intended to be indicative of deep troubles or anomalies—some harbinger of bear markets. There is no incompatibility between the fact that the average stock is down 40% from the highs while the average of all stocks (that is, the market) is down 10% from its own highs. One must consider that the stocks did not all reach their highs at the same time. Given that stocks are not 100% correlated, stock A might reach its maximum in January, stock B might reach its maximum in April, but the average of the two stocks A and B might reach its maximum at some time in February. Furthermore, in the event of negatively correlated stocks, if stock A is at its maximum when stock B is at its minimum, then they could both be down 40% from their maximum when the stock market is at its highs! By a law of probability called distribution of the maximum of random variables, the maximum of an average is necessarily less volatile than the average maximum. You Should Be Dead by Now This brings to mind another common violation of probability by prime-time TV financial experts, who may be selected for their looks, their charisma, and their presentation skills, but certainly not for their incisive minds. For instance, a fallacy that I saw… ([Location 3430](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3430))
    - Tags: [[pink]] 
- life expectancy may be seventy-three years. But as you advance in age and do not die, your life expectancy increases along with your life. Why? Because other people, by dying, have taken your spot in the statistics, for expectation means average. So if you are seventy-three and are in good health, you may still have, say, nine years in expectation. But the expectation would change, and at eighty-two, you will have another five years, provided of course you are still alive. Even someone one hundred years old still has a positive conditional life expectation. Such a statement, when one thinks about it, is not too different from the one that says: Our operation has a mortality rate of 1%. So far we have operated on ninety-nine patients with great success; you are our one hundreth, hence you have a 100% probability of dying on the table. TV financial planners may confuse a few people. This is quite harmless. What is far more worrying is the supply of information by nonprofessionals to professionals; it is to the journalists that we turn next. The Bloomberg Explanations I have, on my desk, a machine eponymously called a Bloomberg (after the legendary founder Michael Bloomberg). It acts as a safe e-mail service, a news service, a historical-data retrieving tool, a charting system, an invaluable analytical aid, and, not least, a screen where I can see the price of securities and currencies. I have gotten so addicted to it that I cannot operate without it, as I would otherwise feel cut off from the rest of the world. I use it to get in contact with my friends, confirm appointments, and solve some of those entertaining quarrels that put some sharpness into life. Somehow, traders who do not have a Bloomberg address do not exist for us (they have to have recourse to the more plebeian Internet). But there is one aspect of Bloomberg I would dispense with: the journalist’s commentary. Why? Because they engage in explaining things and perpetuate the right-column, left-column confusion in a serious manner. Bloomberg is not the sole perpetrator; it is just that I have not been exposed to newspapers’ business sections over the past decade, preferring to read real prose instead. As I am writing these lines I see the following headlines on my Bloomberg: → Dow is up 1.03 on lower interest rates. → Dollar down 0.12 yen on higher Japanese surplus. and so on for an entire page.… ([Location 3449](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3449))
    - Tags: [[pink]] 
- against the yen, the dollar against the European currencies, the European stock markets, the United States balance of payments, United States inflation, and another dozen prime factors, then the journalists need to look at all of these factors, look at their historical effect both in isolation and jointly, look at the stability of such influence, then, after consulting the test statistic, isolate the factor if it is possible to do so. Finally, a proper confidence level needs to be given to the factor itself; if it is less than 90% the story would be dead. I can understand why Hume was extremely obsessed with causality and could not accept such inference anywhere. I have a trick to know if something real in the world is taking place. I have set up my Bloomberg monitor to display the price and percentage change of all relevant prices in the world: currencies, stocks, interest rates, and commodities. By dint of looking at the same setup for years, as I keep the currencies in the upper left corner and the various stock markets on the right, I managed to build an instinctive way of knowing if something serious is going on. The trick is to look only at the large percentage changes. Unless something moves by more than its usual daily percentage change, the event is deemed to be noise. Percentage moves are the size of the headlines. In addition, the interpretation is not linear; a 2% move is not twice as significant an event as 1 %, it is rather like… ([Location 3483](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3483))
    - Tags: [[pink]] 
- cannot instinctively understand the nonlinear aspect of probability. Filtering Methods Engineers use methods to clean up the noise from the signal in the data. Did it ever occur to you while talking to your cousin in Australia or the South Pole that the static on the telephone line could be distinguished from the voice of your correspondent? The method is to consider that when a change in amplitude is small, it is more likely to result from noise—with its likelihood of being a signal increasing exponentially as its magnitude increases. The method is called a smoothing kernel, which has been applied in Figures 11.1 and 11.2. But our auditory system is incapable of performing such a function by itself. Likewise our brain cannot see the difference between a significant… ([Location 3496](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3496))
    - Tags: [[pink]] 
- We Do Not Understand Confidence Levels Professionals forget the following reality. It is not the estimate or the forecast that matters so much as the degree of confidence with the opinion. Consider that you are going on a trip one fall morning and need to formulate an idea about the weather conditions prior to packing your luggage. If you expect the temperature to be 60 degrees, plus or minus 10 degrees (say in Arizona), then you would take no snow clothes and no portable electric fan. Now, what if you were going to Chicago, where you are told that the weather, while being 60 degrees, will nevertheless vary by about 30 degrees? You would have to pack winter and summer clothes. Here the expectation of the temperature carries little importance concerning the choice of clothing; it is the variance that matters. Your decision to pack is markedly different now that you are told that the variability would be around 30 degrees. Now let us push the point further; what if you were going to a planet where the expectation is also going to be around 60 degrees, but plus or minus 500 degrees? What would you pack? We can see that my activity in the market (and other random variables) depends far less on where I think the market or the random variable is going so much as it does on the degree of error I allow around such a confidence level. An Admission We… ([Location 3506](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3506))
    - Tags: [[pink]] 
- fooled by randomness. That will be explored… ([Location 3519](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3519))
    - Tags: [[pink]] 
- Odysseus, the Homerian hero, had the reputation of using guile to overcome stronger opponents. I find the most spectacular use of such guile was against no other opponent than himself. In Book 12 of the Odyssey, the hero encounters the sirens, on an island not far from the rocks of Charybdis and Scylla. Their songs are known to charm the sailors into madness, causing them irresistibly to cast themselves into the sea off the sirens’ coast, and perish. The indescribable beauty of the sirens’ songs is contrasted with the moldering corpses of sailors who strayed into the area around them. Odysseus, forewarned by Circe, contrives the following ruse. He fills the ears of all his men with wax, to the point of total deafness, and has himself tied to the mast. The sailors are under strict instructions not to release him. As they approach the sirens’ island, the sea is calm and over the water comes the sound of a music so ravishing that Odysseus struggles to get loose, expending an inordinate amount of energy to unrestrain himself. His men tie him even further, until they are safely past the poisoned sounds. The first lesson I took from the story is not to even attempt to be Odysseus. He is a mythological character and I am not. He can be tied to the mast; I can merely reach the rank of a sailor who needs to have his ears filled with wax. I AM NOT SO INTELLIGENT The epiphany I had in my career in randomness came when I understood that I was not intelligent enough, nor strong enough, to even try to fight my emotions. Besides, I believe that I need my emotions to formulate my ideas and get the energy to execute them. I am just intelligent enough to understand that I have a predisposition to be fooled by randomness—and to accept the fact that I am rather emotional. I am dominated by my emotions—but as an aesthete, I am happy about that fact. I am just like every single character whom I ridiculed in this book. Not only that, but I may be even worse than them because there may be a negative correlation between beliefs and behavior (recall Popper the man). The difference between me and those I ridicule is that I try to be aware of it. No matter how long I study and try to understand probability, my emotions will respond to a different set of calculations, those that my unintelligent genes want me to handle. If my brain can tell the difference between noise and signal, my heart cannot. Such unintelligent behavior does not just cover probability and randomness. I do not think I am reasonable enough to avoid getting angry when a discourteous driver blows his horn at me for being one nanosecond late after a traffic light turns green. I am fully aware that such anger is self-destructive and offers no benefit, and that if I were to develop anger for every idiot around me doing something of the sort, I would be long dead. These small daily emotions are not rational. But we need them to function properly. We are designed to respond to hostility with hostility. I have… ([Location 3526](https://readwise.io/to_kindle?action=open&asin=B002RI9BH6&location=3526))
    - Tags: [[pink]]

